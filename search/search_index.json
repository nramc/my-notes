{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Welcome.!","text":"<p>The Ultimate Playbook for coding snippets, references, procedures and How-To articles based on real time experience.</p>"},{"location":"index.html#recently-published-articles","title":"Recently Published Articles","text":""},{"location":"index.html#tag:latest","title":"Latest","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus          </li> <li>            Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors          </li> <li>            Pragmatic Clean Architecture: A Developer's Journey Beyond Theory          </li> <li>            Self-Contained Systems Architecture in Practice: Wins and Challenges          </li> </ul>"},{"location":"about.html","title":"About Us","text":"<ul> <li>Welcome to My Notes: A Developer's Playbook, Personal Knowledge Management System (PKMS), a knowledge hub built by   developers,   for developers.</li> <li>We\u2019re here to simplify and enhance your(our) learning journey, whether you're just starting out or looking to deepen   your expertise.</li> <li>Our mission is to provide a go-to resource that combines practical, ready-to-use code snippets, in-depth How-To   guides, and valuable improvements or feature to enhance application.</li> </ul>"},{"location":"about.html#our-purpose","title":"Our Purpose","text":"<ul> <li>We created My Notes Playbook to address a common gap in developer resources: a single, well-organized platform for   sharing   best practices, capturing useful knowledge, and making it easily accessible whenever you need it.</li> <li>With a curated collection of tutorials, articles, and quick reference materials, My Notes: A Developer's Playbook   is more than just a repository; it\u2019s a learning companion built to support you at every stage of your journey.</li> </ul>"},{"location":"about.html#what-youll-find-here","title":"What You\u2019ll Find Here","text":"<ul> <li>Code Snippets: Save time with ready-made code examples for a wide range of languages and use cases, from simple   scripts to complex implementations.</li> <li>How-To Guides: Step-by-step guides covering common tasks, troubleshooting, and best practices to make your   development process smoother.</li> <li>Articles and Insights: In-depth articles on emerging technologies, coding techniques, and trends that help you   stay ahead.</li> <li>Improvements: Various improvements and features helps end users &amp; developers and improve application's data   quality and security</li> </ul>"},{"location":"about.html#our-community","title":"Our Community","text":"<ul> <li>We believe in the power of knowledge sharing and continuous learning.</li> <li>Our platform is designed not only for individual growth but also for collaboration and community.</li> <li>We welcome contributions from developers who want to share their expertise and knowledge with fellow developers,   making My Notes: A Developer's Playbook a dynamic, ever-evolving source of reliable knowledge.</li> </ul>"},{"location":"about.html#join-us","title":"Join Us","text":"<ul> <li>Whether you\u2019re here to learn, share, or discover new techniques, My Notes: A Developer's Playbook is here to   support your journey.</li> <li>Together, we\u2019re building a brighter, more connected future for developers everywhere.</li> </ul>"},{"location":"table-of-index.html","title":"Sitemap","text":"<p>This page provides an overview of the entire content structure of this knowledge management system. It serves as a quick navigation guide, allowing us to explore all sections and pages easily.</p> <p>{{pagetree}}</p>"},{"location":"tags.html","title":"Tags","text":"<p>This page lists all content organized by tags, helping us easily find related topics. Tags group similar content together, allowing for quick navigation and discovery.</p>"},{"location":"tags.html#tag:architecture","title":"Architecture","text":"<ul> <li>            Pragmatic Clean Architecture: A Developer's Journey Beyond Theory          </li> <li>            Self-Contained Systems Architecture in Practice: Wins and Challenges          </li> </ul>"},{"location":"tags.html#tag:automation","title":"Automation","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Automating Maven Dependency Updates          </li> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            Automation Testing Tips          </li> <li>            Improve Code Health          </li> <li>            OpenRewrite Integration          </li> </ul>"},{"location":"tags.html#tag:cicd","title":"CI/CD","text":"<ul> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> </ul>"},{"location":"tags.html#tag:clean-code","title":"Clean Code","text":"<ul> <li>            Improve Code Health          </li> <li>            OpenRewrite Integration          </li> <li>            Pragmatic Clean Architecture: A Developer's Journey Beyond Theory          </li> </ul>"},{"location":"tags.html#tag:code-coverage","title":"Code Coverage","text":"<ul> <li>            Excluding Java Code from JaCoCo Code Coverage Using Annotations          </li> </ul>"},{"location":"tags.html#tag:code-refactoring","title":"Code Refactoring","text":"<ul> <li>            Improve Code Health          </li> <li>            OpenRewrite Integration          </li> </ul>"},{"location":"tags.html#tag:data-quality","title":"Data Quality","text":"<ul> <li>            Improve Data Quality          </li> <li>            Secure Password          </li> </ul>"},{"location":"tags.html#tag:dependency-management","title":"Dependency Management","text":"<ul> <li>            Automating Maven Dependency Updates          </li> </ul>"},{"location":"tags.html#tag:developer-tools","title":"Developer Tools","text":"<ul> <li>            Developer Workstation Tools          </li> <li>            IntelliJ IDE Testing Plugins          </li> </ul>"},{"location":"tags.html#tag:documentation","title":"Documentation","text":"<ul> <li>            Improve Documentation          </li> </ul>"},{"location":"tags.html#tag:email","title":"Email","text":"<ul> <li>            Email Template          </li> </ul>"},{"location":"tags.html#tag:guideline","title":"Guideline","text":"<ul> <li>            Java Application Development: Must-Have Checklist          </li> </ul>"},{"location":"tags.html#tag:how-to","title":"How-To","text":"<ul> <li>            Professional Feedback          </li> </ul>"},{"location":"tags.html#tag:http-client","title":"Http Client","text":"<ul> <li>            HTTP Client - IntelliJ Plugin          </li> </ul>"},{"location":"tags.html#tag:improvement","title":"Improvement","text":"<ul> <li>            Maximizing Web Application Usability with Deep Links          </li> <li>            Optimizing Social Media Sharing with Open Graph Meta Tags          </li> </ul>"},{"location":"tags.html#tag:improvements","title":"Improvements","text":"<ul> <li>            Improve Code Health          </li> <li>            Improve Data Quality          </li> <li>            Improve Documentation          </li> <li>            Improve Web Application          </li> <li>            Secure Password          </li> </ul>"},{"location":"tags.html#tag:intellij-plugins","title":"IntelliJ Plugins","text":"<ul> <li>            IntelliJ IDE Testing Plugins          </li> </ul>"},{"location":"tags.html#tag:jacoco","title":"JaCoCo","text":"<ul> <li>            Excluding Java Code from JaCoCo Code Coverage Using Annotations          </li> </ul>"},{"location":"tags.html#tag:java","title":"Java","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Automating Maven Dependency Updates          </li> <li>            Conditionally Registering JUnit 5 Extensions          </li> <li>            Developer Workstation Tools          </li> <li>            Email Template          </li> <li>            Excluding Java Code from JaCoCo Code Coverage Using Annotations          </li> <li>            Java Application Development: Must-Have Checklist          </li> <li>            Java Notes          </li> <li>            Local Development Essentials          </li> <li>            Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus          </li> <li>            Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors          </li> <li>            OpenRewrite Integration          </li> <li>            Pragmatic Clean Architecture: A Developer's Journey Beyond Theory          </li> <li>            Shift-Left Testing with Spring Boot and Testcontainers - A Comprehensive Guide          </li> <li>            Validations          </li> </ul>"},{"location":"tags.html#tag:junit","title":"JUnit","text":"<ul> <li>            Conditionally Registering JUnit 5 Extensions          </li> </ul>"},{"location":"tags.html#tag:kubernetes","title":"Kubernetes","text":"<ul> <li>            Kubernetes Logs Verification          </li> <li>            Useful Kubernetes Commands          </li> </ul>"},{"location":"tags.html#tag:latest","title":"Latest","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus          </li> <li>            Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors          </li> <li>            Pragmatic Clean Architecture: A Developer's Journey Beyond Theory          </li> <li>            Self-Contained Systems Architecture in Practice: Wins and Challenges          </li> </ul>"},{"location":"tags.html#tag:logs-verification","title":"Logs Verification","text":"<ul> <li>            Kubernetes Logs Verification          </li> </ul>"},{"location":"tags.html#tag:maven","title":"Maven","text":"<ul> <li>            Automating Maven Dependency Updates          </li> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            OpenRewrite Integration          </li> </ul>"},{"location":"tags.html#tag:monitoring","title":"Monitoring","text":"<ul> <li>            Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus          </li> <li>            Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors          </li> </ul>"},{"location":"tags.html#tag:password","title":"Password","text":"<ul> <li>            Secure Password          </li> </ul>"},{"location":"tags.html#tag:penetration-testing","title":"Penetration Testing","text":"<ul> <li>            Penetration Testing          </li> </ul>"},{"location":"tags.html#tag:productivity","title":"Productivity","text":"<ul> <li>            Developer Workstation Tools          </li> <li>            HTTP Client - IntelliJ Plugin          </li> <li>            IntelliJ IDE Testing Plugins          </li> <li>            IntelliJ IDEA Live Templates          </li> <li>            Local Development Essentials          </li> </ul>"},{"location":"tags.html#tag:scripts","title":"Scripts","text":"<ul> <li>            Useful Kubernetes Commands          </li> </ul>"},{"location":"tags.html#tag:secure-coding","title":"Secure Coding","text":"<ul> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            Improve Code Health          </li> <li>            OpenRewrite Integration          </li> <li>            Secure Coding          </li> <li>            Secure Password          </li> <li>            Validations          </li> </ul>"},{"location":"tags.html#tag:security","title":"Security","text":"<ul> <li>            Penetration Testing          </li> <li>            Secure Coding          </li> <li>            Secure Password          </li> </ul>"},{"location":"tags.html#tag:security-testing","title":"Security Testing","text":"<ul> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            Penetration Testing          </li> </ul>"},{"location":"tags.html#tag:spring-boot","title":"Spring Boot","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus          </li> <li>            Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors          </li> <li>            Shift-Left Testing with Spring Boot and Testcontainers - A Comprehensive Guide          </li> </ul>"},{"location":"tags.html#tag:system-design","title":"System Design","text":"<ul> <li>            Self-Contained Systems Architecture in Practice: Wins and Challenges          </li> </ul>"},{"location":"tags.html#tag:template","title":"Template","text":"<ul> <li>            Email Template          </li> <li>            Professional Feedback          </li> </ul>"},{"location":"tags.html#tag:testcontainers","title":"Testcontainers","text":"<ul> <li>            Shift-Left Testing with Spring Boot and Testcontainers - A Comprehensive Guide          </li> </ul>"},{"location":"tags.html#tag:testing","title":"Testing","text":"<ul> <li>            Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract          </li> <li>            Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide          </li> <li>            Automation Testing Tips          </li> <li>            Conditionally Registering JUnit 5 Extensions          </li> <li>            HTTP Client - IntelliJ Plugin          </li> <li>            IntelliJ IDE Testing Plugins          </li> <li>            Penetration Testing          </li> <li>            Shift-Left Testing with Spring Boot and Testcontainers - A Comprehensive Guide          </li> </ul>"},{"location":"tags.html#tag:tips","title":"Tips","text":"<ul> <li>            Automation Testing Tips          </li> </ul>"},{"location":"tags.html#tag:uiux","title":"UI/UX","text":"<ul> <li>            Maximizing Web Application Usability with Deep Links          </li> </ul>"},{"location":"tags.html#tag:validations","title":"Validations","text":"<ul> <li>            Improve Data Quality          </li> <li>            Validations          </li> </ul>"},{"location":"tags.html#tag:web-application","title":"Web Application","text":"<ul> <li>            Improve Web Application          </li> <li>            Maximizing Web Application Usability with Deep Links          </li> <li>            Optimizing Social Media Sharing with Open Graph Meta Tags          </li> </ul>"},{"location":"tags.html#tag:workstation-setup","title":"Workstation Setup","text":"<ul> <li>            Developer Workstation Tools          </li> <li>            IntelliJ IDEA Live Templates          </li> <li>            Local Development Essentials          </li> </ul>"},{"location":"tags.html#tag:workstation-setup","title":"Workstation-Setup","text":"<ul> <li>            HTTP Client - IntelliJ Plugin          </li> </ul>"},{"location":"blog/index.html","title":"Blogs","text":""},{"location":"blog/http-client-intellij-plugin.html","title":"HTTP Client - IntelliJ Plugin","text":"<ul> <li>HTTP Client helps to create, edit, and   execute HTTP requests directly in the IntelliJ IDEA code editor.</li> <li>It provides varies features like a configuring env variable file with support for environments like dev, qa and live</li> </ul>","tags":["Http Client","Productivity","Workstation-Setup","Testing"]},{"location":"blog/http-client-intellij-plugin.html#environment-files","title":"Environment files","text":"<ul> <li>create an environment file in project test source directory <code>src/test/http-client/http-client.env.json</code></li> <li>Configure environment variables based on different environments</li> </ul> <pre><code>{\n  \"dev\": {\n    \"appURL\": \"https://example-dev.com\"\n  },\n  \"qa\": {\n    \"appURL\": \"https://example-qa.com\"\n  },\n  \"live\": {\n    \"appURL\": \"https://example.com\"\n  }\n}\n</code></pre>","tags":["Http Client","Productivity","Workstation-Setup","Testing"]},{"location":"blog/http-client-intellij-plugin.html#http-scripts","title":"HTTP Scripts","text":"<ul> <li>please find below sample http script from <code>src/test/http-client/scripts/</code></li> </ul> <pre><code># Constant values\n@usecase = REGISTRATION\n\n### Registration\n# this is pre javascript block executed before http request executed\n&lt; {%\nconst pepperVal = request.environment.get(\"someConfidentialEnvironmentSpecificValue\")\nconst dateUtcIsoFormat = new Date().toISOString().split('T')[0];\nconst formattedEntityVal = pepperVal + ':' + dateUtcIsoFormat;\n\nconst hashedEntity = crypto.sha256().updateWithText(formattedEntityVal, 'UTF-8').digest().toBase64(true);\n\n// Dynamically derived value added to request context and can be used in http request\nrequest.variables.set(\"dynamicHashedEntity\", hashedEntity)\n\n%}\nPOST {{appURL}}\nContent-Type: application/vnd.registration+json\n\n{\n  \"name\": \"My Name\",\n  \"emailAddress\": \"my-email-address@example.com\",\n  \"signature\": \"{{hashedEntity}}\",\n}\n\n// this is post javascript block executed after http request executed\n&gt; {%\nclient.test(\"Request executed successfully\", function () {\nclient.assert(response.status === 201, \"Response failed\");\nclient.global.set(\"emailToken\", response.body.code)\n});\n%}\n</code></pre> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Http Client","Productivity","Workstation-Setup","Testing"]},{"location":"blog/intellij-live-templates.html","title":"IntelliJ IDEA Live Templates","text":"<p>You can download all below live templates as a file</p> <p>Download File</p> <p>You can place them inside your IntelliJ IDEA in <code>~/Library/Application Support/JetBrains/&lt;IntelliJIdea version&gt;/templates/</code></p>","tags":["Workstation Setup","Productivity"]},{"location":"blog/intellij-live-templates.html#java","title":"Java","text":"<p>Static Factory Method</p> <pre><code># Template Name: factoryMethod\npublic static $CLASS_NAME$ valueOf($PARAM_TYPE$ $PARAM_NAME$) {\n    return new $CLASS_NAME$($PARAM_NAME$);\n}\n\n# Parameters binding: \nCLASS_NAME -&gt; className()\nPARAM_TYPE -&gt; guessElementType()\nPARAM_NAME -&gt; suggestVariableName()\n</code></pre> <p>Command Line Runner <pre><code># Template Name: commandLineRunner\n@org.springframework.context.annotation.Bean\nCommandLineRunner $BEAN_NAME$() {\n    return args -&gt; {};\n}\n\n# Parameters binding: \nBEAN_NAME -&gt; suggestVariableName()\n</code></pre></p> <p>Application Runner <pre><code># Template Name: applicationRunner\n@org.springframework.context.annotation.Bean\norg.springframework.boot.ApplicationRunner $BEAN_NAME$() {\n    return args -&gt; {$END$};\n}\n\n# Parameters binding: \nBEAN_NAME -&gt; suggestVariableName()\n</code></pre></p> <p>Spring Mock MVC Test <pre><code># Template Name: mvcTest\n@org.junit.jupiter.api.Test\nvoid $TEST_METHOD$() throws Exception {\n    mockMvc.perform(org.springframework.test.web.servlet.request.MockMvcRequestBuilders.get(\"$ENDPOINT$\"))\n            .andDo(org.springframework.test.web.servlet.result.MockMvcResultHandlers.print())\n            .andExpect(org.springframework.test.web.servlet.result.MockMvcResultMatchers.status().isOk());\n}\n\n# Parameter binding:\nTEST_METHOD -&gt; methodName()\nENDPOINT -&gt; \"/api/example\"\n</code></pre></p> <p>Constant <pre><code># Template Name: constant\nprivate static final $VAR_TYPE$ $VAR_NAME$ = \"$VALUE$\";\n\n# Parameter bindings:\nVAR_TYPE -&gt; \"String\" / \"int\" / \"boolean\" / \"List&lt;String&gt;\"\nVAR_NAME -&gt; variableName()\nVALUE -&gt; guessValue($VAR_TYPE$)\n</code></pre></p>","tags":["Workstation Setup","Productivity"]},{"location":"blog/intellij-live-templates.html#mkdocs","title":"MkDocs","text":"<p>MkDocs Metadata</p> <pre><code># Template Name: mkdocs-meta-data\n---\ntitle: $TITLE$\ndescription: $DESCRIPTION$\nauthor: $USER$\ndate:\n    created: $DATE$\n    updated: \ncategories:\n  - $END$\ntags:\n  - todo\nlinks:\n  - \"[Author] Ram\": $AUTHOR_PROFILE_URL$\n---\n\n# Parameter bindings:\nUSER -&gt; \"Ramachandran Nellaiyappan\"\nDATE -&gt; date(\"YYYY-MM-d\")\n</code></pre> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Workstation Setup","Productivity"]},{"location":"blog/new-java-application-checklist.html","title":"Java Application Development: Must-Have Checklist","text":"<p>This article outlines the essential steps and considerations for Creating a new Java Application or Service</p> <ul> <li> Spring Initializr is a great tool for creating initial projects with predefined   initial   setup. I find it really helpful.</li> <li> Set up a Sonar project for the repository.   If it is an open source project,   Sonar Cloud is really helpful for maintaining good quality code.</li> <li> Setup Continues Integration (CI) workflow for each commit and merge request.   Feel free to have a look:   Journey API | ci-build-workflow.yml.</li> <li> Setup Continues Deployment (CD) workflow for automated deployment to QA &amp; LIVE environments.</li> <li>Feel free to have a   look:Journey API | release-workflow.yml</li> <li> Docker Compose really helps and boosts developer   productivity and reduces the complexity of environment setup.</li> <li> Containerization: Use Docker or other container solutions to package the application consistently. Feel free to   have look Journey API | Dockerfile</li> <li> Renovate Bot integration really helps to automatically update dependencies. Feel   free to have look Journey API | renovate.json</li> <li> OpenRewrite integration is a really powerful tool to maintain good code quality   and   automated refactoring to reduce technical debt. Feel free to have   look Journey API | rewrite.yml</li> <li> Open API with Swagger/Spring REST API Doc with AsciiDoc   Document the code and create developer-friendly API documentation. There are many other ways and frameworks to   document API, but Personally I would recommend any of these two. Feel free to have   look Journey API Configuration &amp; REST API Documentation</li> <li> Spring Boot Actuator is a great   tool to monitor and manage Spring Boot applications. It provides production-ready features such as metrics,   health checks, and application environment information.</li> <li> Integrate Micrometer with monitoring tools like Prometheus or Grafana to visualize general and application   metrics.</li> <li> Use Flyway or Liquibase for database migrations.</li> <li> Follow Clean Architecture   principles to organize code. Use ArchUnit to enforce architectural rules. Please refer   the article to know more about pragmatic   implementation: Pragmatic Clean Architecture: A Developer's Journey Beyond Theory</li> <li> Use Spring Boot DevTools to enhance the   development experience.   It provides features like automatic restarts, live reload, and configurations.</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Guideline","Java"]},{"location":"blog/open-rewrite.html","title":"OpenRewrite Integration","text":"<p>OpenRewrite  is a powerful, automated refactoring tool designed to help developers modernize and improve their codebases efficiently.</p>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#why-do-we-need-openrewrite","title":"Why Do We Need OpenRewrite?","text":"<ul> <li>Automated Code Refactoring:   Manually updating code can be tedious and error-prone, especially when dealing with large codebases. OpenRewrite   automates repetitive tasks like upgrading deprecated APIs, adjusting library versions, and fixing outdated patterns,   saving developers hours of manual work.</li> <li>Ensure Code Consistency:   In large teams or organizations, different developers may write code in slightly different   styles or patterns. OpenRewrite ensures that changes are applied consistently across the entire codebase, maintaining   uniformity in coding standards.</li> <li>Maintainable and Modern Code:   As programming languages evolve and libraries are updated, developers need to keep   their codebases modern. OpenRewrite simplifies this process by automatically updating APIs, language features, and   libraries without having to rewrite everything manually, allowing developers to adopt the latest best practices   effortlessly.</li> <li>Faster Technical Debt Reduction:   Over time, codebases accumulate technical debt, such as outdated code, inefficient patterns, or unused imports.   OpenRewrite helps developers tackle this debt by automating refactoring tasks, ensuring the codebase stays clean,   efficient, and manageable without requiring dedicated time for manual cleanup.</li> <li>Improve Security Automatically:   Security vulnerabilities in dependencies are a major concern for developers. OpenRewrite can automate updates to   vulnerable libraries and ensure the project is running on secure versions. This keeps the code secure without   developers needing to manually track and update dependencies.</li> <li>Easier Legacy Code Maintenance:   Legacy codebases are often difficult to maintain due to outdated technologies, libraries, or patterns. Developers can   use OpenRewrite to automatically refactor and modernize these legacy systems, improving readability, maintainability,   and performance, all while minimizing the risk of introducing bugs.</li> <li>Integrates Seamlessly with Development Workflow:   OpenRewrite works well with Maven, Gradle, and other build tools, and can be easily integrated into continuous   integration/continuous deployment (CI/CD) pipelines. This means developers don\u2019t have to change their workflow, and   refactoring can happen automatically as part of the regular development process.</li> <li>Customizable Refactoring for Specific Needs:   Sometimes, teams have specific requirements for refactoring that don\u2019t fit standard patterns. OpenRewrite allows   developers to write custom recipes tailored to their project\u2019s unique needs, enabling automatic, project-specific code   transformations that address edge cases or organizational standards.</li> <li>Future-Proofing Codebases:   By continuously applying OpenRewrite to a project, developers can ensure their codebase remains modern and adaptable   to future changes in the ecosystem. This reduces the need for large, disruptive refactorings down the line, allowing   for smoother, incremental updates.</li> <li>Improve Developer Productivity:   Developers want to focus on building new features and solving complex problems, not performing tedious refactorings.   By automating these tasks, OpenRewrite frees up time and mental energy, allowing developers to concentrate on   higher-value activities.</li> </ul>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#getting-started","title":"Getting Started","text":"<p>Please refer official OpenRewrite guide to get started.</p>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#binding-execution-with-maven-life-cycle-phases","title":"Binding execution with Maven Life Cycle phases","text":"<ul> <li>Instead of executing rewrite goal individually, we can also bind the execution goal with maven life cycles like   verify</li> <li>Configure rewrite plugin goal run or runNoFork with maven phase \"process-sources\" and dryRun or dryRunNoFork with \"   prepare-package\"</li> </ul> <pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.openrewrite.maven&lt;/groupId&gt;\n    &lt;artifactId&gt;rewrite-maven-plugin&lt;/artifactId&gt;\n    &lt;version&gt;${rewrite-maven-plugin.version}&lt;/version&gt;\n\n    &lt;executions&gt;\n        &lt;!-- run recipes to make changes when enabled --&gt;\n        &lt;execution&gt;\n            &lt;id&gt;run-open-rewrite-execution&lt;/id&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;runNoFork&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;phase&gt;process-sources&lt;/phase&gt;\n        &lt;/execution&gt;\n\n        &lt;!-- dryRun execution to detect changes without making actual changes --&gt;\n        &lt;execution&gt;\n            &lt;id&gt;dry-run-open-rewrite-execution&lt;/id&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;dryRunNoFork&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;phase&gt;prepare-package&lt;/phase&gt;\n        &lt;/execution&gt;\n\n    &lt;/executions&gt;\n\n    &lt;configuration&gt;\n        &lt;failOnDryRunResults&gt;true&lt;/failOnDryRunResults&gt;\n        &lt;!-- list recipes to be executed when enabled --&gt;\n        &lt;activeRecipes&gt;\n            &lt;recipe&gt;org.openrewrite.java.RemoveUnusedImports&lt;/recipe&gt;\n        &lt;/activeRecipes&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#integration-with-ci-cd","title":"Integration with CI &amp; CD","text":"<ul> <li>Executing dryRun goal as part of CI pipeline, helps to enforce clean code policy</li> <li>Implementing toggles with dedicated CI profile helps to control recipe executions such toggles useful for complex   projects to enable/disable recipes execution can not be applied immediately all together</li> </ul> <p>My approach below is,</p> <ol> <li>Always execute <code>rewrite:run</code> goal in developer work station to make changes in source code, so that the    changes verified by developer and corrected if required any.</li> <li>Always execute <code>rewrite:dryRun</code> goal in both developer workstation and CICD workflow to ensure clean code</li> </ol> <p>To achieve the approach, follow below steps,</p> <ul> <li>To control <code>rewrite:run</code> and <code>rewrite:dryRun</code> goals, define two toggle and set default values   <pre><code>&lt;properties&gt;\n  &lt;!-- open-rewrite \"run\" toggle which make changes in source code: default enabled  --&gt;\n  &lt;rewrite-maven-plugin.skip.run-execution&gt;false&lt;/rewrite-maven-plugin.skip.run-execution&gt;\n\n  &lt;!-- open-rewrite \"dryRun\" toggle which does make changes, instead provide report for anticipated changes: default enabled  --&gt;\n  &lt;rewrite-maven-plugin.skip.dry-run-execution&gt;false&lt;/rewrite-maven-plugin.skip.dry-run-execution&gt;\n  ...\n&lt;/properties&gt;\n</code></pre></li> <li>Disable <code>rewrite:run</code> toggle for CI profile based <code>CI</code> env variable.</li> <li>Please find below pom.xml which contains CI profile with toggle and dryRun execute in CI pipeline and recipes applied   on developer work station,   <pre><code>&lt;profiles&gt;\n  &lt;profile&gt;\n      &lt;id&gt;ci-profile&lt;/id&gt;\n      &lt;properties&gt;\n          &lt;!-- Recommendation: always disable \"run\" which makes changes to source code in CI pipeline\n           and run them only on developer workstation so that the changes reviewed manually --&gt;\n          &lt;rewrite-maven-plugin.skip.run-execution&gt;true&lt;/rewrite-maven-plugin.skip.run-execution&gt;\n      &lt;/properties&gt;\n      &lt;activation&gt;\n          &lt;property&gt;\n              &lt;name&gt;env.CI&lt;/name&gt;\n              &lt;value&gt;true&lt;/value&gt;\n          &lt;/property&gt;\n      &lt;/activation&gt;\n  &lt;/profile&gt;\n&lt;/profiles&gt;\n</code></pre></li> <li>Configure plugin with different executions with toggle,   <pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.openrewrite.maven&lt;/groupId&gt;\n    &lt;artifactId&gt;rewrite-maven-plugin&lt;/artifactId&gt;\n    &lt;version&gt;${rewrite-maven-plugin.version}&lt;/version&gt;\n\n    &lt;executions&gt;\n        &lt;!-- Apply Recipes conditionally --&gt;\n        &lt;execution&gt;\n            &lt;id&gt;run-open-rewrite-execution&lt;/id&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;runNoFork&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;phase&gt;process-sources&lt;/phase&gt;\n            &lt;configuration&gt;\n                &lt;rewriteSkip&gt;${rewrite-maven-plugin.skip}&lt;/rewriteSkip&gt;\n            &lt;/configuration&gt;\n        &lt;/execution&gt;\n\n        &lt;!-- dryRun execution to detect changes without making actual changes --&gt;\n        &lt;execution&gt;\n            &lt;id&gt;dry-run-open-rewrite-execution&lt;/id&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;dryRunNoFork&lt;/goal&gt;\n            &lt;/goals&gt;\n            &lt;phase&gt;prepare-package&lt;/phase&gt;\n        &lt;/execution&gt;\n\n    &lt;/executions&gt;\n\n    &lt;configuration&gt;\n        &lt;!-- make build fail when changes detected during dryRun, this helps to maintain clean code by forcing  --&gt;\n        &lt;failOnDryRunResults&gt;true&lt;/failOnDryRunResults&gt;\n        &lt;!-- list recipes to be executed when enabled --&gt;\n        &lt;activeRecipes&gt;\n            &lt;recipe&gt;...&lt;/recipe&gt;\n        &lt;/activeRecipes&gt;\n\n        &lt;!-- Code Formatting style to be applied --&gt;\n        &lt;activeStyles&gt;\n            &lt;style&gt;org.openrewrite.java.IntelliJ&lt;/style&gt;\n        &lt;/activeStyles&gt;\n    &lt;/configuration&gt;\n\n    &lt;dependencies&gt;\n    &lt;!-- list of external dependencies which is needed for recipes e.g. spring upgrade recipes  --&gt;\n    &lt;/dependencies&gt;\n\n&lt;/plugin&gt;\n</code></pre></li> </ul>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#recommended-recipes","title":"Recommended Recipes","text":"<ul> <li>Below are my personal recommendations   <pre><code>---\ntype: specs.openrewrite.org/v1beta/recipe\nname: io.github.nramc.recipes.source\nrecipeList:\n  - org.openrewrite.staticanalysis.CommonStaticAnalysis\n  - org.openrewrite.staticanalysis.CodeCleanup\n  - org.openrewrite.java.RemoveUnusedImports\n  - org.openrewrite.maven.BestPractices\n  - org.openrewrite.java.logging.slf4j.Slf4jBestPractices\n\n---\ntype: specs.openrewrite.org/v1beta/recipe\nname: io.github.nramc.recipes.testing\nrecipeList:\n  - org.openrewrite.java.testing.mockito.MockitoBestPractices\n  - org.openrewrite.java.testing.junit5.JUnit5BestPractices\n  - org.openrewrite.java.testing.cleanup.BestPractices\n  - org.openrewrite.java.testing.testcontainers.TestContainersBestPractices\n\n\n---\n</code></pre></li> </ul>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/open-rewrite.html#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>It generally makes sense to add the plugin to the root <code>pom.xml</code> in a maven Multi-Module repository so that the   configuration applies to   each module</p> <ul> <li>You might encounter some issues when running Open Sourced OpenRewrite plugin in Multi-module maven projects,   always refer Multi-Module Projects  for known   issues</li> <li>If your issue not listed there with solution, then please create ticket   on GitHub:issues</li> </ul> </li> <li> <p>No Recipe or No Style is run unless explicitly turned on explicitly with setting either in pom.xml or in command line</p> </li> <li>Recipes are classified differently for Source and Test codes. Therefore, it is important to note that not all recipes   executed for test codes.</li> <li>The goals <code>rewrite:run</code> and <code>rewrite:dryRun</code> are configured to fork Maven's life cycle and are a better choice when   running recipes via a stand-alone goal (<code>mvn rewrite:run</code>) because this will trigger all the necessary life-cycle   goals   prior to running rewrite's plugin</li> <li>The goals <code>rewrite:runNoFork</code> and <code>rewrite:dryRunNoFork</code> are more efficient to use them within the context of an   integration build, as these will not cause duplicate life cycle phases to be called</li> <li>My Personnel recommendation, prefer maven phase <code>process-sources</code> for binding <code>run</code> or <code>runNoFork</code> execution,   therefore   making changes in source code performed before unit test and integration tests execution</li> <li>Prefer maven phase <code>prepare-package</code> for binding <code>dryRun</code> or <code>dryRunNoFork</code> execution,   therefore maven build failed early before time-consuming integration tests executed</li> <li>Always configure plugin to execute <code>dryRun</code> and make build fail if any changes exists to avoid adding any new findings</li> <li>Enabled config in such a way recipes applied only on developer workstation and not in CI environment to avoid   commiting unintended changes.</li> <li>Recommendation is always check changes and commit them manually after verification</li> <li>OpenRewrite IntelliJ Plugin really helps to organise and run   recipe in developer workstation</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Code Refactoring","Automation","Secure Coding","Clean Code","Java","Maven"]},{"location":"blog/self-contained-system-architecture.html","title":"Self-Contained Systems Architecture in Practice: Wins and Challenges","text":"","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#introduction","title":"Introduction","text":"<p>Scaling an enterprise system always sounds clean on slides \u2014 until you live through it. We started with clear layers and modular services. But over time, shared frontends, tangled databases, and cross-team blockers slowed everything down.</p> <p>Microservices got us partway there, but they didn\u2019t solve the coordination overhead. That\u2019s when we embraced Self-Contained Systems (SCS) \u2014 not because it was trendy, but because we needed real independence across frontend, backend, and database.</p> <p>In this post, I\u2019ll share how we used Spring Boot, Angular/React, and PostgresSQL/MongoDB to build SCSs that helped us ship faster, reduce risk, and scale smarter \u2014 plus the pitfalls we ran into and how we overcame them.</p>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#what-is-scs","title":"What is SCS?","text":"<p>The textbook definitions of Self-Contained Systems (SCS):</p> <p>An architectural approach that separates a larger system's functionality into many independent, collaborating systems.</p> <p>In our words:</p> <p>A Self-Contained System (SCS) is a vertical slice of your application that owns everything it needs: its own frontend, backend, and database. It can be developed, deployed, and scaled independently. No waiting on other teams. No shared release pipelines.</p> <p>A simple analogy:</p> <p>If a monolith is a giant \"all-in-one restaurant\" and microservices are individual \"food counters\" inside a mall food court, then SCS is a full small restaurant \u2014 complete kitchen, waiters, tables, and a door you can walk into \u2014 next to other small restaurants.</p> <pre><code>stateDiagram-v2\n    state \"Enterprise System\" as EnterpriseSystem {\n\n        SCS_1: Self-Contained System 1\n        UI_1: UI (Angular/React/Vue)\n        Backend_1: Backend (Spring Boot RESTful API)\n        Database_1: Database (PostgresSQL/MongoDB)\n\n        state SCS_1 {\n            UI_1 --&gt; Backend_1\n            Backend_1 --&gt; Database_1\n        }\n        --\n\n        SCS_2: Self-Contained System 2\n        UI_2: UI (Angular/React/Vue)\n        Backend_2: Backend (Spring Boot RESTful API)\n        Database_2: Database (PostgresSQL/MongoDB)\n\n        state SCS_2 {\n            UI_2 --&gt; Backend_2\n            Backend_2 --&gt; Database_2\n        }\n        --\n\n        SCS_3: Self-Contained System 3\n        UI_3: UI (Angular/React/Vue)\n        Backend_3: Backend (Spring Boot RESTful API)\n        Database_3: Database (PostgresSQL/MongoDB)\n\n        state SCS_3 {\n            UI_3 --&gt; Backend_3\n            Backend_3 --&gt; Database_3\n        }\n\n    }\n</code></pre> <p>Each Self-Contained System (SCS):</p> <ul> <li>Has its own UI (frontend if needed).</li> <li>Has its own backend logic.</li> <li>Has its own database (or persistent storage).</li> <li>Can be deployed independently of others.</li> <li>Communicates with other systems only when necessary, often asynchronously (like via messaging or events).</li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#why-people-use-scs","title":"Why people use SCS?","text":"<ul> <li>To make systems easier to evolve, you don't need to touch the whole big system to change something.</li> <li>To allow teams to work independently.</li> <li>To reduce deployment risks, you deploy small parts, not the whole monster app.</li> <li>To simplify scaling, scale only the parts that need it.</li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#scs-vs-microservices","title":"SCS vs Microservices","text":"<p>Self-Contained Systems (SCS) and microservices are both architectural styles that promote modularity and independence, but they differ in their approach and scope.</p> Feature Self-Contained System (SCS) Microservices Size Bigger (whole user-visible system) Smaller (one function or feature) Deployment Deployable individually Deployable individually UI Often has its own UI Typically backend only Independence Very strong Strong, but often more interdependent Communication Fewer, asynchronous preferred Lots, synchronous (like REST APIs) is common Aim End-to-end feature delivery Specific business capability Ownership End-to-end feature team ownership Often shared ownership across teams Scaling Can scale independently Can scale independently","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#example-use-case-amazon","title":"Example Use case: Amazon","text":"<p>Let's imagine Amazon and apply Self-Contained Systems (SCS) thinking to it.</p> <p>When you visit Amazon, you see different parts:</p> <ul> <li>Home page (banners, suggestions)</li> <li>Search</li> <li>Product page (descriptions, reviews)</li> <li>Cart</li> <li>Payments</li> <li>Order history</li> <li>And more...</li> </ul> <p>In a Self-Contained System (SCS) architecture: Each of these parts could be a separate system, like this:</p> <pre><code>\nstateDiagram-v2\n    state \"Amazon\" as Amazon {\n        Direction LR\n\n        state Search {\n            UI_Search: UI (Angular/React/Vue)\n            Backend_Search: Backend (Spring Boot RESTful API)\n            Database_Search: Database (PostgresSQL/MongoDB)\n\n            UI_Search --&gt; Backend_Search\n            Backend_Search --&gt; Database_Search\n        }\n        state ProductDetails {\n            UI_ProductDetails: UI (Angular/React/Vue)\n            Backend_ProductDetails: Backend (Spring Boot RESTful API)\n            Database_ProductDetails: Database (PostgresSQL/MongoDB)\n\n            UI_ProductDetails --&gt; Backend_ProductDetails\n            Backend_ProductDetails --&gt; Database_ProductDetails\n        }\n        state OrderManagement {\n            UI_OrderManagement: UI (Angular/React/Vue)\n            Backend_OrderManagement: Backend (Spring Boot RESTful API)\n            Database_OrderManagement: Database (PostgresSQL/MongoDB)\n\n            UI_OrderManagement --&gt; Backend_OrderManagement\n            Backend_OrderManagement --&gt; Database_OrderManagement\n        }\n        state Recommendations {\n            UI_Recommendations: UI (Angular/React/Vue)\n            Backend_Recommendations: Backend (Spring Boot RESTful API)\n            Database_Recommendations: Database (PostgresSQL/MongoDB)\n\n            UI_Recommendations --&gt; Backend_Recommendations\n            Backend_Recommendations --&gt; Database_Recommendations\n        }\n        state \"...\" as SoOn {\n            UI_SoOn: More domain-specific modules like Notifications, Recommendations, etc.\n\n        }\n\n        Search --&gt; ProductDetails\n        ProductDetails --&gt; OrderManagement\n        OrderManagement --&gt; Recommendations\n        Recommendations --&gt; SoOn\n        SoOn --&gt; Recommendations\n        Recommendations --&gt; OrderManagement\n        OrderManagement --&gt; ProductDetails\n        ProductDetails --&gt; Search\n\n    }\n</code></pre> Part of Amazon Possible SCS Search Engine A system that handles search queries, suggestions, filters Product Details A system that shows product info, specs, reviews Shopping Cart A system that handles cart actions (add/remove/view) Checkout/Payments A system for checkout steps, payment processing Order Management A system to track orders, shipping updates Recommendations A system that suggests products based on user behavior Notifications A system that sends emails, push notifications User Profile A system that manages user accounts, preferences <p>Key Amazon + Self-Contained System architecture points:</p> <ul> <li>If the Search system needs an update (e.g., better filters), Amazon doesn't have to redeploy the Cart or Payments   system.</li> <li>If the Cart system is overwhelmed on Black Friday, Amazon can scale just that system.</li> <li>Different teams can own different systems \u2014 Search team, Payments team, Cart team \u2014 all moving fast without blocking   each other.</li> <li>If one system fails (say Recommendations), the rest (like Checkout) still work \u2014 improving reliability.</li> <li>If Amazon wants to add a new feature (like a new payment method), it can do so in the Payments system without touching   the Cart or Search systems.</li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#scs-in-practice","title":"SCS in Practice","text":"","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#our-transition-to-scs","title":"Our transition to SCS","text":"<p>Before SCS, we were working in a typical \"microservice-ish\" setup: backend split into services, but all tied together by a shared frontend and a few common databases. On paper, it looked modular. In practice, it was a mess.</p> <p>We didn\u2019t rewrite everything overnight. We picked one painful area \u2014 a feature set that constantly needed changes \u2014 and turned it into our first SCS.</p> <p>How we broke it down:</p> <ul> <li>Backend: A standalone Spring Boot service, owning its business logic end-to-end.</li> <li>Frontend: A separate Angular/React app \u2014 no shared codebase, no shared UI framework.</li> <li>Database: Its own PostgresSQL schema. No joins across SCS boundaries. If we needed data, we fetched it through   APIs or events.</li> </ul> <p>Each SCS became a product inside the product \u2014 fully owned by a team, built and released independently.</p> <p>We used Docker to containerize everything. CI/CD pipelines were isolated. No more waiting on a global release train. Each team had control from commit to production.</p> <p>We didn't aim for \"perfect boundaries\" \u2014 we aimed for autonomy with purpose. We made sure that each SCS could evolve independently but still fit into the larger system.</p>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#implementations","title":"Implementations","text":"<p>Here's a simple high level journey of how we set up a Self-Contained System (SCS), using a hypothetical Order Service as an example.</p> <p>The Order Service is,</p> <ul> <li>a self-contained system that handles everything related to orders</li> <li>a Spring Boot backend with REST APIs</li> <li>an Angular frontend</li> <li>a PostgresSQL database</li> <li>a Docker container for deployment</li> <li>a Flyway for database migrations</li> <li>a Kafka for event-driven communication</li> <li>a AsciiDoc for API documentation</li> <li>a GitHub Action CI/CD pipeline for continuous integration and deployment</li> </ul> <p>We used a monorepo approach to manage the codebase, with separate directories (maven modules) for the backend and frontend.</p> <p>The maven multi-module project directory structure looks like this:</p> <pre><code>order-service/\n\u251c\u2500\u2500 order-service-backend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 main/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 java/com/example/order/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 OrderServiceApplication.java\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 config/                # CORS, security, OpenAPI\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 controller/            # REST APIs (exposed only for this SCS or events)\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 service/               # Business logic\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 domain/                # Entities, enums, value objects\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 repository/            # Spring Data JPA / Mongo Repositories\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 integration/           # External API clients (REST templates, Feign, etc.)\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 event/                 # Event producers / consumers\n\u2502   \u2502   \u2514\u2500\u2500 resources/\n\u2502   \u2502       \u251c\u2500\u2500 application.yml\n\u2502   \u2502       \u2514\u2500\u2500 db/migration/             # Flyway/Liquibase scripts\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 pom.xml / build.gradle\n\u2502\n\u251c\u2500\u2500 order-service-frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 core/                     # Services, interceptors\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 features/                 # Feature modules (e.g., order-list, order-create)\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 shared/                   # Shared components, pipes, directives\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 app-routing.module.ts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 app.component.ts / html\n\u2502   \u251c\u2500\u2500 environments/\n\u2502   \u2502   \u2514\u2500\u2500 environment.prod.ts / dev.ts\n\u2502   \u251c\u2500\u2500 angular.json\n\u2502   \u251c\u2500\u2500 Dockerfile                        # Optional, if dedicated deployment is needed for frontend\n\u2502   \u2514\u2500\u2500 package.json\n\u2502\n\u251c\u2500\u2500 docker-compose.yml                    # Local development with DB and dependencies\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 .github/workflows/ci-cd.yml           # GitHub Action pipeline\n</code></pre> <p>Note</p> <ul> <li>The above directory structure is a simplified version. In a real-world scenario, you might have more   directories for tests, documentation, and other resources.</li> <li>Order Service is just an example. You can have multiple SCSs like Cart Service, Payment Service, etc.</li> <li>Order Service package both frontend and backend together as a single deployable container. You can also have   separate containers for frontend and backend if needed.</li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#key-points-in-implementation","title":"Key Points in Implementation","text":"<ul> <li>Backend: Dedicated maven module for Spring Boot application which serves   frontend resources and handle event producers/consumers, and a database migration tool   like Flyway or Liquibase.</li> <li>Database: Each SCS has its own   database  PostgresSQL / MongoDB / Cassandra.   We used a separate schema for each SCS to avoid shared databases.</li> <li>Frontend: Dedicated module for Angular app with feature modules, shared components, and a core module for   services. Some SCSs may not have a frontend at all, but if they do, we   used Angular / React to build the UI.</li> <li>UI Shared Components: We created a shared library for common components (like theme, brandings, buttons, modals,   etc.) to avoid duplication and to have unified design across SCSs. This library can be published as an NPM package and   used in multiple SCSs.</li> <li>Authentication: We used Single Sign On(SSO), OAuth2 &amp; JWT based stateless authentication to unify authentication   across SCS.   We used Spring Security for authentication and authorization. Each SCS   has   its own security configuration.</li> <li>API Documentation: We used AsciiDoc   with SpringRestDocs for API documentation. Each SCS has its own API   documentation, which is generated automatically from the code.</li> <li>Event-Driven Communication: We used Kafka   with Spring Kafka for event-driven communication between SCSs. Each SCS can   publish and subscribe to events independently.</li> <li>Docker: Each SCS has its own Dockerfile for containerization. We   packaged both frontend and backend together as a single deployable container. We   used Frontend Maven Plugin to build the frontend and package it   with the backend.</li> <li>Local Development: We used Docker Compose   with SpringBoot support to set up a local development   environment. Each SCS has its own Docker Compose file to spin up the whole SCS with its dependencies (like   PostgresSQL).</li> <li>CI/CD: Each SCS has its own CI/CD pipeline (like GitHub Actions). We set up pipelines to build,   test, and deploy each SCS independently.</li> <li>Testing: We used unit tests for individual components for both frontend and backend. Integration tests with   Testcontainers for the whole SCS. We also set up contract testing   with Spring Cloud Contract to ensure that APIs   between SCSs were compatible.</li> <li>Monitoring: We used tools like Prometheus and Grafana for monitoring each SCS independently. Each SCS has its own   monitoring setup to track performance, errors, and other metrics.</li> </ul> <p>Tip</p> <p>JHipster is a great tool to generate a Spring Boot + Angular/React + Database application with Docker support. You can use it to kickstart your SCS development.</p>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#real-benefits-we-experienced","title":"Real Benefits We Experienced","text":"<ul> <li>Independent &amp; Faster Deployments: Teams could ship features on their own schedule. No more syncing across services   or waiting for \"release windows\".</li> <li>Faster Development: Frontend and backend evolved in sync. If we needed a new API, we just built it \u2014 no waiting on   another team.</li> <li>Reduced Complexity: Each SCS was a smaller, more manageable codebase. We could focus on one part of the system   without worrying about the whole thing.</li> <li>Domain-Driven Structure: SCS aligned perfectly with our business domains. Product features mapped directly to   technical boundaries.</li> <li>Easier Troubleshooting: Since we kept each system isolated, debugging issues became faster. You knew exactly where   to look.</li> <li>Less Risky Changes: Because each SCS was loosely coupled, changes in one didn't break the rest. It reduced blast   radius and boosted confidence.</li> <li>Scalability: We could scale individual SCS based on demand. If the Cart system was under heavy load, we could   scale just that one.</li> <li>Better Testing: Each SCS could be tested independently. We could run unit tests, integration tests, and end-to-end   tests without worrying about the whole system.</li> <li>Reduced Technical Debt: As we evolved, we could refactor and improve each SCS without worrying about the whole   system. It allowed us to pay down technical debt incrementally.</li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#challenges-we-faced-solutions","title":"Challenges We Faced &amp; Solutions","text":"<ul> <li>Cross-SCS Communication: SCSs are isolated by design, but features often span boundaries. Syncing data or   triggering workflows across systems brought tough decisions: REST? Messaging? Duplication?<ul> <li>Solution: We used a mix of REST APIs for synchronous calls and event-driven architecture (like Kafka) for   asynchronous communication.</li> <li>We also defined clear contracts and APIs to minimize coupling.</li> </ul> </li> <li>UI Fragmentation: Each SCS had its own UI, leading to a fragmented user experience. We had to ensure that the   overall experience was consistent and cohesive.<ul> <li>Solution: We created a design system and style guide to ensure consistency across UIs.</li> <li>We used UI composition techniques (like iframes or micro frontends) to integrate UIs when needed.</li> </ul> </li> <li>Data Duplication &amp; Sync: We moved away from shared databases, but that meant duplicating some data between   systems. Keeping it consistent was tricky \u2014 especially when events failed or arrived late.<ul> <li>Solution: We embraced eventual consistency. We used event sourcing to manage data across systems.</li> </ul> </li> <li>Testing Across Boundaries: Unit tests were easy. Test containers helped with integration tests. But end-to-end   testing across SCSs was a challenge. We had to ensure that the whole system worked together, even if each part was   isolated.<ul> <li>Solution: We used contract testing (like interface testing) to ensure that APIs between SCSs were compatible.</li> </ul> </li> <li>Dev &amp; CI/CD Complexity: Multiple apps meant more pipelines, more configs, more moving parts. Local development   also needed better tooling.<ul> <li>Solution: We invested in good local dev setups. Each SCS had its own Docker Compose file for local testing.</li> <li>We used CI/CD tools (like GitLab or GitHub Actions) to manage pipelines for each SCS independently.</li> </ul> </li> </ul>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#conclusion","title":"Conclusion","text":"<p>Self-Contained Systems (SCS) are a game-changer for scaling complex enterprise systems. They give teams autonomy, independence, and faster delivery \u2014 but only if done right. SCS isn\u2019t a quick fix; it\u2019s about evolving your architecture as you go.</p> <p>We didn\u2019t start with SCS. We learned from real pain points, tackled challenges like cross-SCS communication and UI fragmentation, and saw huge benefits in faster releases and clearer ownership.</p> <p>For architects and senior devs: start small, learn from the journey, and let SCS give your teams the freedom to scale independently. When done right, it\u2019s a powerful way to break free from coordination bottlenecks and deliver at speed.</p> <p>Self-Contained Systems isn\u2019t just an architecture \u2014 it\u2019s a mindset shift that unlocks true team independence.</p>","tags":["Architecture","System Design","Latest"]},{"location":"blog/self-contained-system-architecture.html#references","title":"References","text":"<ul> <li>Self-Contained Systems (SCS) Architecture</li> <li> Simon Martinelli - Goodbye Microservices, Hello Self-Contained Systems</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Architecture","System Design","Latest"]},{"location":"blog/jacoco-exclude-code-with-annotation.html","title":"Excluding Java Code from JaCoCo Code Coverage Using Annotations","text":"<p>In this article, we explore how to exclude Java code from JaCoCo coverage using annotations.</p> <p>JaCoCo is a widely used code coverage tool for Java applications, helping developers assess test coverage. However, there are scenarios where certain methods or classes should be excluded from coverage reports, such as generated code, logging methods, or specific utility functions.</p>","tags":["Java","JaCoCo","Code Coverage"]},{"location":"blog/jacoco-exclude-code-with-annotation.html#why-exclude-code-from-jacoco-coverage","title":"Why Exclude Code from JaCoCo Coverage?","text":"<p>Some parts of the codebase should be excluded from test coverage calculations because they do not contribute to business logic or are externally managed.</p> <p>Common cases include:</p> <ul> <li>Generated Code: Code generated by frameworks such as Lombok, JAXB, or MapStruct.</li> <li>Logging Methods: Utility methods used exclusively for logging.</li> <li>Boilerplate Code: Getters, setters, and other auto-generated methods.</li> <li>Test Utility Classes: Helper methods used only for testing purposes.</li> </ul>","tags":["Java","JaCoCo","Code Coverage"]},{"location":"blog/jacoco-exclude-code-with-annotation.html#excluding-code-using-generated-annotation","title":"Excluding Code Using <code>@Generated</code> Annotation","text":"<p>JaCoCo automatically excludes methods and classes annotated with any annotation whose name ends with <code>Generated</code>.</p> <p>This includes standard annotations like <code>javax.annotation.Generated</code> (Java 9+) and <code>jakarta.annotation.Generated</code> (Java 17+), as well as any custom annotation that follows this naming pattern.</p> <p>For Example, you can create a custom annotation like this:</p> <pre><code>@Documented\n@Retention(RUNTIME)\n@Target({TYPE, METHOD})\npublic @interface NoCodeCoverageGenerated {\n    String description() default \"\";\n}\n</code></pre> <pre><code>import javax.annotation.Generated;\n\npublic class SampleClass {\n\n    @Generated\n    public void generatedMethod() {\n        // JaCoCo will ignore this method\n    }\n\n    @NoCodeCoverageGenerated\n    public void log() {\n        // JaCoCo will ignore this method\n    }\n}\n</code></pre> <p>JaCoCo automatically detects and excludes such methods from coverage reports without requiring additional configuration.</p>","tags":["Java","JaCoCo","Code Coverage"]},{"location":"blog/jacoco-exclude-code-with-annotation.html#excluding-classesfiles-in-jacocoexec","title":"Excluding Classes/files in <code>jacoco.exec</code>","text":"<p>To exclude entire classes from coverage reports, configure the <code>jacoco-maven-plugin</code> as follows:</p> <pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.jacoco&lt;/groupId&gt;\n    &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\n    &lt;version&gt;0.8.8&lt;/version&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;prepare-agent&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n    &lt;configuration&gt;\n        &lt;excludes&gt;\n            &lt;exclude&gt;com/example/generated/**&lt;/exclude&gt;\n        &lt;/excludes&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>","tags":["Java","JaCoCo","Code Coverage"]},{"location":"blog/jacoco-exclude-code-with-annotation.html#conclusion","title":"Conclusion","text":"<p>Excluding specific methods or classes from JaCoCo reports is crucial to maintain accurate and meaningful coverage metrics. Since JaCoCo automatically excludes all methods annotated with any annotation ending in <code>Generated</code>, developers do not need additional configuration for this behavior.</p> <p>By properly configuring JaCoCo, teams can focus on improving the quality of actual business logic while avoiding misleading coverage statistics.</p> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","JaCoCo","Code Coverage"]},{"location":"blog/clean-architecture-developer-journey.html","title":"Pragmatic Clean Architecture: A Developer's Journey Beyond Theory","text":"<p>TL;DR: Clean Architecture offers powerful principles for building modular, testable systems \u2014 but applying it in real-world projects requires balance.</p> <p>This article highlights common pitfalls like over-abstraction, complex layering, and over engineering \u2014 and shows how to avoid them by staying pragmatic.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#introduction","title":"Introduction","text":"<p>In the world of software development, Clean Architecture is often discussed in theoretical terms. However, the real challenge lies in applying these principles to actual projects. This article aims to bridge that gap by providing practical insights into implementing Clean Architecture from our real time experience in java springboot application.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#understanding-clean-architecture","title":"Understanding Clean Architecture","text":"<p>Clean Architecture is a software design philosophy that emphasizes separation of concerns, testability, and maintainability. The core idea is to structure your code in a way that allows for easy changes and adaptations without affecting the entire system.</p> <p>The architecture is typically divided into layers, each with its own responsibilities:</p> <ul> <li>Entities: The core business logic and data structures.</li> <li>Use Cases: Application-specific logic \u2014 what the system does.</li> <li>Interface Adapters: Bridges between the core and the outside world (e.g., controllers, presenters, mappers).</li> <li>Frameworks and Drivers: External stuff like databases, UI, messaging systems, etc.</li> </ul> <p>A key rule: dependencies point inward. Outer layers (like web controllers or repositories) can depend on inner layers (like use cases), but never the other way around.</p> <p>To know more about Clean Architecture, you can refer to the Clean Architecture by Robert C. Martin.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#clean-architecture-theory-meets-reality","title":"Clean Architecture: Theory Meets Reality","text":"","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#the-ideal-world-clean-architecture","title":"The Ideal World: Clean Architecture","text":"<p>Clean Architecture gives us a great mental model for building systems that are straightforward to maintain, adapt, and test \u2014 especially as complexity grows.</p> <p>The idea sounds awesome on paper:</p> <ul> <li>Clear separation of concerns \u2013 each layer (like controllers, business logic, and infrastructure) has its own job   and doesn't step on others' toes.</li> <li>Core logic knows nothing about frameworks \u2013 your real business rules don\u2019t depend on Spring, databases, or HTTP.</li> <li>Easy to test \u2013 you can test your core logic without spinning up a database or web server.</li> <li>Modular and flexible \u2013 adding features or swapping technologies doesn\u2019t mean ripping things apart.</li> </ul> <p>It\u2019s all about making change less painful \u2014 so when the business shifts, your architecture doesn\u2019t collapse.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#the-reality-what-actually-happens-in-real-projects","title":"The Reality: What Actually Happens in Real Projects","text":"<p>Clean Architecture sounds great in theory, but once you're deep into a real codebase with fast changing requirements, business pressure and deadlines, things get messy.</p> <p>Here\u2019s what we\u2019ve actually experienced:</p> <p>Time &amp; Resources vs. Architectural Purity</p> <p>Ideal: Clean Architecture advocates for careful, thoughtful design that takes into account scalability and long-term maintainability.</p> <p>Reality: In a real project, time-to-market is critical. You have two weeks to ship a feature, and writing five layers of interfaces just to save a user to the database feels like overkill. Clean Architecture needs upfront time \u2014 time to define interfaces, structure packages, and set up layers. That\u2019s hard to justify when the business wants result yesterday.</p> <p>Constantly Changing Requirements</p> <p>Ideal: Clean Architecture is meant to make change easier \u2014 and it does, eventually.</p> <p>Reality: Business requirements often change rapidly, and systems need to be adaptable. However, adhering strictly to Clean Architecture\u2019s guidelines can sometimes make such changes difficult and time-consuming.</p> <p>Complexity of Over-Abstraction</p> <p>Ideal: Each layer in Clean Architecture serves a specific purpose, ensuring clear responsibilities and reducing dependencies between components.</p> <p>Reality: The ideal of having separate abstractions for each layer often leads to over-engineering. E.g., For simple CRUD operations, going full Clean Arch can turn a 10-line service into 5 classes spread across 3 packages. That might be okay for critical flows, but for basic features, it just feels like ceremony. We\u2019ve learned to apply structure where it adds value \u2014 and skip it where it doesn\u2019t.</p> <p>Team Dynamics and Experience Matter</p> <p>Ideal: With a well-structured, modular system, each team member can focus on a specific layer of the architecture. This clear structure helps in scaling the team and the project.</p> <p>Reality: The complexity of Clean Architecture can be overwhelming, particularly for teams with limited experience in architectural design. While the theory assumes a well-coordinated, highly skilled team, in practice, the learning curve can slow down development, especially if the team isn't already familiar with the pattern.</p> <p>Simplicity Beats Purity (Most of the Time)</p> <p>Ideal: Clean Architecture emphasizes modularity and separation, providing a clean, well-organized codebase where each component does only one thing.</p> <p>Reality: When the problem is small \u2014 like a CRUD API \u2014 forcing it into the full Clean Architecture, mold can make the code harder to work with, not easier. We try to ask: \u201cIs this layer really adding clarity?\u201d If not, we don\u2019t build it.</p> <p>When Frameworks Already Do the Job</p> <p>Ideal: Clean Architecture emphasizes decoupling the business logic from the infrastructure (e.g., databases, frameworks). This makes it easy to swap out technologies without affecting the core functionality.</p> <p>Reality: Spring already gives us a lot: dependency injection, configuration, transactional boundaries, etc. Sometimes Clean Architecture wants us to re-abstract things that Spring already handles well. In those cases, we\u2019ve learned to lean into the framework \u2014 not fight it. No need to reinvent the wheel just for purity\u2019s sake.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#a-practical-middle-ground-what-actually-worked-for-us","title":"A Practical Middle Ground: What Actually Worked for Us","text":"<p>Perfect Clean Architecture looks great in diagrams \u2014 but codebases aren\u2019t built on diagrams. In real projects, we rarely have the luxury to build every abstraction upfront, and frankly, we don\u2019t need to. The key is knowing when structure helps, and when it just gets in the way.</p> <p>Here\u2019s what worked for us.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#our-journey-from-hexagonal-to-clean-architecture","title":"Our Journey: From Hexagonal to Clean Architecture","text":"<p>We started with Hexagonal Architecture because it offered a straightforward way to isolate the core domain from external systems like databases, APIs, and messaging. It worked well for us in the early stages\u2014especially when the domain was simple and small.</p> <p>But as the business logic expanded, things got tricky. Features grew, boundaries between components blurred, and cross-cutting concerns started leaking into places they didn\u2019t belong. The core wasn\u2019t as clean as we thought, and the structure became harder to reason about.</p> <p>At that point, we decided to shift toward Clean Architecture. Its layered approach gave us better control over dependency flow and helped us manage growing complexity more systematically. It also allowed us to define clearer contracts between layers, which became critical as the team and codebase scaled.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#start-simple-evolve-intentionally","title":"Start Simple, Evolve Intentionally","text":"<p>We didn\u2019t try to enforce all the layers or abstractions from day one.</p> <p>Instead, we started simple \u2014 just enough structure to keep things organized. As complexity grew (new business rules, shared logic, integrations), we added layers only where they brought value. If something was straightforward, we kept it that way.</p> <p>In our experience, architecture should evolve with the problem, not race ahead of it.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#what-we-learned","title":"What We Learned","text":"<p>At the end of the day, here\u2019s what really matters when applying Clean Architecture in a real-world project:</p> <ul> <li>Delivery &gt; Purity: Shipping working software matters more than perfectly layered code. Architecture should enable   delivery \u2014 not block it.</li> <li>Evolve the Design: Start simple. Add structure only when the domain or complexity truly demands it. Don\u2019t   front-load abstractions you might never need.</li> <li>Be Pragmatic: Fit the architecture to the project \u2014 not the other way around. Every rule is bendable if it makes   the system easier to work with.</li> <li>Keep the Business Domain Front and Center: Structure your code around what the business actually needs. When the   domain leads, the rest of the system tends to follow naturally.</li> <li>Avoid Gold Plating: Don\u2019t build layers or abstractions \u201cjust in case.\u201d Stick to what delivers value now \u2014 you can   always refactor later.</li> <li>Use Dependency Injection: Decoupling helps \u2014 especially when testing or swapping components. We let the   framework (like Spring) do the heavy lifting here.</li> <li>Respect the Dependency Rule: Core logic shouldn\u2019t depend on external stuff. Keep dependencies pointing inwards,   and let the outer layers handle frameworks, DBs, and the web.</li> <li>Refactor as You Grow: Architecture isn\u2019t a one-time decision. Make time to revisit and clean things up as the   codebase evolves.</li> <li>Learn from Experience: Continuously learn from your experiences and adapt your approach as needed. Don\u2019t expect   perfection \u2014 just aim for progress.</li> <li>Use Tools Wisely: Leverage tools and frameworks that can help you implement Clean Architecture effectively. Tools   like ArchUnit are great to enforce the rules you care about.</li> </ul>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#real-world-implementation-lessons-from-our-codebase","title":"Real-World Implementation: Lessons from our codebase","text":"<p>Here\u2019s a simplified version of our project structure, which reflects our approach to Clean Architecture:</p> <pre><code>my-project\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 main\n        \u251c\u2500\u2500 asciidoc                         # Docs (e.g., system design, API docs)\n        \u2514\u2500\u2500 java\n            \u2514\u2500\u2500 com.github.nramc.base        \n                \u251c\u2500\u2500 config                   # Configuration classes (e.g., Spring configuration, application setup)\n                \u251c\u2500\u2500 core                     # Core domain and application logic\n                \u2502   \u251c\u2500\u2500 application          # Application layer, orchestrates use cases and business logic\n                \u2502   \u251c\u2500\u2500 domain               # Core business domain logic\n                \u2502   \u2502   \u251c\u2500\u2500 model            # Domain models or entities (e.g., User, Order)\n                \u2502   \u2502   \u2514\u2500\u2500 service          # Domain services that encapsulate business logic\n                \u2502   \u251c\u2500\u2500 exception            # Custom exception classes for error handling\n                \u2502   \u251c\u2500\u2500 provider             # Wrappers for system/external services\n                \u2502   \u251c\u2500\u2500 usecase              # Use cases or application services (e.g., CreateUserUseCase)\n                \u2502   \u251c\u2500\u2500 util                 # Core Utility classes (e.g., helper methods, common functionality)\n                \u2502   \u2514\u2500\u2500 validator            # Validator classes (e.g., business rule validations)\n                \u2502       \u2514\u2500\u2500 impl             # Implementations of validation logic\n                \u251c\u2500\u2500 gateway                  # External gateways or integrations with third-party systems\n                \u251c\u2500\u2500 repository               # Repository interfaces and implementations for data access\n                \u2502   \u251c\u2500\u2500 converter            # Classes to convert between domain models and database models\n                \u2502   \u251c\u2500\u2500 impl                 # Implementations of repository interfaces (e.g., JPA repository)\n                \u2502   \u251c\u2500\u2500 projection           # Projection classes for database queries (e.g., DTOs for queries)\n                \u251c\u2500\u2500 util                     # Additional utility classes that don\u2019t fit into `core.util`\n                \u251c\u2500\u2500 web                      # Web layer: Controllers, request handling, and web-specific logic\n                \u2502   \u251c\u2500\u2500 exception            # Web-specific exceptions (e.g., HTTP error handling)\n                \u2502   \u251c\u2500\u2500 interceptor          # Interceptors for request/response modification (e.g., logging, security)\n                \u2502   \u2514\u2500\u2500 resource             # Resource classes for exposing APIs (e.g., REST controllers)\n                \u2514\u2500\u2500 MySpringBootApplication.java     # Main entry point of the Spring Boot application\n</code></pre> <p>Note</p> <p>This is how our structure evolved \u2014 not a one-size-fits-all. It reflects our balance between clean architecture principles and real-world constraints. The key is to keep responsibilities clear, enforce boundaries where they matter, and stay flexible enough to adapt as the system grows.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#what-helped-lightweight-archunit-rules","title":"What Helped: Lightweight ArchUnit Rules","text":"<p>To avoid architecture drift, we added ArchUnit tests to enforce a few key boundaries. Nothing too fancy \u2014 just enough guardrails to catch accidental coupling early.</p> <p>These checks live in our test suite and help the team stay aligned without needing to do architecture reviews every week.</p> <pre><code>package com.github.nramc.dev.journey.api;\n\nimport com.tngtech.archunit.core.domain.JavaClasses;\nimport com.tngtech.archunit.core.importer.ClassFileImporter;\nimport com.tngtech.archunit.core.importer.ImportOption;\nimport com.tngtech.archunit.lang.ArchRule;\nimport org.junit.jupiter.api.Test;\n\nimport static com.tngtech.archunit.lang.syntax.ArchRuleDefinition.noClasses;\n\nclass CleanArchitectureTest {\n    private final JavaClasses importedClasses = new ClassFileImporter()\n            .withImportOption(new ImportOption.DoNotIncludeTests())\n            .importPackages(\"com.github.nramc\");\n\n    @Test\n    void coreShouldNotDependOnWebOrRepositoryOrGateway() {\n        ArchRule rule = noClasses()\n                .that().resideInAnyPackage(\"..core..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..web..\", \"..repository..\", \"..gateway..\", \"..util..\", \"..config..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void domainShouldNotDependOnOtherPackages() {\n        ArchRule rule = noClasses()\n                .that().resideInAPackage(\"..core.domain..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\n                        \"..core.application..\",\n                        \"..core.usecase..\",\n                        \"..repository..\",\n                        \"..gateway..\",\n                        \"..web..\"\n                );\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void useCasesShouldNotDependOnWebOrRepositoryOrGateway() {\n        ArchRule rule = noClasses()\n                .that().resideInAnyPackage(\"..core.usecase..\", \"..core.application..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..web..\", \"..repository..\", \"..gateway..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void configShouldNotBeDependedOn() {\n        ArchRule rule = noClasses()\n                .that().resideOutsideOfPackage(\"..config..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..config..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void gatewayShouldOnlyBeAccessedByConfigAndGatewayItself() {\n        ArchRule rule = noClasses()\n                .that().resideOutsideOfPackages(\"..config..\", \"..gateway..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..gateway..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void webShouldNotAccessRepositoryDirectly() {\n        ArchRule rule = noClasses()\n                .that().resideInAPackage(\"..web..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..repository..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void webShouldOnlyBeAccessedByConfigAndItself() {\n        ArchRule rule = noClasses()\n                .that().resideOutsideOfPackages(\"..config..\", \"..web..\")\n                .should().dependOnClassesThat()\n                .resideInAnyPackage(\"..web..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void utilShouldNotDependOnOtherPackages() {\n        ArchRule rule = classes()\n                .that().resideInAPackage(\"..util..\")\n                .should().onlyDependOnClassesThat().\n                resideOutsideOfPackages(\"..web..\", \"..gateway..\", \"..service..\", \"..repository..\", \"..usecase..\");\n\n        rule.check(importedClasses);\n    }\n\n    @Test\n    void projectShouldNotHaveCyclicDependency() {\n        SliceRule sliceRule = slices().matching(\"com.github.nramc.(*)..\").should().beFreeOfCycles();\n        sliceRule.check(importedClasses);\n    }\n}\n</code></pre> <p>Note</p> <p>Focus on enforcing the boundaries that matter most \u2014 not every theoretical rule. ArchUnit works best when it protects the essence of your structure, not every detail.</p> <p>JUnit5 @ArchTest</p> <p>With JUnit5, you can use the <code>@ArchTest</code> annotation too to run the ArchUnit rules as part of your test suite. This allows you to enforce architectural rules without writing separate test method. ArchUnit: JUnit 5 Support</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#conclusion","title":"Conclusion","text":"<p>Clean Architecture is a powerful tool for building maintainable and testable software. However, it is essential to apply these principles pragmatically and adapt them to the needs of your project. By focusing on the business domain, avoiding over-engineering, and following best practices, you can create a clean and effective architecture that meets the needs of your team and your business.</p> <p>Clean Architecture is a direction, not a destination.</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/clean-architecture-developer-journey.html#references","title":"References","text":"<ul> <li>The Clean Architecture by Robert C. Martin (Uncle Bob)</li> <li>A quick introduction to clean architecture</li> <li> Anatomy of a Spring Boot App with Clean Architecture by Steve Pember @ Spring I/O 2023</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Architecture","Java","Clean Code","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html","title":"Mastering Spring Boot Actuator: Deep Dive into Health Indicators &amp; Info Contributors","text":"<p>TL;DR: Spring Boot Actuator gives you /health and /info endpoints out of the box\u2014but don\u2019t stop there. Add custom checks for what really matters (like external services), share useful app info, and lock things down securely. It\u2019s a small effort that makes life way easier when things go sideways.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#introduction","title":"Introduction","text":"<p>When it comes to production applications, there\u2019s no room for ambiguity. You need to know how your system is performing and whether it's healthy \u2014 without having to dive into logs or wait for something to break.</p> <p>Spring Boot Actuator offers a set of endpoints like <code>/health</code> and <code>/info</code> that can give you key insights into your application\u2019s state. However, many developers miss out on the full potential of these endpoints by leaving them in their default configuration.</p> <p>In this article, we\u2019ll explore why these endpoints are crucial for any production-grade application and provide practical examples of how to use them effectively. You\u2019ll learn how to enhance your health checks, improve observability, and ensure that your system\u2019s status is always clear\u2014whether it\u2019s running smoothly or facing issues.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#application-health-indicators","title":"Application Health Indicators","text":"<p>Health indicators are used to check the health of various components in your application. They can be used to monitor the status of databases, message brokers, and other services. Health indicators return a <code>Health</code> object that contains information about the health status and any additional details.</p> <p>The <code>/health</code> endpoint will return a simple JSON response indicating whether the application is up or down.</p> <pre><code>{\n  \"status\": \"UP\"\n}\n</code></pre> <p>By default, SpringBoot does not include details and individual components in the health check response. You can include them by setting the<code>management.endpoint.health.show-details</code> and <code>management.endpoint.health.show-components</code> properties in your <code>application.properties</code> or <code>application.yml</code></p> <pre><code>management:\n  endpoint:\n    health:\n      show-details: always # or \"when_authorized\"\n      show-components: always # or \"when_authorized\"\n</code></pre> <p>and then you can see the details of the health check.</p> <pre><code>{\n  \"status\": \"UP\",\n  \"components\": {\n    \"diskSpace\": {\n      \"status\": \"UP\",\n      \"details\": {\n        \"total\": 499963174912,\n        \"free\": 277909123072,\n        \"threshold\": 10485760,\n        \"path\": \"...\",\n        \"exists\": true\n      }\n    },\n    \"mail\": {\n      \"status\": \"UP\",\n      \"details\": {\n        \"location\": \"localhost:1025\"\n      }\n    },\n    \"mongo\": {\n      \"status\": \"UP\",\n      \"details\": {\n        \"maxWireVersion\": 21\n      }\n    },\n    \"ping\": {\n      \"status\": \"UP\"\n    },\n    \"ssl\": {\n      \"status\": \"UP\",\n      \"details\": {\n        \"validChains\": [],\n        \"invalidChains\": []\n      }\n    }\n  }\n}\n</code></pre> <p>Warning</p> <p>The <code>/health</code> endpoint is not secured by default. Make sure <code>details</code> are not exposing sensitive information. If you are not sure, then set <code>management.endpoint.health.show-details</code> to <code>when_authorized</code> or <code>never</code>.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#the-default-health-check-useful-but-limited","title":"The Default Health Check: Useful, But Limited","text":"<p>By default, Spring Boot checks the basic things like database connectivity, disk space, and a few other system metrics. To know more about autoconfigured health indicators, refer to the Auto-configured HealthIndicators.</p> <p>This is helpful for ensuring that the app is up and running from a technical standpoint, but in most production environments, you need more.</p> <p>For example:</p> <ul> <li>Is the payment gateway service available? If your payment service is down, your e-commerce platform is basically   offline, but the default <code>/health</code> endpoint wouldn't tell you that.</li> <li>Is your batch job running as expected? If scheduled tasks are stuck, that could be impacting your app, but again,   the default health check won\u2019t capture that.</li> <li>Are all external APIs reachable? If your app relies on third-party APIs, it\u2019s essential to monitor their   availability\u2014especially if they\u2019re critical for functionality.</li> <li>Is your message broker (like RabbitMQ or Kafka) up and running? If you\u2019re using a message broker for asynchronous   processing, you need to ensure that it\u2019s healthy.</li> <li>Is your application\u2019s circuit breaker configuration valid? If you\u2019re using Spring Cloud Netflix or Spring Cloud   Resilience4j, you need to ensure that the circuit breaker configuration is valid and that there are no issues with   circuit breaking.</li> </ul>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#custom-healthindicator-how-it-adds-value","title":"Custom HealthIndicator: How It Adds Value","text":"<p>To create a custom health indicator, you need to implement the <code>HealthIndicator</code> interface. This interface requires you to implement the <code>health()</code> method, which returns a <code>Health</code> object. The <code>Health</code> object can contain various details about the health status, including a status code (like UP or DOWN) and any additional information you want to provide.</p> <p>Let\u2019s say you need to monitor the connectivity to an external payment gateway. If the gateway is down, you can\u2019t process payments, and your users can\u2019t make purchases.</p> <p>Here\u2019s how you can create a custom health indicator for that:</p> <pre><code>import org.springframework.boot.actuate.health.Health;\nimport org.springframework.boot.actuate.health.HealthIndicator;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class PaymentGatewayHealthIndicator implements HealthIndicator {\n\n    @Override\n    public Health health() {\n        boolean isPaymentServiceUp = checkPaymentService(); // Logic to check the payment gateway status\n        if (isPaymentServiceUp) {\n            return Health.up().withDetail(\"Payment Service\", \"Available\").build();\n        } else {\n            return Health.down().withDetail(\"Payment Service\", \"Unavailable\").build();\n        }\n    }\n\n    private boolean checkPaymentService() {\n        // Simulate the check, e.g., an HTTP request to the payment gateway\n        return true;\n    }\n}\n</code></pre> <p>now you can see the status of the payment gateway in the <code>/health</code> endpoint:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"components\": {\n    \"diskSpace\": {\n      \"status\": \"UP\"\n    },\n    \"mail\": {\n      \"status\": \"UP\"\n    },\n    \"mongo\": {\n      \"status\": \"UP\"\n    },\n    \"paymentGateway\": {\n      \"status\": \"UP\"\n    },\n    \"ping\": {\n      \"status\": \"UP\"\n    },\n    \"ssl\": {\n      \"status\": \"UP\"\n    }\n  }\n}\n</code></pre>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#custom-health-groups","title":"Custom Health Groups","text":"<p>You can also group health indicators into different categories. This is useful for separating infrastructure checks (infra), external APIs (external), and application logic (core) for cleaner diagnostics.</p> <p>To create a custom health group, you can use properties in your <code>application.properties</code> or <code>application.yml</code> file.</p> <pre><code>management:\n  endpoint:\n    health:\n      group:\n        infra:\n          include: diskSpace, mongo\n        external:\n          include: paymentGateway, mail\n        core:\n          include: ping, ssl\n</code></pre> <p>Now, when you access the grouped health endpoint as <code>/actuator/health/infra</code>, you\u2019ll see the health status of the infrastructure components:</p> <pre><code>{\n  \"status\": \"UP\",\n  \"components\": {\n    \"diskSpace\": {\n      \"status\": \"UP\"\n    },\n    \"mongo\": {\n      \"status\": \"UP\"\n    }\n  }\n}\n</code></pre> <p>Please refer to the Spring Boot Actuator documentation for finer tuning options.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#application-information-contributors","title":"Application Information Contributors","text":"<p>Info contributors are used to provide additional information about your application. This can include build information, environment variables, and other metadata. Info contributors return an <code>Info</code> object that contains key-value pairs of information. They are typically used to enhance the <code>/info</code> endpoint of the actuator.</p> <p>The <code>/info</code> endpoint in Spring Boot is often overlooked. Out of the box, it doesn\u2019t do much\u2014usually just shows an empty JSON or a couple of basic build properties if configured. But with a little customization, it can become a powerful tool for understanding your application\u2019s state, environment, and versioning.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#what-info-can-tell-you","title":"What <code>/info</code> Can Tell You","text":"<p>The idea behind <code>/info</code> is simple: provide metadata about your application that can help with diagnostics, version tracking, or internal transparency.</p> <p>SpringBoot provides a few built-in info contributors, such as:</p> <ul> <li><code>BuildProperties</code>: Provides information about the build, like version, artifact, and group.</li> <li><code>GitInfo</code>: If you\u2019re using Git, this contributor can provide information about the current commit, branch, and   tags.</li> <li><code>Environment</code>: Exposes environment variables and system properties.</li> <li><code>System</code>: Provides system-related information like OS name, version, and architecture.</li> <li><code>CustomInfoContributor</code>: You can create your own info contributor to expose any custom information you want.</li> </ul> <p>To know more about autoconfigured info contributors, refer to Auto-configured InfoContributors</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#environment-info-contributor","title":"Environment Info Contributor","text":"<p>You can expose <code>info.*</code> environment properties by enabling Environment Info Contributor in your <code>application.properties</code> or<code>application.yml</code> file.</p> <pre><code>management:\n  endpoint:\n    info:\n      env:\n        enabled: true\n# properties start with info. added to the info endpoint\ninfo:\n  encoding: UTF-8\n  source: 17\n  target: 17\n</code></pre> <p>Now, when you access the <code>/info</code> endpoint, you\u2019ll see the additional information:</p> <pre><code>{\n  \"encoding\": \"UTF-8\",\n  \"source\": \"17\",\n  \"target\": \"17\"\n}\n</code></pre>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#writing-custom-infocontributors","title":"Writing Custom InfoContributors","text":"<p>To create a custom info contributor, you need to implement the <code>InfoContributor</code> interface. This interface requires you to implement the <code>contribute()</code> method, which takes an <code>Info.Builder</code> object as a parameter. You can use this builder to add key-value pairs of information to the <code>Info</code> object.</p> <p>Here\u2019s an example of a custom info contributor that adds application-specific information:</p> <pre><code>import org.springframework.boot.actuate.info.Info;\nimport org.springframework.boot.actuate.info.InfoContributor;\nimport org.springframework.stereotype.Component;\n\nimport java.util.Collections;\n\n@Component\npublic class MyInfoContributor implements InfoContributor {\n\n    @Override\n    public void contribute(Info.Builder builder) {\n        builder.withDetail(\"example\", Collections.singletonMap(\"key\", \"value\"));\n    }\n\n}\n</code></pre> <p>Now, when you access the <code>/info</code> endpoint, you\u2019ll see the additional information:</p> <pre><code>{\n  \"example\": {\n    \"key\": \"value\"\n  }\n}\n</code></pre> <p>To know more about Information Contributors, refer to Application Information</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#best-practices","title":"Best Practices","text":"<ul> <li>Security: Always secure your actuator endpoints, especially <code>/health</code> and <code>/info</code>. Use Spring Security to   restrict access to these endpoints.</li> <li>Granularity: Be careful about the level of detail you expose it. While it\u2019s good to have detailed health checks,   you don\u2019t want to expose sensitive information.</li> <li>Monitoring: Use monitoring tools like Prometheus or Grafana to visualize the data from your actuator endpoints.</li> <li>Focus on business-critical components: Don\u2019t just monitor the database or disk space\u2014include health checks for   services your app depends on to function, like payment providers, licensing APIs, or background schedulers.</li> <li>Avoid false negatives: External APIs might have temporary hiccups. Use timeouts, circuit breakers, and thresholds   to avoid reporting the entire app as \u201cDOWN\u201d for a minor or transient issue.</li> <li>Group health checks:Use health groups to separate infrastructure checks (infra), external APIs (external), and   application logic (core) for cleaner diagnostics.</li> <li>Versioning: Use the <code>/info</code> endpoint to track the version of your application. This is especially useful for   debugging and support.</li> <li>Keep checks lightweight: Health checks should respond quickly. Avoid long-running calls or expensive database   queries.</li> <li>Use withDetail() wisely: Add helpful details in responses\u2014but don\u2019t expose internal logic or error stack traces in   production.</li> </ul>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#conclusion","title":"Conclusion","text":"<p>Spring Boot Actuator isn\u2019t just about exposing endpoints \u2014 it\u2019s about gaining visibility into your application\u2019s health and behavior.</p> <p>By customizing health checks and info contributors, you turn basic metrics into meaningful insights. When used well, these tools help you detect issues early, track deployments confidently, and support your team with real-time diagnostics.</p> <p>Invest a bit in observability now \u2014 and save hours in production later.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-health-info-actuator-endpoints.html#references","title":"References","text":"<ul> <li>Spring Boot Actuator Documentation</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html","title":"Mastering Observability: Custom Metrics in Spring Boot with Micrometer and Prometheus","text":"","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#introduction","title":"Introduction","text":"<p>Ever found yourself debugging a production issue thinking, \"I wish I knew what this part of the app was really doing...\"? You\u2019re not alone. Logs and stack traces are helpful\u2014but they don't always tell the full story.</p> <p>Observability is key to maintaining reliable applications, and while built-in metrics cover the basics, they often fall short when you need insights into your business logic or background processing.</p> <p>That\u2019s where custom metrics come in.</p> <p>In this guide, we\u2019ll walk through how to use Micrometer in a Spring Boot application to define and collect custom metrics, and how to expose them to Prometheus for real-world monitoring.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#spring-boot-actuator-the-built-in-metrics","title":"Spring Boot Actuator: The Built-In Metrics","text":"<p>Spring Boot Actuator provides a rich set of built-in metrics out of the box, including:</p> <ul> <li>JVM: memory, threads, garbage collection</li> <li>System: CPU usage, disk space</li> <li>Logging: log levels, logger stats</li> <li>Tasks: execution times, thread pool usage</li> <li>Data sources: connection pools, query times</li> <li>HTTP: request counts, response times</li> <li>Kafka &amp; Redis: consumer lag, cache hit/miss, and more</li> <li>so on...</li> </ul> <p>To know more about the built-in metrics, refer to the Spring Boot Actuator's Metrics.</p> <p>These are great for infrastructure-level visibility\u2014but they won\u2019t tell you what your business logic is doing.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#why-custom-metrics","title":"Why Custom Metrics?","text":"<p>Imagine you're building an e-commerce system. You might want to know:</p> <ul> <li>How many orders failed validation today?</li> <li>What\u2019s the average time to process a payment?</li> <li>Is the call to the shipping provider timing out?</li> <li>How often does inventory sync fail?</li> </ul> <p>The default Spring Boot metrics won\u2019t answer any of those questions. Custom metrics will.</p> <p>They let you monitor what actually matters to your application and your users\u2014making them invaluable for performance tuning, troubleshooting, and tracking your Service Level Objectives (SLOs).</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#a-quick-look-at-the-stack","title":"A Quick Look at the Stack","text":"","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#micrometer","title":"Micrometer","text":"<p>Micrometer is the metrics facade used by Spring Boot. It offers a vendor-neutral API to create and publish metrics to backends like Prometheus, Datadog, New Relic, and more.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#prometheus","title":"Prometheus","text":"<p>Prometheus scrapes metrics from your application at regular intervals and stores them as time series data. With its powerful query language (PromQL), you can slice, dice, and alert on metrics easily.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#spring-boot-actuator","title":"Spring Boot Actuator","text":"<p>Spring Boot Actuator bridges the gap, exposing your metrics (including custom ones) via HTTP endpoints like <code>/actuator/metrics</code>.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#setting-up-micrometer-and-prometheus-in-spring-boot","title":"Setting Up Micrometer and Prometheus in Spring Boot","text":"","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#add-dependencies","title":"Add Dependencies","text":"<p>To get started, you need to add the necessary dependencies to your Spring Boot project. In this example, we will use prometheus as the metrics backend.</p> <p>For Maven Dependency,</p> <pre><code>&lt;depdencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.micrometer&lt;/groupId&gt;\n        &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n&lt;/depdencies&gt;\n</code></pre> <p>For Gradle Dependency,</p> <pre><code>implementation 'org.springframework.boot:spring-boot-starter-actuator'\nimplementation 'io.micrometer:micrometer-registry-prometheus'\n</code></pre>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#expose-metrics-endpoint","title":"Expose Metrics Endpoint","text":"<p>In application.yml</p> <pre><code>management:\n  endpoints:\n    web:\n      exposure:\n        include: health,info,prometheus\n</code></pre> <p>Prometheus will now scrape metrics from <code>/actuator/prometheus</code>.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#choosing-the-right-metric-type","title":"Choosing the Right Metric Type","text":"<p>Micrometer provides several types of metrics, each suited for different use cases. Here are some of the most common metric types:</p> <ul> <li>Counter: A counter is a simple metric that only increases. It is used to count occurrences of events, such as the   number of requests received or the number of errors encountered.</li> <li>Gauge: A gauge is a metric that can go up or down. It is used to measure values that can change over time, such as   the current number of active users or the amount of memory used by the application.</li> <li>Timer: A timer is a metric that measures the duration of an event. It is used to measure the time taken to   complete a task, such as the time taken to process a request or the time taken to execute a background job.</li> <li>Distribution Summary: A distribution summary is a metric that measures the distribution of values over time. It is   used to measure the size of requests or responses, such as the size of files uploaded or downloaded.</li> </ul>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#example-real-time-use-cases-with-custom-metrics","title":"Example: Real Time Use Cases with Custom Metrics","text":"Use Case Metric Type What It Tells You Failed order validations Counter How often orders fail business rules\u2014helps detect spikes or regressions Payment processing duration Timer Measures latency of payment flow\u2014helps identify slowdowns or backend issues Inventory sync queue size Gauge Tracks current queue depth\u2014indicates backlog or stuck jobs Feature usage (e.g., Download Catalog) Counter Understands which features users actually use\u2014great for product insights File upload sizes Distribution Summary Monitors payload size trends\u2014useful for spotting anomalies or enforcing limits Third-party API failure count Counter Tracks reliability of external services\u2014helps trigger alerts or fallback mechanisms Shipping provider response times Timer Detects slow API responses\u2014useful for SLA monitoring and debugging integrations Number of background jobs in progress Gauge Shows real-time processing load\u2014helps with scaling and capacity planning Login attempts per user role Counter Helps detect suspicious patterns\u2014useful for security monitoring Email sending failures Counter Tracks delivery issues\u2014helps maintain communication reliability Product recommendation latency Timer Measures AI/ML component performance\u2014useful for UX tuning and optimization","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#custom-metrics-with-micrometer","title":"Custom Metrics with Micrometer","text":"","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#counter","title":"Counter","text":"<p>Counters are simple metrics that only increase. They are useful for counting occurrences of events, such as errors, requests, retries, etc.</p> <pre><code>private final Counter paymentFailureCounter;\n\npublic PaymentService(MeterRegistry meterRegistry) {\n    this.paymentFailureCounter = Counter.builder(\"payment.failures\")\n            .description(\"Number of failed payment attempts\")\n            .tag(\"region\", \"DE\") // Add tags to categorize the metric\n            .register(meterRegistry);\n}\n\npublic void processPayment() {\n    try {\n        // Payment processing logic\n    } catch (Exception e) {\n        paymentFailureCounter.increment();\n    }\n}\n</code></pre> <p>Tip</p> <p>You can also use the <code>@Counted</code> annotation to automatically create counters for your methods. This is useful for tracking method calls without manually creating counters. <pre><code>@Counted(value = \"payment.failures\", description = \"Number of failed payment attempts\", \n        extraTags = {\"region\", \"DE\"}, recordFailuresOnly = true) \npublic void processPayment() {\n    // Payment processing logic\n}\n</code></pre></p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#gauge","title":"Gauge","text":"<p>Gauges are metrics that can go up or down. They are useful for measuring values that can change over time, such as the current number of active users, memory usage, etc.</p> <pre><code>public JobService(MeterRegistry meterRegistry) {\n    this.threadPoolExecutor = Executors.newFixedThreadPool(10);\n    this.userSessionManager = new UserSessionManager();\n    this.cache = new Cache();\n\n    Gauge.builder(\"thread.pool.active\", threadPoolExecutor, ThreadPoolExecutor::getActiveCount)\n            .description(\"Number of active threads in the pool\")\n            .register(meterRegistry);\n\n    Gauge.builder(\"active.users\", userSessionManager, UserSessionManager::getActiveUserCount)\n            .description(\"Current number of active users\")\n            .register(meterRegistry);\n\n    Gauge.builder(\"cache.size\", cache, Cache::size)\n            .description(\"Current number of items in the cache\")\n            .register(meterRegistry);\n\n}\n</code></pre> <p>Warning</p> <p>Use <code>Gauge</code> carefully. Micrometer uses weak references under the hood, referenced objects must remain alive, or the metric disappears silently.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#timer","title":"Timer","text":"<p>Timers are metrics that measure the duration of an event. They are useful for measuring the time taken to complete a task, such as the time taken to process a request or the time taken to execute a background job.</p> <pre><code>private final Timer paymentProcessingTimer;\n\npublic PaymentService(MeterRegistry meterRegistry) {\n    this.paymentProcessingTimer = Timer.builder(\"payment.processing.time\")\n            .description(\"Time taken to process payment\")\n            .tag(\"region\", \"DE\") // Add tags to categorize the metric\n            .register(meterRegistry);\n}\n\npublic void processPayment() {\n    paymentProcessingTimer.record(() -&gt; {\n        // Payment processing logic\n    });\n}\n</code></pre> <p>Tip</p> <p>You can also use the <code>@Timed</code> annotation to automatically create timers for your methods. This is useful for tracking method execution time without manually creating timers. <pre><code>@Timed(value = \"payment.processing.time\", description = \"Time taken to process payment\", \n        extraTags = {\"region\", \"DE\"}) \npublic void processPayment() {\n    // Payment processing logic\n}\n</code></pre></p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#timer-with-buckets-and-percentiles","title":"Timer with Buckets and Percentiles","text":"<p>Timers can be configured with custom buckets and percentiles to provide more granular insights into the performance of your application. This is particularly useful for identifying outliers and understanding the distribution of response times.</p> <pre><code>class EmailNotificationService {\n\n    private final MeterRegistry meterRegistry;\n\n    public EmailNotificationService(MeterRegistry meterRegistry) {\n        this.timedEmailNotification = this.email = meterRegistry;\n        Timer.builder(\"journey.notification.email.timed\")\n                .description(\"Time taken to send email notification\")\n                .publishPercentileHistogram() // Optional histogram\n                .publishPercentiles(0.5, 0.95, 0.99) // Optional percentiles\n                .serviceLevelObjectives( // Optional service level objectives\n                        Duration.ofMillis(100),\n                        Duration.ofMillis(300),\n                        Duration.ofMillis(500),\n                        Duration.ofSeconds(1),\n                        Duration.ofSeconds(2)\n                )\n                .register(meterRegistry);\n    }\n\n    public void sendEmail(String notificationText) {\n        timedEmailNotification.record(() -&gt; sendEmail(notificationText));\n    }\n}\n</code></pre> <p>Percentiles (e.g., 50th, 95th, 99th) track the spread of execution times, while buckets group data into predefined time ranges (e.g., &lt; 100 ms, &lt; 500 ms). Together, they help monitor performance and highlight slow operations.</p> <p>Warning</p> <p>Be cautious with the number of buckets and percentiles you use. Too many can lead to high memory usage and performance degradation.</p> <p>Tip</p> <p>You can also use the <code>@Timed</code> annotation with custom buckets and percentiles. <pre><code>@Timed(value = \"journey.notification.email.timed\", description = \"Time taken to send email notification\", extraTags = {\"type\", \"email\"}, percentiles = {0.5, 0.95}, histogram = true,\n        serviceLevelObjectives = {0.1, 0.3, 0.5, 1, 2})\npublic void sendEmail(String notificationText) {\n    // Email sending logic\n}\n</code></pre></p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#longtasktimer","title":"LongTaskTimer","text":"<p>LongTaskTimer is a special type of Micrometer timer designed for measuring tasks that take a long time to complete \u2014think seconds, minutes, or even hours.</p> <p>Unlike the standard Timer, which wraps and measures quick operations (like method calls or HTTP requests), LongTaskTimer is used when:</p> <ul> <li>You start a task at one point in time and stop it later.</li> <li>You want to measure the duration of long-running tasks, such as background jobs or batch processing.</li> <li>You want to track the number of concurrent tasks running at any given time.</li> </ul> <pre><code>private final LongTaskTimer longTaskTimer;\n\npublic JobService(MeterRegistry meterRegistry) {\n    this.longTaskTimer = LongTaskTimer.builder(\"long_running_tasks\")\n            .description(\"Long-running tasks in progress\")\n            .register(meterRegistry);\n}\n\npublic void executeLongRunningTask() {\n    // Start the task\n    longTaskTimer.start();\n    try {\n        // Long-running task logic\n    } finally {\n        // Stop the task\n        longTaskTimer.stop();\n    }\n}\n</code></pre> <p>It Produces</p> <ul> <li><code>*_active_tasks</code>: Number of currently running tasks.</li> <li><code>*_duration_seconds</code>: Total time all active tasks have been running (in seconds).</li> </ul> <p>Warning</p> <p>LongTaskTimer is not suitable for measuring short-lived tasks. For those, use the standard Timer.</p> <p>Tip</p> <p>You can also use the <code>@Timed</code> annotation for long running tasks.</p> <pre><code>@Timed(value = \"journey.notification.email.timed\", description = \"Time taken to send email notification\", extraTags = {\"type\", \"email\"}, longTask = true)\npublic void sendEmail(String notificationText) {\n    // Email sending logic\n}\n</code></pre>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#distribution-summary","title":"Distribution Summary","text":"<p>Distribution summaries are metrics that measure the distribution of values over time. They are useful for measuring the size of requests or responses, such as the size of files uploaded or downloaded.</p> <pre><code>private final DistributionSummary fileUploadSizeSummary;\n\npublic FileUploadService(MeterRegistry meterRegistry) {\n    this.fileUploadSizeSummary = DistributionSummary.builder(\"file.upload.size\")\n            .description(\"Size of uploaded files\")\n            .baseUnit(\"bytes\") // Specify the base unit for the metric\n            .publishPercentileHistogram() // Optional histogram\n            .publishPercentiles(0.5, 0.95, 0.99) // Optional percentiles\n            .register(meterRegistry);\n}\n\npublic void uploadFile(MultipartFile file) {\n    // File upload logic\n    fileUploadSizeSummary.record(file.getSize());\n}\n</code></pre> <p>Warning</p> <p>As with Timer, be mindful with histograms and SLOs\u2014too many buckets can lead to high cardinality, affecting performance and scraping efficiency in Prometheus.</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#function-based-metrics","title":"Function-based metrics","text":"<p>Function-based metrics in Micrometer allow you to bind live values from your application state without manually updating the metric. Unlike counters or timers that require you to increment or record manually, function-based metrics reflect values pulled directly from an object or function at collection time. Micrometer uses a getter function you supply, which is polled each time metrics are scraped. The value it returns becomes the metric's current value.</p> <p>This is especially useful for monitoring internal states like the size of a queue, number of items in a cache, or even memory used by a custom object.</p> <pre><code>@Component\npublic class OrderQueue {\n\n    private final BlockingQueue&lt;Order&gt; queue = new LinkedBlockingQueue&lt;&gt;();\n\n    public OrderQueue(MeterRegistry registry) {\n        Gauge.builder(\"order.queue.size\", queue, BlockingQueue::size)\n                .description(\"Current number of orders in the processing queue\")\n                .register(registry);\n    }\n\n    public void add(Order order) {\n        queue.offer(order);\n    }\n\n    public Order poll() {\n        return queue.poll();\n    }\n}\n</code></pre> <p>Warning</p> <ul> <li>Function-based metrics are not suitable for high-frequency updates.</li> <li>They are best used for values that change less frequently or are expensive to compute. </li> <li>Don\u2019t use them to model event frequency\u2014use counters or timers for that.</li> <li>Avoid expensive computations in the getter function\u2014it's called every scrape cycle.</li> </ul>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#best-practices-for-custom-metrics","title":"Best Practices for Custom Metrics","text":"<ul> <li>Keep names consistent and descriptive: Prefer <code>payment_processing_duration_seconds</code> over <code>payment_duration</code>.</li> <li>Use tags wisely: Tags are powerful but can lead to high cardinality if not used carefully. High cardinality can   lead to performance issues and make it difficult to analyze your metrics. Avoid using user IDs, emails, or dynamic   values as tags. Instead, use static values that are relevant to the metric.</li> <li>Group by business use case: When creating metrics, think about how they will be used. For example, a metric like   <code>inventory_sync_failures</code> is more useful than <code>background_job_errors</code>.</li> <li>Choose sensible buckets for timers and histograms: When configuring Prometheus, choose buckets that make sense for   your application. For example, if you are measuring response times, choose buckets that reflect the expected response   times for your application.</li> <li>Use labels for dimensions: Use labels to add dimensions to your metrics. For example, you can use labels to   differentiate between different environments (e.g., <code>dev</code>, <code>staging</code>, <code>prod</code>) or different versions of your   application.</li> <li>Use the right metric type for the job: Choose the right metric type for the job. For example, if you are measuring   a rate, use a meter. If you are measuring a duration, use a timer. If you are measuring a distribution, use a   histogram.</li> <li>Don\u2019t overdo it: Stick to what you\u2019ll actually monitor. Every metric has a cost.</li> </ul>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/custom-metrics.html#conclusion","title":"Conclusion","text":"<p>Custom metrics help you shift from infrastructure monitoring to business-level observability. They turn your metrics into a living dashboard of how your system is really behaving\u2014at runtime, in production, under a real load.</p> <p>They're lightweight, powerful, and when used wisely, one of the most developer-friendly ways to stay ahead of problems.</p> <p>Design them with intent, and they\u2019ll become one of your app\u2019s most valuable assets.</p> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Spring Boot","Monitoring","Latest"]},{"location":"blog/contract-testing.html","title":"Automating Contract Testing: A Developer\u2019s Guide with Spring Cloud Contract","text":"","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#introduction","title":"Introduction","text":"<p>In Microservices architecture, seamless communication between services is essential. As systems grow in complexity, traditional integration testing often struggles to catch issues early. This is where Contract Testing becomes invaluable.</p> <p>This guide explores Spring Cloud Contract, a robust framework for implementing contract testing in Java-based microservices. Whether you're a beginner or looking to enhance your skills, you'll find practical insights, examples, and best practices to master contract testing.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#what-is-contract-testing","title":"What is Contract Testing?","text":"<p>Contract Testing is a testing approach that focuses on verifying the interactions between service providers and consumers. It ensures that both parties adhere to the agreed-upon behavior, reducing integration issues and improving collaboration, even when developed independently.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#why-spring-cloud-contract","title":"Why Spring Cloud Contract?","text":"<p>Spring Cloud Contract simplifies contract testing by providing a full-fledged framework to define, verify, and share contracts between service providers and consumers.</p> <p>Key features of Spring Cloud Contract include:</p> <ul> <li>Automation: Automatically generates tests and stubs from contracts, saving time and effort.</li> <li>Consumer-Driven Contracts: Supports a consumer-first approach, ensuring APIs meet consumer expectations.</li> <li>Stubbing: Generates stubs for service providers, allowing consumers to test against a mocked version of the API.</li> <li>Integration with Spring: Seamlessly integrates with Spring Boot and other Spring projects, making it easy to adopt   in existing applications.</li> <li>Flexibility: Supports multiple contract formats, including Java, Groovy DSL and YAML, catering to different team   preferences.</li> <li>CI/CD Friendly: Easily integrates into CI/CD pipelines, enabling continuous verification of contracts.</li> </ul>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#how-contract-testing-works","title":"How Contract Testing Works ?","text":"<p>Spring Cloud Contract ensures seamless contract testing by automating the verification of interactions between service providers and consumers.</p> <p>Here's the workflow:</p> <pre><code>\nsequenceDiagram\n    participant Provider as Provider Service\n    participant Artifactory as Artifactory\n    participant Consumer as Consumer Service\n\n    Provider-&gt;&gt;Provider: Define Contracts (YAML/Groovy DSL)\n    Provider-&gt;&gt;Provider: Generate Tests from Contracts\n    Provider-&gt;&gt;Provider: Run Tests to Verify Contracts\n    Provider-&gt;&gt;Provider: Generate Stubs\n    Provider-&gt;&gt;Artifactory: Publish Stubs\n    Consumer-&gt;&gt;Artifactory: Fetch Stubs\n    Consumer-&gt;&gt;Consumer: Test Integration with Stubs</code></pre> <ul> <li>Define Contracts: Write contracts in Groovy DSL or YAML format specifying request-response expectations.</li> <li>Generate Tests: Spring Cloud Contract generates provider-side tests from the contracts.</li> <li>Run Tests: Execute the generated tests to ensure the provider adheres to the contract.</li> <li>Generate Stubs: Stubs are created for consumers to simulate provider behavior.</li> <li>Publish Stubs: The provider publishes the generated stubs to an artifact repository.</li> <li>Fetch Stubs: The consumer fetches the stubs from the artifact repository.</li> <li>Consumer Testing: Consumers use the stubs to test their integration without relying on the actual provider.</li> </ul>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#provider-service","title":"Provider Service","text":"","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#project-setup","title":"Project Setup","text":"<p>To get started with Spring Cloud Contract, you need to configure your project with the necessary dependencies and plugins. Below is a step-by-step guide to set up your project.</p> <p>1. Add Maven Dependencies</p> <p>Include the Spring Cloud Contract dependencies in your pom.xml file. These dependencies provide the core functionality for contract testing.</p> <pre><code>&lt;project&gt;\n    ...\n    &lt;properties&gt;\n        &lt;spring-cloud-contract.version&gt;4.2.1&lt;/spring-cloud-contract.version&gt;\n    &lt;/properties&gt;\n    ...\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-contract.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-cloud-starter-contract-verifier&lt;/artifactId&gt;\n        &lt;version&gt;${spring-cloud-contract.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/project&gt;\n</code></pre> <p>2. Configure the Spring Cloud Contract Plugin</p> <p>Add the Spring Cloud Contract Maven plugin to your <code>pom.xml</code>. This plugin is responsible for generating test classes and stubs from your contract files.</p> <pre><code>&lt;build&gt;\n    &lt;plugins&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-contract-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;${spring-cloud-contract.version}&lt;/version&gt;\n            &lt;extensions&gt;true&lt;/extensions&gt;\n            &lt;configuration&gt;\n                &lt;baseClassForTests&gt;com.github.nramc.dev.journey.api.JourneyApiContractBase&lt;/baseClassForTests&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <p>Note</p> <p>Please refer to the Spring Cloud Contract Maven Plugin to know more about the configuration options available for the plugin.</p> <p>3. Define a Base Test Class</p> <p>Create a base test class for your contract tests. This class will set up the necessary context for your tests and configure RestAssured to use the Spring Web Application context.</p> <pre><code>package com.github.nramc.dev.journey.api;\n\nimport com.github.nramc.dev.journey.api.config.TestContainersConfiguration;\nimport io.restassured.module.mockmvc.RestAssuredMockMvc;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.context.annotation.Import;\nimport org.springframework.test.context.ActiveProfiles;\nimport org.springframework.web.context.WebApplicationContext;\n\n@SpringBootTest(classes = {JourneyApiApplication.class})\n@Import(TestContainersConfiguration.class)\n@ActiveProfiles(\"test\")\n// Suppressing the warning for the test class as public visibility is required for contract tests\n@SuppressWarnings(\"java:S5786\")\npublic class JourneyApiContractBase {\n    @Autowired\n    WebApplicationContext context;\n\n    @BeforeEach\n    void setup() {\n        RestAssuredMockMvc.webAppContextSetup(this.context);\n    }\n}\n</code></pre> <p>Note</p> <p>The <code>JourneyApiContractBase</code> class use <code>@SpringBootTest</code> and <code>@ActiveProfiles</code> annotations to load the complete Spring application context. This is not always required to perform contract tests. We can use <code>@MockMvcTest</code> to load only the required beans for the test. In the above example, we are using <code>@SpringBootTest</code> to load the complete  application context with testcontainer to test the complete API flow.</p> <p>4. Run Maven Command</p> <p>Execute the following Maven command to generate the contract tests and stubs:</p> <pre><code>mvn clean install\n</code></pre> <p>Note: Build might fail if you have not defined any contract files. You can skip the build by using the <code>-DskipTests</code> flag.</p> <p>This will generate test classes in the <code>target/generated-test-sources/contracts</code> directory and stubs in the <code>target/stubs</code> directory.</p> <p>With this setup, your project is ready to use Spring Cloud Contract for contract testing.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#defining-contract","title":"Defining Contract","text":"<p>Contracts define the expected interactions between service providers and consumers. In Spring Cloud Contract, these contracts can be written in Groovy DSL or YAML format. They specify the request and response details for API endpoints, ensuring both parties adhere to the agreed behavior.</p> <p>1. Create the Contract File</p> <p>Contracts are typically placed in the <code>src/test/resources/contracts</code> directory. Below is an example of a contract written in YAML format for a signup API endpoint:</p> <pre><code>  request:\n    method: POST\n    url: /rest/signup\n    body:\n      \"username\": example-username@example.com\n      \"password\": Strong@password123\n      \"name\": \"John Doe\"\n    headers:\n      Content-Type: application/json\n    matchers:\n      body:\n        - path: $.['username']\n          type: by_regex\n          value: \"[a-zA-Z0-9._-]{8,20}@[a-zA-Z0-9]{3,20}\\\\.[a-zA-Z]{2,6}\"\n        - path: $.['password']\n          type: by_regex\n          value: \"(?=.*[a-z])(?=.*[A-Z])(?=.*\\\\d)(?=.*[@.#$!%*?&amp;^])[A-Za-z\\\\d@.#$!%*?&amp;]{8,50}\"\n        - path: $.['name']\n          type: by_regex\n          value: \"[a-zA-Z\\\\s]{3,50}\"\n  response:\n    status: 201\n</code></pre> <p>2. Contract File Structure</p> <ul> <li>Request: Defines the HTTP method, URL, headers, and body.</li> <li>Matchers: Validates the request body using patterns (e.g., regex).</li> <li>Response: Specifies the expected status, headers, and body.</li> </ul> <p>Tip</p> <p>Please refer to the Spring Cloud Contract's YML Schema for detailed information on the DSL syntax and available options.</p> <p>3. Organizing Contracts</p> <p>Organize contracts by grouping them into subdirectories based on functionality or API endpoints.</p> <p>For example</p> <pre><code>src/test/resources/contracts/\n    /signup/\n        - signup-contract.yaml\n        - signup-invalid-request.yaml\n    /login/\n        - login-contract.yaml\n        - login-invalid-request.yaml\n    /userinfo/\n        - userinfo-contract.yaml\n        - userinfo-invalid-request.yaml\n</code></pre> <p>By defining contracts, you ensure clear communication between services and enable automated testing of API interactions.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#generate-and-verify-tests","title":"Generate and Verify Tests","text":"<p>Once you have defined the contract files, you can generate the test classes and stub files using the Spring Cloud Contract Maven plugin. The plugin will read the contract files and generate the test classes and stub files based on the contract definitions.</p> <p>When you run the Maven command:</p> <pre><code>mvn clean install\n</code></pre> <p>It will generate the test class <code>ContractVerifierTest</code> in the <code>target/generated-test-sources/contracts</code> directory. The test class will contain the contract tests for the API endpoints defined in the contract files. The generated test class will use RestAssured to perform the API calls and assert the responses.</p> <pre><code>package com.github.nramc.dev.journey.api;\n\nimport com.github.nramc.dev.journey.api.JourneyApiContractBase;\nimport com.jayway.jsonpath.DocumentContext;\nimport com.jayway.jsonpath.JsonPath;\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.extension.ExtendWith;\nimport io.restassured.module.mockmvc.specification.MockMvcRequestSpecification;\nimport io.restassured.response.ResponseOptions;\n\nimport static org.springframework.cloud.contract.verifier.assertion.SpringCloudContractAssertions.assertThat;\nimport static org.springframework.cloud.contract.verifier.util.ContractVerifierUtil.*;\nimport static com.toomuchcoding.jsonassert.JsonAssertion.assertThatJson;\nimport static io.restassured.module.mockmvc.RestAssuredMockMvc.*;\n\n@SuppressWarnings(\"rawtypes\")\npublic class ContractVerifierTest extends JourneyApiContractBase {\n\n    @Test\n    public void validate_signup_contract() throws Exception {\n        // given:\n        MockMvcRequestSpecification request = given()\n                .header(\"Content-Type\", \"application/json\")\n                .body(\"{\\\"username\\\":\\\"example-username@example.com\\\",\\\"password\\\":\\\"Strong@password123\\\",\\\"name\\\":\\\"John Doe\\\"}\");\n\n        // when:\n        ResponseOptions response = given().spec(request)\n\n                .post(\"/rest/signup\");\n\n        // then:\n        assertThat(response.statusCode()).isEqualTo(201);\n\n    }\n}\n</code></pre>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#generate-publish-stubs","title":"Generate &amp; Publish Stubs","text":"<p>Maven build command <code>mvn install</code> will also generate stub files in <code>journey-api-web/target/stubs</code> directory for the API endpoints defined in the contract files.</p> <p>The stub files will be in JSON format and contain the request and response details for the API endpoints.</p> <p>These stub files packaged as jar files <code>journey-api-web/target/journey-api-web-1.0.1-SNAPSHOT-stubs.jar</code> and published to the artifactory repository. These stub files can then be reused by other microservices to mock API responses during testing.</p> <p>Please find below the sample stub file <code>journey-api-web/target/stubs/META-INF/com.github.nramc.dev.journey/journey-api-web/1.0.1-SNAPSHOT/mappings/signup-contract.json</code> generated for the signup API endpoint.</p> <pre><code>{\n  \"id\": \"9b4e7581-0d7c-4ba2-af50-f84efa624991\",\n  \"request\": {\n    \"urlPath\": \"/rest/signup\",\n    \"method\": \"POST\",\n    \"headers\": {\n      \"Content-Type\": {\n        \"equalTo\": \"application/json\"\n      }\n    },\n    \"bodyPatterns\": [\n      {\n        \"matchesJsonPath\": \"$[?(@.['username'] =~ /([a-zA-Z0-9]{8,20}@[a-zA-Z0-9]{3,20}\\\\.[a-zA-Z]{2,6})/)]\"\n      },\n      {\n        \"matchesJsonPath\": \"$[?(@.['password'] =~ /((?=.*[a-z])(?=.*[A-Z])(?=.*\\\\d)(?=.*[@.#$!%*?&amp;^])[A-Za-z\\\\d@.#$!%*?&amp;]{8,50})/)]\"\n      },\n      {\n        \"matchesJsonPath\": \"$[?(@.['name'] =~ /([a-zA-Z\\\\s]{3,50})/)]\"\n      }\n    ]\n  },\n  \"response\": {\n    \"status\": 201,\n    \"transformers\": [\n      \"response-template\",\n      \"spring-cloud-contract\"\n    ]\n  },\n  \"uuid\": \"9b4e7581-0d7c-4ba2-af50-f84efa624991\"\n}\n</code></pre>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#consumer-service","title":"Consumer Service","text":"<p>The consumer microservice will use the stub files generated by provider to mock the API responses. The consumer microservice will use WireMock to mock the API responses using the stub files.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#project-setup_1","title":"Project Setup","text":"<p>To set up the consumer microservice with Spring Cloud Contract, you need to add the following dependencies in your <code>pom.xml</code> file.</p> <pre><code>&lt;project&gt;\n    ...\n    &lt;properties&gt;\n        &lt;spring-cloud-contract.version&gt;4.0.0&lt;/spring-cloud-contract.version&gt;\n    &lt;/properties&gt;\n    ...\n    &lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-contract.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-cloud-starter-contract-stub-runner&lt;/artifactId&gt;\n        &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/project&gt;\n</code></pre>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#fetching-stubs","title":"Fetching Stubs","text":"<p>The stub files can be fetched from the artifactory repository using the Spring Cloud Contract Stub Runner.</p> <p>There are two modes to fetch the stub files,</p> <ol> <li>Local Mode: The stub files are downloaded from the local directory.</li> <li>Remote Mode: The stub files are downloaded from the artifactory repository.</li> </ol> <p>In this example, we will use the local mode to fetch the stub files.</p> <p>Include the stub JAR in your <code>pom.xml</code> under the test scope,</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.github.nramc.dev.journey&lt;/groupId&gt;\n    &lt;artifactId&gt;journey-api-web&lt;/artifactId&gt;\n    &lt;version&gt;${journey-api.version}&lt;/version&gt;\n    &lt;classifier&gt;stubs&lt;/classifier&gt;\n    &lt;scope&gt;test&lt;/scope&gt;\n&lt;/dependency&gt;\n</code></pre> <p>This will include the stub files in the classpath of the consumer service.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#configure-stub-runner","title":"Configure Stub Runner","text":"<p>The Stub Runner in Spring Cloud Contract allows you to fetch the stub files from the local directory or remote repository and use them to mock the API responses.</p> <p>There are various ways to configure the Stub Runner in your consumer service.</p> <p>1. Using <code>@AutoConfigureStubRunner</code> annotation</p> <p>You can use the <code>@AutoConfigureStubRunner</code> annotation to configure the Stub Runner in your test class. This will automatically download the stub files from the local directory or remote repository and use them to mock the API responses.</p> <pre><code>@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE, classes = JourneyIntegrationApplication.class)\n@ActiveProfiles(\"integration\") // application specific profile to load context\n\n@AutoConfigureStubRunner(\n        ids = \"com.github.nramc.dev.journey:journey-api-web:+:stubs:6565\",\n        stubsMode = StubRunnerProperties.StubsMode.LOCAL)\nclass JourneyApiContractsTest {\n    // Test cases will be here  \n}\n</code></pre> <p>2. Using JUnit5 Extension You can also use the <code>StubRunnerExtension</code> to configure the Stub Runner in your test class. This will allow you to configure the Stub Runner in a more flexible way and use it in your test class.</p> <pre><code>@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE, classes = JourneyIntegrationApplication.class)\n@ActiveProfiles(\"integration\") // application specific profile to load context\nclass JourneyApiContractsTest {\n\n    @RegisterExtension\n    public static StubRunnerExtension stubRunnerExtension = new StubRunnerExtension()\n            .downloadStub(\"com.github.nramc.dev.journey:journey-api-web:+:stubs:6565\")\n            .stubsMode(StubRunnerProperties.StubsMode.LOCAL);\n\n    // Test cases will be here  \n}\n</code></pre> <p>Note</p> <p>To use the remote mode, you need to set the <code>stubsMode</code> to <code>REMOTE</code> and provide the <code>repositoryRoot</code> URL. Please refer to the Spring Cloud Contract Stub Runner </p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#writing-tests","title":"Writing Tests","text":"<p>Once you have configured the Stub Runner, you can write the consumer tests using RestAssured to perform the API calls and assert the responses.</p> <pre><code>package com.github.nramc.dev.journey.api.tests.testcase.contracts;\n\nimport com.github.nramc.dev.journey.api.tests.application.JourneyIntegrationApplication;\nimport io.restassured.RestAssured;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.cloud.contract.stubrunner.spring.AutoConfigureStubRunner;\nimport org.springframework.cloud.contract.stubrunner.spring.StubRunnerProperties;\nimport org.springframework.test.context.ActiveProfiles;\n\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE, classes = JourneyIntegrationApplication.class)\n@ActiveProfiles(\"integration\") // application specific profile to load context\n\n@AutoConfigureStubRunner(\n        ids = \"com.github.nramc.dev.journey:journey-api-web:+:stubs:6565\",\n        stubsMode = StubRunnerProperties.StubsMode.LOCAL)\nclass JourneyApiContractsTest {\n\n    @Test\n    void signup_whenSignupDataValid_shouldReturnSuccess() {\n        RestAssured.given()\n                .port(6565)\n                .contentType(\"application/json\")\n                .accept(\"application/json\")\n                .body(\"\"\"\n                        {\"username\":\"username@example.com\", \"password\":\"Strong@password123\", \"name\":\"John Doe\"}\n                        \"\"\")\n                .post(\"/rest/signup\")\n                .then()\n                .statusCode(201);\n    }\n}\n</code></pre>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#running-the-tests","title":"Running the Tests","text":"<p>To run the tests, you can use the following command:</p> <pre><code>mvn clean test\n</code></pre> <p>This will run the tests in the <code>JourneyApiContractsTest</code> class and use the stub files to mock the API responses.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#conclusion","title":"Conclusion","text":"<p>In this guide, we explored the fundamentals of contract testing and how to implement it using Spring Cloud Contract.</p> <p>Contract testing is a game-changer in microservices architecture, ensuring seamless communication between services. By automating contract testing, you can catch integration issues early, improve collaboration between teams, and enhance the overall quality of your software.</p> <p>You can further enhance your testing strategy by combining contract testing with API schema validation or integrating it into your CI/CD pipeline for continuous feedback.</p> <p>Strong contracts build strong microservices.</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/contract-testing.html#references","title":"References","text":"<ul> <li>Spring Cloud Contract</li> <li>Spring Cloud Contract Maven Plugin</li> <li>WireMock</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Spring Boot","Testing","Automation","Latest"]},{"location":"blog/junit-extension-conditional-execution.html","title":"Conditionally Registering JUnit 5 Extensions","text":"<p>TL;DR: JUnit 5 extensions can be registered statically with @ExtendWith or dynamically with @RegisterExtension , but both have drawbacks. @ExtendWith applies extensions unconditionally, while @RegisterExtension requires manual instantiation and lacks centralized control. A custom conditional extension resolver enables dynamic registration based on Spring profiles, environment variables, feature flags and so on, keeping test setups clean and efficient. By Using a custom annotation (e.g. @ExtendWithProfileCondition), extensions load only when needed and improve test flexibility and maintainability.</p>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#introduction","title":"Introduction","text":"<p>JUnit 5 provides a powerful extension model that allows developers to customize test execution. While extensions can be registered globally using <code>@ExtendWith</code>, there are cases where you might want to conditionally register an extension based on specific criteria, such as the active Spring profile, an environment variable, feature flags and so on.</p> <p>In this article, we explore how to conditionally register JUnit 5 extensions dynamically, focusing on a reusable approach that allows easy integration of any new conditions.</p>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#understanding-junit-5-extensions","title":"Understanding JUnit 5 Extensions","text":"<p>JUnit 5 extensions allow custom behavior to be injected at different stages of test execution. Some common extension interfaces include:</p> <ul> <li><code>BeforeAllCallback</code> \u2013 Executed before all tests in a test class.</li> <li><code>BeforeEachCallback</code> \u2013 Executed before each test method.</li> <li><code>BeforeTestExecutionCallback</code> - Executed before each test method but after <code>BeforeEachCallback</code>.</li> <li><code>AfterTestExecutionCallback</code> - Executed after each test method but before <code>AfterEachCallback</code>.</li> <li><code>AfterEachCallback</code> \u2013 Executed after each test method.</li> <li><code>AfterAllCallback</code> \u2013 Executed after all tests in a test class.</li> </ul> <p>Registering Extensions Using <code>@ExtendWith</code></p> <p>By default, JUnit registers extensions using:</p> <pre><code>@ExtendWith(MyExtension.class)\nclass MyTestClass {\n    // continue with test methods\n}\n</code></pre> <p>The <code>@ExtendWith</code> annotation is a static mechanism for registering extensions. It applies extensions * unconditionally*, meaning the extensions are always loaded and executed, regardless of the test execution context. This can lead to:</p> <ul> <li>Unnecessary resource consumption if the extension is not always needed.</li> <li>Inefficient Test execution due to redundant extensions being loaded.</li> <li>Reduced flexibility, as conditions cannot be applied dynamically.</li> </ul> <p>Registering Extensions Using <code>@RegisterExtension</code></p> <p>JUnit 5 also provides an alternative way to register extensions conditionally at run time using <code>@RegisterExtension</code>. This allows more dynamic control over the extension lifecycle within the test class:</p> <pre><code>class MyTest {\n    @RegisterExtension\n    static MyCustomExtension myCustomExtension = \"true\".equals(System.getenv(\"USE_CUSTOM_EXTENSION\")) ? new MyCustomExtension() : MyCustomExtension.NO_OP;\n    // continue with test methods\n}\n</code></pre> <p><code>@RegisterExtension</code> provides more flexibility by allowing extensions to be defined as instance variables, but it still has limitations:</p> <ul> <li>While this approach works for simple conditions, it becomes problematic with more complex conditions, such as managing   Spring profiles or feature toggles.</li> <li>The Conditions often require runtime evaluation, which cannot be easily handled at   class initialization.</li> <li>Extensions are still instantiated even if they are not needed for a specific test execution.</li> <li>The logic for enabling/disabling extensions based on runtime conditions has to be implemented within the test class   , leading to duplication across multiple test classes.</li> </ul>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#designing-a-conditional-extension-resolver","title":"Designing a Conditional Extension Resolver","text":"<p>To toggle the above-mentioned limitations, custom solution provides:</p> <ul> <li>Dynamic extension registration based on conditions.</li> <li>Centralized logic, keeping test classes clean.</li> <li>Reusable condition evaluators, making it easy to introduce new conditions (e.g., Spring profiles, environment   variables, feature flags, system properties, so on.).</li> </ul> <p>We can create a generic resolver that allows executing extensions conditionally based on the test context.</p> <p>Implement abstract conditional extension resolver</p> <p>We define an abstract conditional extension resolver that listens to JUnit lifecycle callbacks and delegates handling to subclasses:</p> <pre><code>public abstract class AbstractConditionalExtensionResolver implements BeforeAllCallback, BeforeEachCallback, BeforeTestExecutionCallback, AfterTestExecutionCallback, AfterEachCallback, AfterAllCallback {\n\n    public abstract void handler(ExtensionContext context, Class&lt;? extends Extension&gt; callbackClass);\n\n    @Override\n    public void beforeAll(ExtensionContext context) {\n        handler(context, BeforeAllCallback.class);\n    }\n\n    @Override\n    public void beforeEach(ExtensionContext context) {\n        handler(context, BeforeEachCallback.class);\n    }\n\n    @Override\n    public void beforeTestExecution(ExtensionContext context) {\n        handler(context, BeforeTestExecutionCallback.class);\n    }\n\n    @Override\n    public void afterTestExecution(ExtensionContext context) {\n        handler(context, AfterTestExecutionCallback.class);\n    }\n\n    @Override\n    public void afterEach(ExtensionContext context) {\n        handler(context, AfterEachCallback.class);\n    }\n\n    @Override\n    public void afterAll(ExtensionContext context) {\n        handler(context, AfterAllCallback.class);\n    }\n\n    protected void invokeExtensionsIfApplicable(ExtensionContext context, Class&lt;? extends Extension&gt;[] extensions, Class&lt;? extends Extension&gt; targetExtensionType) {\n        Arrays.stream(extensions).filter(targetExtensionType::isAssignableFrom).forEach(extensionClass -&gt; {\n            try {\n                Extension extensionInstance = extensionClass.getDeclaredConstructor().newInstance();\n                switch (extensionInstance) {\n                    case BeforeAllCallback callback -&gt; callback.beforeAll(context);\n                    case BeforeEachCallback callback -&gt; callback.beforeEach(context);\n                    case BeforeTestExecutionCallback callback -&gt; callback.beforeTestExecution(context);\n                    case AfterTestExecutionCallback callback -&gt; callback.afterTestExecution(context);\n                    case AfterEachCallback callback -&gt; callback.afterEach(context);\n                    case AfterAllCallback callback -&gt; callback.afterAll(context);\n                    default -&gt; log.warn(\"Unsupported extension: {}\", extensionClass);\n                }\n            } catch (Exception ex) {\n                throw new RuntimeException(\"Failed to instantiate and invoke extension: \" + extensionClass, ex);\n            }\n        });\n    }\n\n}\n</code></pre> <ul> <li>The <code>handler()</code> method must be implemented by custom resolvers to evaluate conditions and register extensions   dynamically.</li> </ul>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#resolver-for-spring-profiles","title":"Resolver for Spring Profiles","text":"<p>Define the conditional extension annotation The Custom annotation <code>@ExtendWithProfileCondition</code> is used to specify the profiles and extensions to be registered based on the active Spring profiles:</p> <pre><code>@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.METHOD, ElementType.TYPE})\n@ExtendWith(ExtendWithProfileConditionResolver.class)\npublic @interface ExtendWithProfileCondition {\n\n    String[] profiles() default {};\n\n    Class&lt;? extends Extension&gt;[] extensions() default {};\n}\n</code></pre> <p>Implement the Conditional Extension Resolver</p> <p>The resolver checks the specified spring profiles and activates the extensions only if the active profiles match with any of the specified profiles:</p> <pre><code>@Slf4j\npublic class ExtendWithProfileConditionResolver extends AbstractConditionalExtensionResolver {\n\n    @Override\n    public void handler(ExtensionContext context, Class&lt;? extends Extension&gt; callbackClass) {\n        Stream.of(context.getTestClass(), context.getTestMethod())\n                .flatMap(Optional::stream)\n                .map(element -&gt; element.getAnnotation(ExtendWithProfileCondition.class))\n                .filter(Objects::nonNull)\n                .forEach(annotation -&gt; evaluateConditionAndInvokeExtensions(context, annotation, callbackClass));\n    }\n\n    private void evaluateConditionAndInvokeExtensions(ExtensionContext context, ExtendWithProfileCondition extendWith, Class&lt;? extends Extension&gt; targetExtensionType) {\n        if (evaluateCondition(context, extendWith)) {\n            log.debug(\"Condition met for profile:[{}] Registering extensions:[{}]\", Arrays.toString(extendWith.profiles()), extendWith.extensions());\n            invokeExtensionsIfApplicable(context, extendWith.extensions(), targetExtensionType);\n        } else {\n            log.debug(\"Condition not met for profile:[{}]. Skipping extensions.\", Arrays.toString(extendWith.profiles()));\n        }\n    }\n\n    private boolean evaluateCondition(ExtensionContext context, ExtendWithProfileCondition extendWith) {\n        Environment environment = SpringExtension.getApplicationContext(context).getEnvironment();\n        return ArrayUtils.isEmpty(extendWith.profiles()) ||\n                Arrays.stream(environment.getActiveProfiles()).anyMatch(profile -&gt; ArrayUtils.contains(extendWith.profiles(), profile));\n    }\n\n}\n</code></pre> <p>Use the Conditional Extension Registration in Tests</p> <p>Now, we can use the <code>@ExtendWithProfileCondition</code> annotation to conditionally register extensions based on the active Spring profiles:</p> <pre><code>@ExtendWithProfileCondition(profiles = \"dev\", extensions = {MyBeforeEachExtension.class, MyBeforeAllExtension.class})\n@ExtendWith(SpringExtension.class)\n@ActiveProfiles(\"dev\")\nclass MyConditionalTest {\n\n    @Test\n    void myTestCase1() {\n        System.out.println(\"MyBeforeEachExtension &amp; MyBeforeAllExtension executed only when spring profile 'dev' activated!\");\n    }\n\n    @Test\n    @ExtendWithProfileCondition(profiles = {\"prod\", \"dev\"}, extensions = {MyBeforeEachMethodExtension.class})\n    void myTestCase2() {\n        System.out.println(\"MyBeforeEachMethodExtension executed only when spring profile either 'dev' or 'prod' activated!\");\n    }\n\n    @Test\n    @ExtendWithProfileCondition(profiles = \"dev\", extensions = {MyBeforeTestMethodExtension.class})\n    void myTestCase3() {\n        System.out.println(\"MyBeforeTestMethodExtension executed only when spring profile 'dev' activated!\");\n    }\n}\n</code></pre>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#resolver-for-env-variables","title":"Resolver for Env Variables","text":"<p>Define the conditional extension annotation</p> <p>The Custom annotation <code>@ExtendWithEnvCondition</code> is used to specify the environment variables and extensions to be registered based on the active environment variables:</p> <pre><code>@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.METHOD, ElementType.TYPE})\n@ExtendWith(ExtendWithEnvConditionResolver.class)\npublic @interface ExtendWithEnvCondition {\n\n    String[] variables() default {};\n\n    Class&lt;? extends Extension&gt;[] extensions() default {};\n}\n</code></pre> <p>Implement the Conditional Extension Resolver</p> <p>The resolver checks the specified environment variables and activates the extensions only if the active environment variables match with any of the specified environment variables:</p> <pre><code>@Slf4j\npublic class ExtendWithEnvConditionResolver extends AbstractConditionalExtensionResolver {\n\n    @Override\n    public void handler(ExtensionContext context, Class&lt;? extends Extension&gt; callbackClass) {\n        Stream.of(context.getTestClass(), context.getTestMethod())\n                .flatMap(Optional::stream)\n                .map(element -&gt; element.getAnnotation(ExtendWithEnvironmentVariableCondition.class))\n                .filter(Objects::nonNull)\n                .forEach(annotation -&gt; evaluateConditionAndInvokeExtensions(context, annotation, callbackClass));\n    }\n\n    private void evaluateConditionAndInvokeExtensions(ExtensionContext context, ExtendWithEnvironmentVariableCondition extendWith, Class&lt;? extends Extension&gt; targetExtensionType) {\n        if (evaluateCondition(extendWith)) {\n            log.debug(\"Condition met for env variables:[{}] Registering extensions:[{}]\", Arrays.toString(extendWith.variables()), extendWith.extensions());\n            invokeExtensionsIfApplicable(context, extendWith.extensions(), targetExtensionType);\n        } else {\n            log.debug(\"Condition not met for env variables:[{}]. Skipping extensions.\", Arrays.toString(extendWith.variables()));\n        }\n    }\n\n    private boolean evaluateCondition(ExtendWithEnvironmentVariableCondition extendWith) {\n        if (ArrayUtils.isEmpty(extendWith.variables())) {\n            return true;\n        }\n\n        return Arrays.stream(extendWith.variables())\n                .map(variable -&gt; variable.split(\"=\"))\n                .anyMatch(keyValueEntry -&gt; System.getenv(keyValueEntry[0]).equals(keyValueEntry[1]));\n    }\n\n}\n</code></pre> <p>Use the Conditional Extension Registration in Tests</p> <p>Now, we can use the <code>@ExtendWithEnvCondition</code> annotation to conditionally register extensions based on the active environment variables:</p> <pre><code>@ExtendWithEnvCondition(variables = {\"ENV_TEST_TYPE=SMOOTH\", \"ENV_TEST_TYPE=ROUGH\"}, extensions = {MyBeforeEachExtension.class, MyBeforeAllExtension.class})\nclass MyConditionalTest {\n\n    @Test\n    void myTestCase1() {\n        System.out.println(\"MyBeforeEachExtension &amp; MyBeforeAllExtension executed only when environment variable ENV_TEST_TYPE either 'SMOOTH' or 'ROUGH'\");\n    }\n\n    @Test\n    @ExtendWithEnvCondition(variables = {\"ENV_TEST_TYPE=SMOOTH\"}, extensions = {MyBeforeEachMethodExtension.class})\n    void myTestCase2() {\n        System.out.println(\"MyBeforeEachMethodExtension executed only when env variable ENV_TEST_TYPE is 'SMOOTH'\");\n    }\n\n    @Test\n    @ExtendWithEnvCondition(variables = {\"ENV_TEST_TYPE=ROUGH\"}, extensions = {MyBeforeEachMethodExtension.class})\n    void myTestCase3() {\n        System.out.println(\"MyBeforeEachMethodExtension executed only when env variable ENV_TEST_TYPE is 'ROUGH'\");\n    }\n}\n</code></pre>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#resolver-for-feature-flags","title":"Resolver for Feature Flags","text":"<p>Define the conditional extension annotation</p> <p>The Custom annotation <code>@ExtendWithFeatureFlagCondition</code> is used to specify the feature flags and extensions to be registered based on the active feature flags:</p> <pre><code>@Retention(RetentionPolicy.RUNTIME)\n@Target({ElementType.METHOD, ElementType.TYPE})\n@ExtendWith(ExtendWithFeatureFlagConditionResolver.class)\npublic @interface ExtendWithFeatureFlagCondition {\n\n    String[] property() default {};\n\n    Class&lt;? extends Extension&gt;[] extensions() default {};\n}\n</code></pre> <p>Implement the Conditional Extension Resolver</p> <p>The resolver checks the specified feature flags and activates the extensions only if the feature flags are enabled, i.e., the property value is true:</p> <p>Note: Below implementation uses Spring application context. If you are not using Spring, you can replace it with your own implementation to get the environment properties.</p> <pre><code>@Slf4j\npublic class ExtendWithFeatureFlagConditionResolver extends AbstractConditionalExtensionResolver {\n\n    @Override\n    public void handler(ExtensionContext context, Class&lt;? extends Extension&gt; callbackClass) {\n        Stream.of(context.getTestClass(), context.getTestMethod())\n                .flatMap(Optional::stream)\n                .map(element -&gt; element.getAnnotation(ExtendWithFeatureFlagCondition.class))\n                .filter(Objects::nonNull)\n                .forEach(annotation -&gt; evaluateConditionAndInvokeExtensions(context, annotation, callbackClass));\n    }\n\n    private void evaluateConditionAndInvokeExtensions(ExtensionContext context, ExtendWithFeatureFlagCondition extendWith, Class&lt;? extends Extension&gt; targetExtensionType) {\n        if (evaluateCondition(context, extendWith)) {\n            log.debug(\"Condition met for feature:[{}] Registering extensions:[{}]\", Arrays.toString(extendWith.property()), extendWith.extensions());\n            invokeExtensionsIfApplicable(context, extendWith.extensions(), targetExtensionType);\n        } else {\n            log.debug(\"Condition not met for feature:[{}]. Skipping extensions.\", Arrays.toString(extendWith.property()));\n        }\n    }\n\n    private boolean evaluateCondition(ExtensionContext context, ExtendWithFeatureFlagCondition extendWith) {\n        if (ArrayUtils.isEmpty(extendWith.property())) {\n            return true;\n        }\n\n        Environment environment = SpringExtension.getApplicationContext(context).getEnvironment();\n        return Arrays.stream(extendWith.property())\n                .anyMatch(property -&gt; environment.getProperty(property, Boolean.class, false));\n    }\n\n}\n</code></pre> <p>Use the Conditional Extension Registration in Tests</p> <p>Now, we can use the <code>@ExtendWithFeatureFlagCondition</code> annotation to conditionally register extensions based on the active feature:</p> <pre><code>@ExtendWith(SpringExtension.class)\n@TestPropertySource(properties = {\"feature.one.enabled=true\", \"feature.two.enabled=true\"})\n@ExtendWithFeatureFlagCondition(property = {\"feature.one.enabled\", \"feature.two.enabled\"}, extensions = {MyBeforeEachExtension.class, MyBeforeAllExtension.class})\nclass MyConditionalTest {\n\n    @Test\n    void myTestCase1() {\n        System.out.println(\"MyBeforeEachExtension &amp; MyBeforeAllExtension executed only when either feature.one or feature.two is enabled!\");\n    }\n\n    @Test\n    @ExtendWithFeatureFlagCondition(property = {\"feature.one.enabled\"}, extensions = {MyBeforeEachMethodExtension.class})\n    void myTestCase2() {\n        System.out.println(\"MyBeforeEachMethodExtension executed only when feature.one is enabled!\");\n    }\n\n    @Test\n    @ExtendWithFeatureFlagCondition(property = {\"feature.two.enabled\"}, extensions = {MyBeforeEachMethodExtension.class})\n    void myTestCase3() {\n        System.out.println(\"MyBeforeEachMethodExtension executed only when feature.two is enabled!\");\n    }\n}\n</code></pre>","tags":["Java","Testing","JUnit"]},{"location":"blog/junit-extension-conditional-execution.html#conclusion","title":"Conclusion","text":"<p>By implementing a generic conditional extension resolver, we gain the flexibility to apply extensions based on a variety of runtime conditions. This approach keeps our test setup clean, reusable, and extensible, ensuring that extensions are only applied when necessary.</p> <p>This method can be expanded further easily to support:</p> <ul> <li>System properties (<code>System.getProperty()</code>)</li> <li>Application Configuration Properties</li> <li>Test Profiles</li> <li>Operating System</li> <li>User Role</li> <li>Resource Availability</li> <li>Time of Day</li> <li>Custom database or API checks</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Testing","JUnit"]},{"location":"blog/shift-left-testing-with-springboot.html","title":"Shift-Left Testing with Spring Boot and Testcontainers: A Comprehensive Guide","text":"<p>TL;DR: Shift-Left Testing is a software testing approach that emphasizes testing early in the development lifecycle. With Spring Boot and Testcontainers, developers can detect integration issues early by running tests in isolated environments during local development and CI/CD\u2014instead of waiting for QA deployments. This approach ensures seamless service interactions, faster feedback, and more reliable releases, reducing late-stage surprises and improving software quality.</p> <p>Inspiration &amp; Credits: Shift-Left Testing with Testcontainers: Catching Bugs Early with Local Integration Tests</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#introduction","title":"Introduction","text":"<p>In modern software development, testing early and often is crucial for delivering high-quality applications. Shift-Left Testing is a practice that emphasizes testing as early as possible in the software development lifecycle. By catching bugs early, teams can reduce costs, improve code quality, and speed up delivery cycles.</p> <p>Spring Boot, with its test-friendly ecosystem, is well-suited for implementing Shift-Left Testing. Additionally, Testcontainers, a library for providing lightweight, disposable containers for testing, enhances integration and end-to-end testing by allowing developers to run real dependencies like databases, message brokers, and other external services in a controlled environment.</p> <p>In this article, we\u2019ll explore how Spring Boot and Testcontainers help implement Shift-Left Testing efficiently.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#understanding-shift-left-testing","title":"Understanding Shift-Left Testing","text":"","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#what-is-shift-left-testing","title":"What is Shift-Left Testing?","text":"<p>Shift-Left Testing is a software testing approach that emphasizes testing early in the development lifecycle. By moving testing activities to the left (i.e., earlier in the process), teams can identify and fix issues sooner, reducing the risk of defects reaching production.</p> <p>To know more about Shift-Left Testing, read this comprehensive guide.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#why-shift-left-testing-matters","title":"Why Shift-Left Testing Matters?","text":"<p>Traditional integration, security and performance testing often happen late in the software development lifecycle (e.g., after deployment to a staging or QA environment). This can lead to:</p> <p>\u274c Late discovery of critical bugs \u274c High cost of fixing defects \u274c Delays in delivery</p> <p>By applying shift-left testing with SpringBoot and Testcontainers, you create a production-like testing environment earlier in development, reducing surprises later.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#benefits-of-shift-left-testing","title":"Benefits of Shift-Left Testing?","text":"<p>\u2705 Early Bug Detection \u2013 Catching bugs early in development reduces the cost of fixing them later.</p> <p>\u2705 Faster Feedback Loops \u2013 Developers get immediate feedback on code changes, enabling faster iterations.</p> <p>\u2705 Improved Code Quality \u2013 By testing early and often, teams can deliver more reliable software.</p> <p>\u2705 Reduced Time to Market \u2013 Faster testing cycles lead to quicker delivery of features and bug fixes.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#with-testcontainers","title":"With Testcontainers","text":"<p>Testcontainers is a Java library that enables developers to run real dependencies in Docker containers within their test environment. This eliminates the need for in-memory databases and local installations of services like PostgresSQL, Redis, Kafka, or Elasticsearch.</p> <p>Testcontainers helps to bring integration testing closer to the development phase by:</p> <p>\u2705 Providing Realistic Testing Environments \u2013 Instead of relying on in-memory databases (e.g., H2) or mocked services, Testcontainers allow you to spin up actual services (PostgresSQL, Kafka, Redis, etc.), mirroring production.</p> <p>\u2705 Reducing Environment-Related Bugs \u2013 Since tests run against real containers, they catch issues related to configurations, dependencies, and network interactions early.</p> <p>\u2705 Ensuring Consistency Across Environments \u2013 By using the same image in local development, CI/CD pipelines, and QA environments, you maintain consistency and reduce surprises.</p> <p>\u2705 Enhancing End-to-End Testing \u2013 Testcontainers can be used to test end-to-end scenarios involving multiple services, databases, and external dependencies in isolated environment.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#with-spring-boot","title":"With Spring Boot","text":"<p>Spring Boot is a popular Java framework that simplifies the development of standalone, production-ready applications.</p> <p>Key features that support Shift-Left Testing include:</p> <p>\ud83c\udf1f Test-Friendly Ecosystem \u2013 Spring Boot provides robust support for writing unit, integration, and end-to-end tests.</p> <p>\ud83c\udf1f Dependency Injection \u2013 Spring\u2019s dependency injection mechanism allows you to mock or replace dependencies for testing.</p> <p>\ud83c\udf1f Integration with JUnit, TestNG and Cucumber \u2013 Spring Boot integrates seamlessly with popular testing frameworks, enabling you to write and run tests easily.</p> <p>\ud83c\udf1f Profile Management \u2013 Spring profiles help manage different configurations for development, testing, and production.</p> <p>\ud83c\udf1f Externalized Configuration \u2013 Spring Boot\u2019s externalized configuration allows you to configure applications using properties files, YAML files, environment variables, etc.</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#shift-left-testing-strategy","title":"Shift-Left Testing Strategy","text":"<p>Disclaimer: This strategy focuses exclusively on integration testing and end-to-end testing. It does not cover unit testing approaches.</p> <p>You can define a test suite for your Spring Boot application that covers all possible use cases and scenarios. This test suite can be run at different stages of the development lifecycle:</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#1-local-development-testing","title":"1. Local Development Testing","text":"<pre><code>graph LR;\n    A[Local Development] --&gt; |Add new feature|B(Tests run locally);\n    B --&gt; |Immediate feedback on code changes|A;\n    B --&gt; |Tests pass| D[Ready for commit];</code></pre> <ul> <li>Developers write integration tests using Testcontainers to validate the application\u2019s interactions with external   services.</li> <li>Testcontainers spin up real dependencies (e.g., databases, message brokers) in Docker containers.</li> <li>Tests run locally to catch issues early in the development process.</li> <li>Developers receive immediate feedback on code changes.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#2-cicd-integration-testing","title":"2. CI/CD Integration Testing","text":"<pre><code>graph LR;\n    A(Developer) --&gt;|committed code| B(Tests run in CICD pipeline);\n    B --&gt;|Feedback on integration issues| A;\n    B --&gt;|Tests pass| C(Ready for merge);</code></pre> <ul> <li>CI/CD pipelines execute the same integration tests against a Testcontainers-based environment.</li> <li>Tests run automatically on every code commit, ensuring consistent behavior across environments.</li> <li>Developers receive feedback on the integration of new code with existing services.</li> <li>Issues are caught early before merging changes into the main branch.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#3-qastaging-testing","title":"3. QA/Staging Testing","text":"<pre><code>graph LR;\n    A(Feature deployed to QA) --&gt; B(Tests executed in QA environment);\n    B --&gt;|Real-world readiness|C(Tests validate application stability);\n    B --&gt;|QA teams focus on higher-level testing|C;\n    B --&gt;|Tests pass|D(Ready for production deployment);\n</code></pre> <ul> <li>After passing integration tests, the same test suite is executed against the deployed QA environment.</li> <li>Tests validate real-world readiness and ensure that the application behaves as expected in a production-like   environment.</li> <li>QA teams can focus on higher-level testing (e.g., user acceptance testing) with confidence in the application\u2019s   stability.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#challenges-solutions","title":"Challenges &amp; Solutions","text":"<p>Implementing Shift-Left Testing strategy has some real time challenges; Spring Boot with Testcontainers can help us to overcome them:</p> <ul> <li>Maintaining Test Suite Consistency: Ensuring test consistency across environments can be challenging.   Spring Boot profiles and Configurations ensure the same test used across local, CI/CD, and QA, maintaining   consistency.</li> <li>Managing Test Data Parity: Inconsistent test data can lead to unreliable results.   Testcontainers ensures that tests run against real services, maintaining data parity across environments.</li> <li>Handling External Dependencies: Testing real integrations instead of mocks can be challenging.   Testcontainers eliminates the need for mocks by providing actual services like databases, message brokers, ensuring   more realistic tests.</li> <li>Test Execution Time: As the test suite grows, waiting for feedback can delay development.   Testcontainers enables quick feedback by spinning up real services in containers, reducing the time it takes to run   tests.</li> <li>Managing Infrastructure for Testing: Setting up environments manually is time-consuming.   Testcontainers automates environment setup and teardown, ensuring a clean environment for each test and reducing   manual overhead.</li> <li>Flaky and Unstable Tests: External dependencies and dynamic environments can cause flaky tests.   Testcontainers provides stable, isolated environments, minimizing the risk of flaky tests.</li> <li>Parallel Test Execution: Running tests concurrently can cause resource conflicts if not properly isolated.   Testcontainers provides an isolated application environment (via a container) for the entire suite, ensuring tests   interact with a consistent setup without conflicting resources, even when tests run in parallel.</li> <li>Ensuring Environment Parity: Differences between environments can cause surprises. Testcontainers ensures   consistency between local, CI/CD, and QA environments by using the same containerized services.</li> <li>Database State Management: Ensuring databases are properly seeded,   cleaned up between test runs to avoid inconsistent results.   Testcontainers helps by spinning up fresh, isolated databases for each test session, ensuring a   clean state before each test and preventing data leakage between tests.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#implementation","title":"Implementation","text":"<p>Tip</p> <p>It is highly recommended to create a separate Maven module for integration and end-to-end tests. This approach helps differentiate these tests from unit tests and improves maintainability by keeping the testing code organized. It also allows you to configure and manage dependencies specific to integration testing without interfering with the unit test setup.</p> <p>Implementing Shift-Left Testing with Spring Boot and Testcontainers involves the following steps:</p> <ol> <li>Setting Up Isolated Test Environment</li> <li>Writing Test</li> <li>Running Test Locally</li> <li>Running Test in CI/CD Pipeline</li> <li>Running Test in QA Environment</li> </ol>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#1-setting-up-isolated-test-environment","title":"1. Setting Up Isolated Test Environment","text":"<p>Test environment setup is crucial for Shift-Left Testing. For a consistent test environment, Testcontainers is used to spin up real external dependencies like databases and message brokers in isolated Docker containers. For external HTTP services, WireMock simulates API interactions, enabling tests to run against realistic service behaviors without relying on third-party systems. Together, these tools ensure accurate, reproducible tests in a controlled environment.</p> <p>The following diagram illustrates the setup of an isolated test environment using Spring Boot, Testcontainers, and WireMock:</p> <pre><code>graph LR;\n    subgraph \"Isolated Test Environment\"\n        A[Spring Boot Application] --&gt; B[Testcontainers]\n        B --&gt; C[External Dependencies such as DB, Redis, Kafka, etc.]\n        A --&gt; D[WireMock]\n        D --&gt; E[External Services HTTP APIs]\n    end\n    F[Tests] --&gt; |Verify| A\n\n    style A stroke:#333,stroke-width:2px,font-weight:bold\n    style B stroke:#333,stroke-width:2px,font-weight:bold\n    style C stroke:#333,stroke-width:2px,font-weight:bold\n    style D stroke:#333,stroke-width:2px,font-weight:bold\n    style E stroke:#333,stroke-width:2px,font-weight:bold\n    style F stroke:#333,stroke-width:2px,font-weight:bold</code></pre> <p>To set up an isolated test environment using SpringBoot and Testcontainers, first you need to add below dependencies to your project:</p> <pre><code>&lt;dependencies&gt;\n    &lt;!-- remember to add your source module dependency if it is a multi-module project.  --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;com.github.nramc.dev.journey&lt;/groupId&gt;\n        &lt;artifactId&gt;journey-api-web&lt;/artifactId&gt;\n        &lt;version&gt;${project.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\n        &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.wiremock&lt;/groupId&gt;\n        &lt;artifactId&gt;wiremock-standalone&lt;/artifactId&gt;\n        &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n\n    &lt;!-- preferred api client for testing --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.rest-assured&lt;/groupId&gt;\n        &lt;artifactId&gt;rest-assured&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n\n    &lt;!-- preferred reporting tool   --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.qameta.allure&lt;/groupId&gt;\n        &lt;artifactId&gt;allure-rest-assured&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n\n    ...\n&lt;/dependencies&gt;\n</code></pre> <p>Next, you need to create a main class which serves as the entry point for running the Spring Boot application with Testcontainers during integration testing. It overrides the default application context by using <code>SpringApplication.from()</code> to load the main application and combines it with a custom <code>TestContainerConfig</code> class, which configures the necessary containers for the test environment. This setup allows integration tests to run with real external dependencies managed by Testcontainers.</p> <pre><code>public class IntegrationApplication {\n    public static void main(String[] args) {\n        SpringApplication.from(Application::main)\n                .with(TestContainerConfig.class)\n                .run(args);\n    }\n}\n</code></pre>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#testcontainers-configuration","title":"Testcontainers Configuration","text":"<p>Testcontainers can be configured in two ways, depending on project needs:</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#programmatic-approach","title":"Programmatic Approach","text":"<p>The <code>TestContainerConfig</code> class configures the Testcontainers to spin up real external dependencies like databases, message brokers, and other services required for integration testing. The <code>@ServiceConnection</code> Spring Boot annotation initializes the Testcontainers for the specified service, ensuring that the container is started before the application context is loaded and inject.</p> <pre><code>@TestConfiguration(proxyBeanMethods = false)\npublic class TestContainerConfig {\n\n    @Bean\n    @ServiceConnection\n    public ConfluentKafkaContainer kafkaContainer() {\n        return new ConfluentKafkaContainer(DockerImageName.parse(\"confluentinc/cp-kafka:7.4.0\")).withReuse(true);\n    }\n\n    @Bean\n    @ServiceConnection\n    public MongoDBContainer mongoDBContainer() {\n        return new MongoDBContainer(DockerImageName.parse(\"mongo:latest\"))\n                .withExposedPorts(27017)\n                .withReuse(true);\n    }\n\n}\n</code></pre>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#declarative-approach","title":"Declarative Approach","text":"<p>Define services in a <code>docker-compose.yml</code> file for consistency across environments.</p> <pre><code>version: '3.8'\nservices:\n  kafka:\n    image: confluentinc/cp-kafka:7.4.0\n    ports:\n      - \"9092:9092\"\n    environment:\n      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092\n  mongodb:\n    image: mongo\n    container_name: mongo\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - data:/data\n    environment:\n      - MONGO_INITDB_ROOT_USERNAME=mongodb_user\n      - MONGO_INITDB_ROOT_PASSWORD=mongodb_pwd\n</code></pre> <p>if you choose to use the declarative approach, then remember to add springboot docker compose dependency which takes care of staring and stopping container before application start-up.</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-docker-compose&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Next, you need to define a spring profile for integration testing example <code>integration</code> and specify all relevant configurations in either <code>application.yml</code> file or dedicated <code>application-integration.yml</code>.</p> <pre><code>spring:\n  mail:\n    username: noreply@journey.com\n    password: test-password\n    host: localhost\n    port: 1025\n    properties:\n      mail.smtp.auth: false\n      mail.smtp.starttls.enable: false\n      mail.smtp.starttls.required: false\n\nservice:\n  cloudinary:\n    api-key: dummy-integration-test-api-key\n    api-secret: dummy-integration-test-api-secret\n    cloud-name: integration-test-cloud-name\n    additional-properties:\n      upload_preset: journey_integration_test\n      # Wiremock URL for Cloudinary API stub\n      upload_prefix: http://localhost:8090/cloudinary/api/\n</code></pre> <p>Note: If you check carefully, the above configuration does not include Database and Kafka configurations. This is because <code>spring-boot-docker-compose</code> automatically fetch container details and inject them into spring context.</p> <p>You can start the application by running the <code>IntegrationApplication</code> class with spring profile <code>integration</code>. This will start the Spring Boot application with specified Testcontainers.</p> <p>Next, to start and stop application automatically as part of maven lifecycle, you need to add Spring Boot mave plugin with configuration. Pre-integration-test phase is used to start the test application and post-integration-test phase is used to stop the test application.</p> <pre><code>&lt;plugins&gt;\n    &lt;plugin&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\n        &lt;executions&gt;\n            &lt;execution&gt;\n                &lt;id&gt;pre-integration-test&lt;/id&gt;\n                &lt;goals&gt;\n                    &lt;goal&gt;start&lt;/goal&gt;\n                &lt;/goals&gt;\n                &lt;phase&gt;pre-integration-test&lt;/phase&gt;\n                &lt;configuration&gt;\n                    &lt;mainClass&gt;\n                        com.github.nramc.dev.journey.api.testing.integration.application.IntegrationApplication\n                    &lt;/mainClass&gt;\n                    &lt;profiles&gt;integration&lt;/profiles&gt;\n                &lt;/configuration&gt;\n            &lt;/execution&gt;\n            &lt;execution&gt;\n                &lt;id&gt;post-integration-test&lt;/id&gt;\n                &lt;goals&gt;\n                    &lt;goal&gt;stop&lt;/goal&gt;\n                &lt;/goals&gt;\n                &lt;phase&gt;post-integration-test&lt;/phase&gt;\n            &lt;/execution&gt;\n        &lt;/executions&gt;\n        &lt;configuration&gt;\n            &lt;!-- Additional classpath added to look for customized main class for integration application --&gt;\n            &lt;useTestClasspath&gt;true&lt;/useTestClasspath&gt;\n        &lt;/configuration&gt;\n    &lt;/plugin&gt;\n&lt;/plugins&gt;\n</code></pre> <p>Add test classpath to maven plugin configuration</p> <ul> <li>The <code>useTestClasspath</code> configuration ensures that the test classpath is included in the Maven plugin configuration.   This allows the plugin to locate the customized main class for the integration application.</li> <li>The <code>additionalClasspathElement</code> configuration can be used to specify additional classpath elements, ensuring that the plugin finds the   main class.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#2-writing-test","title":"2. Writing Test","text":"<p>Tip: Use JUnit 5 and Spring TestContext Framework</p> <p>If you're interested in writing reusable logic for your tests, especially when actions need to be conditionally executed, you can leverage JUnit Extensions, as described in this article on JUnit Extension Conditional Execution. It explains how to conditionally perform actions based on factors like Spring profiles, environment variables, or feature flags. </p> <p>Next, Let's write a simple integration test using JUnit 5 and RestAssured to validate the health check endpoint of the Spring Boot application. This test will ensure that the application is up and running and that the health check endpoint returns a status of UP.</p> <pre><code>class HelloWorldTest {\n\n    @BeforeAll\n    static void setup() {\n        RestAssured.baseURI = \"http://localhost:8080\";\n    }\n\n    @Test\n    void healthCheck_shouldBeAvailable_andShouldBeOK() {\n        given()\n                .get(\"/actuator/health\")\n                .then()\n                .statusCode(HttpStatus.OK.value())\n                .body(\"status\", equalTo(\"UP\"));\n    }\n}\n</code></pre>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#3-running-test","title":"3. Running Test","text":"<p>Since we start and stop the application as part of maven lifecycle <code>pre-integration-test</code> and <code>post-integration-test</code> respectively, we need to run test in integration phase. Enable and customize <code>maven-failsafe-plugin</code> as follows and optionally you can disable <code>maven-surefire-plugin</code>.</p> <pre><code>&lt;plugins&gt;\n    ...\n    &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n            &lt;skip&gt;true&lt;/skip&gt;\n        &lt;/configuration&gt;\n    &lt;/plugin&gt;\n\n    &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n            &lt;includes&gt;\n                &lt;include&gt;**/*Test.java&lt;/include&gt; &lt;!-- Matches classes ending with 'Test' --&gt;\n            &lt;/includes&gt;\n            &lt;environmentVariables&gt;\n                &lt;SPRING_PROFILES_ACTIVE&gt;${testcase.spring.profiles}&lt;/SPRING_PROFILES_ACTIVE&gt;\n            &lt;/environmentVariables&gt;\n        &lt;/configuration&gt;\n    &lt;/plugin&gt;\n\n    ...\n&lt;/plugins&gt;\n</code></pre> <p>Now you can run the test using maven command as follows:</p> <pre><code>mvn clean verify \n</code></pre> <p>Note</p> <ul> <li>You can also run the test using IDE by running the <code>IntegrationApplication</code> class with the <code>integration</code> profile.</li> <li>Wait until the Spring Boot application started successfully with Testcontainers.</li> <li>And then execute the <code>HelloWorldTest</code> class.</li> </ul> <p>Adopting test for both Integration and QA test suite</p> <p>To run the same test in both integration and QA environments, you can use Spring profiles to manage different configurations.</p> <p>You can use conditional extensions to run the test based on the active profile. Please refer to the JUnit Extension Conditional Execution article for more details.</p> <p>Let's create a test-suite-specific configuration with desired spring profiles.</p> <pre><code>@TestConfiguration(proxyBeanMethods = false)\n@EnableConfigurationProperties({EnvironmentProperties.class})\n@PropertySource(\"classpath:integration-test.properties\")\n@Profile(\"integration-test\")\npublic class IntegrationTestSuiteConfig {\n    // Add any additional beans or configurations specific to the integration test suite\n}\n\n@TestConfiguration(proxyBeanMethods = false)\n@EnableConfigurationProperties({EnvironmentProperties.class})\n@PropertySource(\"classpath:qa-test.properties\")\n@Profile(\"qa-test\")\npublic class QaTestSuiteConfig {\n    // Add any additional beans or configurations specific to the QA test suite\n}\n</code></pre> <p>Let's adopt the test to use the configurations and execute them for both integration and QA test suite.</p> <pre><code>@SpringJUnitConfig(classes = {IntegrationTestSuiteConfig.class, QaTestSuiteConfig.class})\nclass HelloWorldTest {\n    @Autowired\n    EnvironmentProperties environmentProperties;\n\n    @Test\n    void healthCheck_shouldBeAvailable_andShouldBeOK() {\n        given()\n                .baseUri(environmentProperties.baseUrl())\n                .get(\"/actuator/health\")\n                .then()\n                .statusCode(HttpStatus.OK.value())\n                .body(\"status\", equalTo(\"UP\"));\n    }\n}\n</code></pre> <p>During the development phase, you can run the test with the <code>integration-test</code> profile to validate the integration test suite and <code>qa</code> profile to validate the QA test suite.</p> <p>Note</p> <ul> <li><code>@SpringJUnitConfig</code> annotation from Spring Test Support is used to specify the configuration classes for the test suite.</li> <li>Spring Core implementations does not support yml files, so you need to use <code>@PropertySource</code> to load the properties file.</li> <li>You can also use <code>@SpringBootTest</code> annotation to load the application context with yml file and run the test if you prefer.</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#4-running-test-in-cicd-pipeline","title":"4. Running Test in CI/CD Pipeline","text":"<p>To run the test in CI/CD pipeline, we need to ensure that the Testcontainers are started and stopped automatically as part of the maven lifecycle. We have defined two properties <code>testcase.spring.profiles</code> to activate spring profile for test suite and <code>integration.test.skip</code> to perform start/stop isolated application for integration testing.</p> <pre><code>mvn clean verify -Dtestcase.spring.profiles=integeration-test -Dintegration.test.skip=false\n</code></pre>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#5-running-test-in-qa-environment","title":"5. Running Test in QA Environment","text":"<p>To run the test in QA environment, we need to set the <code>testcase.spring.profiles</code> property to <code>qa-test</code> and skip the integration test by setting the <code>integration.test.skip</code> property to <code>true</code>.</p> <pre><code>mvn clean verify -Dtestcase.spring.profiles=qa-test -Dintegration.test.skip=true\n</code></pre> <p>Make use of Maven Profile</p> <p>You can also create a maven profile to run the test suite with the desired spring profile and skip the integration test. This way you can run the test suite with a single command without specifying the properties each time.</p> <p>```xml\"  integration-test false integration-test qa-test true qa-test <pre><code>Now you can run the test suite with the desired profile using the following command:\n\n```bash\n\nmvn clean verify -P integration-test\nmvn clean verify -P qa-test\n</code></pre></p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#best-practices-for-shift-left-testing","title":"Best Practices for Shift-Left Testing","text":"<ul> <li>Run integration tests as part of CI/CD pipelines \u2013 Don't wait until QA; catch issues early.</li> <li>Use dynamic configuration for test environments \u2013 Ensure tests can switch between integration (Testcontainers) and   QA applications seamlessly.</li> <li>Leverage Spring profiles \u2013 Use different profiles for local, CI/CD, and QA environments.</li> <li>Mock only when necessary \u2013 Prefer real dependencies over mocks to catch integration issues early.</li> <li>Use realistic test data \u2013 Ensure test data parity between local, CI/CD, and QA environments.</li> <li>Monitor and optimize test execution time \u2013 Shift-left should not slow down development; balance comprehensive</li> <li>Ensure test repeatability \u2013 Tests should be deterministic and produce the same results across different   environments.</li> <li>Automate database migrations in tests \u2013 Apply schema migrations dynamically in test environments to validate   database compatibility early.</li> <li>Integrate contract testing \u2013 Use tools like Pact to ensure API compatibility between microservices before   deployment.</li> <li>Parallelize test execution \u2013 Speed up test runs by executing independent tests in parallel across multiple   containers or services.</li> <li>Enforce test coverage metrics \u2013 Track test coverage to ensure critical application paths are well-tested.</li> <li>Incorporate security and performance testing \u2013 Shift-left applies beyond functionality; integrate basic security   scans and performance benchmarks early.</li> <li>Collect and analyze test results \u2013 Implement logging and monitoring for test executions to identify flaky tests   and bottlenecks</li> </ul>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#conclusion","title":"Conclusion","text":"<p>Spring Boot and Testcontainers together empower teams to adopt Shift-Left Testing by enabling early, realistic, and automated testing. By integrating Testcontainers into integration, developers can reduce the gap between local and production environments, ensuring higher softwar quality and faster delivery cycles.</p> <p>By shifting left, you detect issues earlier, cheaper, and faster\u2014leading to better software, fewer surprises, and smoother releases. Start using Testcontainers with Spring Boot today and enhance your testing strategy!</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/shift-left-testing-with-springboot.html#further-reading","title":"Further Reading","text":"<ul> <li>Testcontainers Documentation</li> <li>Spring TestContext Framework</li> <li>What is Shift-Left Testing?</li> <li>Shift-Left Testing with Testcontainers: Catching Bugs Early with Local Integration Tests</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Spring Boot","Testcontainers","Testing"]},{"location":"blog/maven-auto-update-dependencies.html","title":"Automating Maven Dependency Updates","text":"<p>In Java projects, keeping dependencies up to date is crucial for ensuring security, enhancing performance, and maintaining compatibility. However, managing and updating dependencies manually can be tedious and error-prone. Fortunately, there are various tools available to automate this process, such as GitHub Dependabot, RenovateBot, the Maven Versions Plugin, and the OpenRewrite Maven Plugin.</p> <p>This article explores these tools and how they can help you automate Maven dependency updates efficiently.</p> <p>Why Automate Dependency Updates?</p> <p>Automating dependency updates brings several advantages:</p> <ol> <li>Security Enhancements<ul> <li>Fix vulnerabilities automatically by upgrading dependencies.</li> <li>Ensure compliance with security best practices.</li> </ul> </li> <li>Stability and Performance<ul> <li>Upgrade to stable versions for bug fixes and performance improvements.</li> <li>Avoid breaking changes by controlling updates.</li> </ul> </li> <li>CI/CD Integration<ul> <li>Automatically update dependencies in a controlled, repeatable manner.</li> <li>Reduce manual maintenance in large-scale projects.</li> </ul> </li> </ol>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/maven-auto-update-dependencies.html#dependabot-github","title":"Dependabot (GitHub)","text":"<ul> <li>Dependabot   is an automated tool from GitHub that helps you keep your dependencies up to date by automatically creating pull   requests.</li> <li>Fully integrated with GitHub.</li> <li>It supports multiple package managers, including Maven.</li> <li>Configure it via <code>.github/dependabot.yml</code>:   ```yaml     version: 2     updates:<ul> <li>package-ecosystem: \"maven\"   directory: \"/\"   schedule:   interval: \"weekly\"    ```</li> </ul> </li> </ul> <p>Learn more about Dependabot.</p>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/maven-auto-update-dependencies.html#renovate-bot","title":"Renovate Bot","text":"<ul> <li>Renovate Bot is a powerful dependency update tool.</li> <li>Automatically creates pull requests to keep your dependencies up to date.</li> <li>It supports multiple package managers, including Maven.</li> <li>Can be integrated into existing workflows seamlessly.</li> <li>It can be configured via <code>renovate.json</code>:   <pre><code>{\n  \"$schema\": \"https://docs.renovatebot.com/renovate-schema.json\",\n  \"extends\": [\"config:recommended\"]\n}\n</code></pre></li> </ul> <p>Learn more about Renovate Bot.</p>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/maven-auto-update-dependencies.html#maven-versions-plugin","title":"Maven Versions Plugin","text":"<ul> <li>Maven Versions Plugin helps you check for and   update Maven dependencies.</li> <li>It can be run manually or automated through CI/CD pipelines.</li> <li>Works directly within your Maven build lifecycle.</li> <li>It can be executed as part of CI workflows.</li> <li>It can be configured in the <code>pom.xml</code>:   <pre><code>&lt;build&gt;\n  &lt;plugins&gt;\n    &lt;plugin&gt;\n      &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n      &lt;artifactId&gt;versions-maven-plugin&lt;/artifactId&gt;\n      &lt;version&gt;${versions-maven-plugin.version}&lt;/version&gt;\n    &lt;/plugin&gt;\n  &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre></li> <li>It can be run via the command line or integrated into CI/CD pipelines:   <pre><code># To update dependencies to the latest stable release:\nmvn versions:use-latest-releases\n\n# To update dependencies declared using properties:\nmvn versions:update-properties\n\n# To update parent POM version:\nmvn versions:update-parent\n\n# Check for Available Updates Without Applying\n# To display dependency updates:\nmvn versions:display-dependency-updates\n\n# To display plugin updates:\nmvn versions:display-plugin-updates\n</code></pre></li> </ul> <p>Learn more about Maven Versions Plugin.</p>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/maven-auto-update-dependencies.html#openrewrite-maven-plugin","title":"OpenRewrite Maven Plugin","text":"<ul> <li>OpenRewrite is an open-source automated refactoring ecosystem for source code,   enabling developers to effectively eliminate technical debt within their repositories.</li> <li>OpenRewrite Maven Plugin is the fastest way to   apply OpenRewrite recipes to your code as part of your Maven build.</li> <li>UpgradeDependencyVersion Recipe is   a recipe that upgrades dependencies to the latest version.</li> <li>Easily integrated into your Maven build process.</li> <li>It can be configured in the <code>pom.xml</code>:   <pre><code>  &lt;plugin&gt;\n      &lt;groupId&gt;org.openrewrite.maven&lt;/groupId&gt;\n      &lt;artifactId&gt;rewrite-maven-plugin&lt;/artifactId&gt;\n      &lt;version&gt;${rewrite-maven-plugin.version}&lt;/version&gt;\n      &lt;configuration&gt;\n          &lt;activeRecipes&gt;\n              &lt;recipe&gt;com.github.nramc.recipes.UpgradeAllDependencies&lt;/recipe&gt;\n          &lt;/activeRecipes&gt;\n      &lt;/configuration&gt;\n  &lt;/plugin&gt;\n</code></pre> <pre><code>type: specs.openrewrite.org/v1beta/recipe\nname: com.github.nramc.recipes.UpgradeAllDependencies\nrecipeList:\n- org.openrewrite.java.dependencies.UpgradeDependencyVersion:\n  groupId: \"*\"          # Upgrade all dependencies\n  artifactId: \"*\"       # Upgrade all dependencies\n  newVersion: \"latest.release\"\n</code></pre></li> <li>It can be run via the command line or integrated into CI/CD pipelines:   <pre><code># To apply the recipe:\nmvn rewrite:run\n</code></pre></li> </ul> <p>Learn more about OpenRewrite Maven Plugin.</p>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/maven-auto-update-dependencies.html#conclusion","title":"Conclusion","text":"<p>Automating dependency updates is essential for maintaining a secure, stable, and performant Java project. Whether you're using Dependabot, Renovate Bot, the Maven Versions Plugin, or OpenRewrite, each tool offers distinct advantages depending on your needs. By integrating one or more of these tools into your CI/CD pipeline, you can ensure your dependencies are always up to date with minimal manual intervention.</p> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Java","Maven","Dependency Management","Automation"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html","title":"Automating Security Testing in CI/CD Pipelines with OWASP ZAP: A Comprehensive Guide","text":"","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#introduction","title":"Introduction","text":"<p>Security is a critical aspect of software development, and it is essential to ensure that applications are secure before they are deployed to production. Security testing can be performed using various tools and techniques, including Static Code Analysis, Dynamic Application Security Testing(DAST), and penetration testing. Each of these methods has its strengths and weaknesses, and the best approach is to use a combination of them to achieve comprehensive security coverage.</p> <p>We will focus on Dynamic Application Security Testing(DAST), which is a type of security testing that involves testing a running application for vulnerabilities. DAST tools simulate attacks on the application to identify security weaknesses and provide recommendations for remediation.</p> <p>But DAST tools can be complex to set up and configure, and they often require a deep understanding of the application being tested. This is where the OWASP ZAP Automation Frameworkcomes in. The ZAP Automation Framework is a powerful tool that allows you to automate the security testing process using YAML files called scan plans.</p> <p>In this article, We will explore how to use OWASP ZAP Automation Framework to perform a shift left security testing on SpringBoot REST API with OpenAPI documentation. We will use Journey API to demonstrate the process.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#what-is-owasp-zap","title":"What is OWASP ZAP?","text":"<p>OWASP ZAP (Zed Attack Proxy) is a popular open-source web application security scanner. It is designed to find vulnerabilities in web applications during the development and testing phases. ZAP can be used for both manual and automated security testing, making it the best tool for developers and security professionals.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#what-is-zap-automation-framework","title":"What is ZAP Automation Framework?","text":"<p>ZAP Automation Framework is a powerful tool that allows you to automate the security testing process using YAML files called scan plans. These scan plans define the steps to be performed during the security testing process such as authentication, session management, scanning and generating reporting. The scan plans can be customized to include specific tests, configurations, and parameters, allowing you to tailor the security testing process to your specific needs.</p> <p>Note</p> <p>ZAP also provides various other options to automate the security testing process, you can refer to the ZAP Automation Guide. As per OWASP team recommendation, The Automation Framework will in time replace the Command Line and Packaged Scan options. Therefore it is important to start using the Automation Framework for security testing.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#security-testing-with-owasp-zap-automation-framework","title":"Security Testing with OWASP ZAP Automation Framework","text":"<p>In this section, we will explore how to use the ZAP Automation Framework to perform security testing on a SpringBoot REST API with OpenAPI documentation. We will cover the following topics:</p> <ol> <li>Setting up OWASP ZAP</li> <li>Creating a scan plan</li> <li>Running the scan plan</li> <li>Review generated reports</li> </ol>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Running REST API Service - SpringBoot</li> <li>OpenAPI documentation available for the API - Spring RestDoc</li> </ul>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#step-1-install-owasp-zap","title":"Step 1: Install OWASP ZAP","text":"<p>To get started with OWASP ZAP, you need to install it on your local machine. ZAP is available for Windows, macOS, and Linux. The easiest way to install ZAP is to download the executable file for your operating system and run the installer.</p> <p>You can download the latest version of ZAP from the OWASP ZAP website.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#step-2-create-a-scan-plan","title":"Step 2: Create a Scan Plan","text":"<p>The scan plan is a powerful feature of the ZAP Automation Framework that allows you to customize the security testing process to meet your specific needs. You can define the steps to be performed during the security testing process, such as authentication, session management, scanning, and generating reports. The scan plan can be customized to include specific tests, configurations, and parameters, allowing you to tailor the security testing process to your specific needs.</p> <p>The scan plan is defined in a YAML file, which is a human-readable format that is easy to understand and modify. The YAML file contains a series of jobs that perform specific tasks during the security testing process. The jobs are executed in the order they are defined in the YAML file.</p> <p>Our scan plan includes the following types of jobs:</p> <ul> <li>passiveScan-config: This job configures the passive scan settings for the ZAP instance. It allows you to specify   which passive scan rules to enable or disable, as well as other configuration options.</li> <li>openapi: This job configures the OpenAPI settings for the ZAP instance. It allows you to specify the OpenAPI URL   and other configuration options such as Authentication URL, Target API URL.</li> <li>passiveScan-wait: This job waits for the passive scan to complete before proceeding to the next job. It ensures   that all passive scan rules have been executed and that the results are available for review.</li> <li>activeScan: This job performs an active scan on the target application. It simulates attacks on the application to   identify vulnerabilities and provides recommendations for remediation.</li> <li>report: This job generates a report of the scan results. The report includes information about the vulnerabilities   found during the scan, as well as recommendations for remediation.</li> </ul> <p>We will use the ZAP GUI to create the scan plan. The ZAP GUI provides a user-friendly interface for creating and managing scan plans. You can use the GUI to define the steps to be performed during the security testing process, such as authentication, session management, scanning, and generating reports. The GUI also provides a visual representation of the scan plan, making it easy to understand and modify.</p> <p>To create a scan plan using the ZAP GUI, follow these steps: </p> <p>Here is a scan plan for Journey SpringBoot REST API:</p> <pre><code>env:\n  contexts:\n    - name: journey-api\n      urls:\n        - ${TARGET_APP_URL}\n      includePaths:\n        - \"${TARGET_APP_URL}.*\"\n      authentication:\n        method: json\n        parameters:\n          loginPageUrl: ${TARGET_APP_URL}/rest/guestLogin\n          loginRequestUrl: ${TARGET_APP_URL}/rest/guestLogin\n          loginRequestBody: \"{\\\"username\\\":\\\"{%username%}\\\",\\\"password\\\":\\\"{%password%}\\\"\\\n          }\"\n        verification:\n          method: response\n          pollFrequency: 60\n          pollUnits: requests\n          pollUrl: \"\"\n          pollPostData: \"\"\n      sessionManagement:\n        method: headers\n        parameters:\n          Authorization: \"Bearer {%json:token%}\"\n      technology: { }\n      structure: { }\n      users:\n        - name: journey-user\n          credentials:\n            username: ${APP_USERNAME}\n            password: ${APP_PASSWORD}\n  parameters: { }\n  vars:\n    REPORT_DIR: \"zap-report\"\n    APP_USERNAME: \"journey-test-user@journey.com\"\n    APP_PASSWORD: \"Journey-Test@123\"\n    TARGET_APP_URL: \"http://localhost:8080\"\njobs:\n  - type: passiveScan-config\n    parameters: { }\n  - type: openapi\n    parameters:\n      apiUrl: ${TARGET_APP_URL}/doc/openapi\n      targetUrl: ${TARGET_APP_URL}\n      context: journey-api\n      user: journey-user\n  - type: passiveScan-wait\n    parameters: { }\n  - type: activeScan\n    parameters: { }\n    policyDefinition: { }\n  - type: report\n    parameters:\n      reportDir: ${REPORT_DIR}\n      reportTitle: Security Testing Report\n  - type: exitStatus\n    parameters: { }\n</code></pre> <p>Note</p> <p>It is strongly recommend to use the latest version of ZAP GUI for creating the scan plan. You can use the ZAP GUI to create the scan plan and then save it as a YAML file. This will ensure that the scan plan is compatible with the latest version of ZAP and will work as expected.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#step-3-run-the-scan-plan","title":"Step 3: Run the Scan Plan","text":"<p>To run the scan plan, as shown in the video, you can use ZAP GUI instance to open the plan and execute it. Alternatively, execute the scan plan using the ZAP command line interface. The command line interface allows you to run the scan plan in a headless mode, which is useful for automating the security testing process in a CI/CD pipeline.</p> <p>To start the ZAP instance, you can use the following command:</p> <pre><code>sh /Applications/ZAP.app/Contents/MacOS/ZAP.sh -port 9010 -dir ${HOME}/Documents/owasp -cmd -autorun .github/workflows/zap/journey-dast-plan.yaml\n</code></pre> <ul> <li>This command starts the ZAP instance and runs the scan plan defined in the <code>journey-dast-plan.yaml</code> file.</li> <li>The <code>-port</code> option specifies the port for ZAP instance to listen on. By default, ZAP uses port 8080.</li> <li>The <code>-dir</code> option specifies the directory where the ZAP instance will store its data.</li> <li>The <code>-cmd</code> option specifies the command to run the scan plan.</li> <li>The <code>-autorun</code> option specifies the YAML file that contains the scan plan to be executed.</li> </ul> <p>You can find more information about the command line in the ZAP Command Line.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#step-4-review-the-reports","title":"Step 4: Review the Reports","text":"<p>Scan report is generated in the <code>zap-report</code> directory which is mentioned in scan plan. The report includes information about the vulnerabilities found during the scan, as well as recommendations for remediation. The report is generated in HTML format by default, it can be configured to generate in different format if required.</p> <p>The Above video shows the report generated by ZAP for the Journey API.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#automate-security-testing-in-cicd","title":"Automate Security Testing in CI/CD","text":"<p>During development, a developer can install ZAP on their workstation and should be able to run Automation Framework's plan, which tests locally to ensure that the code is secure before committing it to the repository.</p> <p>But How do we ensure automatically that the code is secure? The answer is integrated ZAP into the CI/CD pipeline.</p> <p>You can use ZAP Docker Image to run the scan plan in the CI/CD pipeline. Alternatively, you can use the ZAP Automation Framework GitHub Action to run the scan plan in the CI/CD pipeline. The GitHub Action under the hood uses the ZAP docker image to run the scan plan.</p> <p>Here is an example of how to use the ZAP Automation Framework in a GitHub Actions workflow:</p> <pre><code>name: CI\non:\n  push:\n    branches:\n      - main\n  pull_request:\n    types: [ opened, synchronize, reopened ]\njobs:\n  security-test:\n    name: Security Testing\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up JDK 21\n        uses: actions/setup-java@v4\n        with:\n          java-version: '21'\n          distribution: 'temurin'\n\n      - name: Start application for Security Testing\n        run: |\n          mvn clean install -DskipTests # Optional: to resolve any project dependencies\n          mvn spring-boot:start\n        env:\n          SPRING_PROFILES_ACTIVE: integration\n\n      - name: Wait for application to start\n        run: |\n          timeout 60 bash -c 'until curl -s http://localhost:8080/actuator/health; do sleep 5; done'\n\n      - name: ZAP Scan\n        uses: zaproxy/action-af@v0.2.0\n        with:\n          plan: '.github/workflows/zap/journey-openapi-plan.yaml'\n          cmd_options: '-port 8090'\n          docker_env_vars: |\n            REPORT_DIR\n        env:\n          REPORT_DIR: \"/zap/wrk/zap-report\"\n\n      - name: Stop Spring Boot application\n        run: |\n          mvn spring-boot:stop\n</code></pre> <p>In this example,</p> <ul> <li>we are using the <code>actions/checkout@v4</code> and <code>actions/setup-java@v4</code> action to check out the code from the repository   and set up the JDK 21 environment for the SpringBoot application.</li> <li>we are using the <code>mvn spring-boot:start</code> command to start the SpringBoot application for security testing with spring   profile <code>integration</code>.</li> <li>we are using the <code>timeout</code> &amp; 'curl' command to wait for the application to start before running the ZAP scan.</li> <li>we are using the <code>zaproxy/action-af</code> ZAP's GitHub Action to run the scan plan defined in the   <code>.github/workflows/zap/journey-openapi-plan.yaml</code> file.</li> <li>The <code>cmd_options</code> option specifies the command line options to be passed to the ZAP instance. In this example, we are   using the <code>-port 8090</code> option to change default port 8080, since the application uses port 8080.</li> <li>The <code>docker_env_vars</code> option specifies the environment variables to be passed to the ZAP instance.</li> <li>The <code>REPORT_DIR</code> environment variable specifies the directory where the ZAP instance will store its data.</li> <li>we are using the <code>mvn spring-boot:stop</code> command to stop the SpringBoot application after the ZAP scan is   completed.</li> </ul>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#automate-security-testing-with-staging-environment","title":"Automate Security Testing with Staging Environment","text":"<p>In the above example, we are using the <code>mvn spring-boot:start</code> command to start the SpringBoot application in CI/CD pipeline for security testing. But this is not enough since the application is isolated with mocks and test containers. We need to run security testing with the application running on a staging environment that is similar to the production-like environment.</p> <p>To run the security testing with the application running on a staging environment, you can use the following steps:</p> <ol> <li>Deploy the application to a staging environment using your CI/CD pipeline.</li> <li>Update the <code>TARGET_APP_URL</code> environment variable in the scan plan to point to the staging environment URL.</li> <li>Provide the required environment variables such as <code>APP_USERNAME</code> and <code>APP_PASSWORD</code> to the scan plan.</li> <li>Run the ZAP scan using the ZAP Automation Framework GitHub Action or the ZAP command line interface.</li> </ol> <p>Here is an example of nightly job to run the security testing with the application running on a staging environment:</p> <pre><code>name: Nightly Security Testing\non:\n  schedule:\n    - cron: '0 0 * * *' # Every day at midnight\njobs:\n  security-test:\n    name: Security Testing\n    runs-on: ubuntu-latest\n    steps:\n\n      - name: ZAP Scan\n        uses: zaproxy/action-af@v0.2.0\n        with:\n          plan: '.github/workflows/zap/journey-openapi-plan.yaml'\n          cmd_options: '-port 8090'\n          docker_env_vars: |\n            REPORT_DIR\n        env:\n          REPORT_DIR: \"/zap/wrk/zap-report\"\n          TARGET_APP_URL: \"https://journey-api-qa.com\"\n          APP_USERNAME: ${secrets.APP_USERNAME}\n          APP_PASSWORD: ${secrets.APP_PASSWORD}\n</code></pre> <p>Tip</p> <p>You can trigger the nightly job automatically from deployment workflow as soon as the application is deployed to the staging environment to get immediate feedback.</p> <p>If you want to run manually the security testing with the application running on a staging environment using the ZAP command line interface, you can use the following command:</p> <pre><code># set required environment variables\nexport REPORT_DIR=\"/zap-report\"\nexport TARGET_APP_URL=\"https://journey-api-qa.com\"\nexport APP_USERNAME=\"real-qa-test-user\"\nexport APP_PASSWORD=\"real-qa-test-password\"\n\nsh /Applications/ZAP.app/Contents/MacOS/ZAP.sh -dir ${HOME}/Documents/owasp -cmd -autorun .github/workflows/zap/journey-dast-plan.yaml\n</code></pre>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#real-world-lessons-learned","title":"Real-World Lessons Learned","text":"<ul> <li>Shift Left Security Testing: Incorporate security testing into the development process as early as possible to   identify vulnerabilities before they reach production.</li> <li>Use the latest version of ZAP: The ZAP Automation Framework is constantly evolving, and it is important to use the   latest version of ZAP to take advantage of the latest features and improvements.</li> <li>Use the ZAP GUI to create the scan plan: The ZAP GUI provides a user-friendly interface for creating and managing   scan plans.</li> <li>Fail Build on High Risk Vulnerabilities: It is important to fail the build on high-risk vulnerabilities to ensure   that the application is secure before it is deployed to production. You can use the <code>exitStatus</code> job in the scan plan   to fail the build on high-risk vulnerabilities.</li> <li>Use Environment-Specific Configurations: Ensure scan plans are configured for different environments (e.g.,   development, staging, production) to avoid false positives or missed vulnerabilities.</li> <li>Upload the report to a central location: It is important to upload the scan report to a central location for   review and analysis. You can use the <code>report</code> job in the scan plan to generate the report and upload it to a central   location.</li> </ul>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#conclusion","title":"Conclusion","text":"<p>In this article, we explored how to use the OWASP ZAP Automation Framework to perform security testing on a SpringBoot REST API with OpenAPI documentation. We also discussed how to integrate ZAP Automation Framework into your CI/CD pipeline using GitHub Action.</p> <p>By automating the security testing process, you can ensure that your applications are secure before they are deployed to production. This will help you to identify and remediate security vulnerabilities early in the development process, reducing the risk of security breaches and improving the overall security posture of your applications.</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/owasp-zap-proxy-api-scan-dast.html#references","title":"References","text":"<ul> <li>OWASP ZAP Automation Framework</li> <li>Automation Guide - Options</li> <li>ADDO Workshop</li> <li>GitHub Action:ZAP Automation Framework Scan</li> <li>Dynamic Application Security Testing (DAST)</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Automation","CI/CD","Maven","Testing","Secure Coding","Security Testing","Spring Boot"]},{"location":"blog/deep-links.html","title":"Maximizing Web Application Usability with Deep Links","text":"<p>TL;DR: Deep links enable users to navigate directly to specific content within a web application, improving accessibility, engagement, and efficiency.</p>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#what-are-deep-links","title":"What Are Deep Links?","text":"<p>Deep linking is a technique that allows users to navigate directly to specific content or sections within a web application. Unlike traditional links that simply open a homepage or landing page, deep links take users precisely where they need to go\u2014whether accessed through search engines, shared links, or marketing campaigns\u2014enhancing accessibility and user experience.</p>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#why-do-we-need-deep-links","title":"Why Do We Need Deep Links?","text":"<ol> <li>Enhanced User Experience \u2013 Deep links eliminate unnecessary navigation by directing users to relevant content    instantly.</li> <li>Improved Engagement &amp; Retention \u2013 Users are more likely to engage with your application when they can quickly    find what they need.</li> <li>Marketing &amp; SEO Benefits \u2013 Deep linking improves discoverability in search engines and supports targeted    campaigns.</li> <li>Cross-Platform Consistency \u2013 Deep links can be used to create seamless transitions between web and mobile    applications.</li> </ol>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#key-components-of-a-deep-link","title":"Key Components of a Deep Link","text":"<p>A well-structured deep link should contain the following:</p> Field Description Type Defines the purpose (e.g., navigation, authentication, content access). Expiry Date Controls the validity of the deep link, ensuring security. Create Date Tracks when the deep link was generated. Created By Identifies the creator (user/system). Short URL A user-friendly, compact version of the original URL. Original URL The full-length target URL. Visibility Determines who can access the deep link (public, private, etc.). Metadata Additional information about the deep link (e.g., user, purpose). <p>Example:</p> <pre><code>Short URL: https://app.com/go/xyz123\nOriginal URL: https://app.com/dashboard?section=reports&amp;id=45\n</code></pre>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#implementation-strategies","title":"Implementation Strategies","text":"<pre><code>flowchart TD\n    A[User/System Requests a Deep Link] --&gt; B[Generate Short URL]\n    B --&gt; C[Store in Database]\n\n    C --&gt;|Link shared with User| D[User Clicks Short URL]\n    D --&gt; E[Server Receives Request]\n    E --&gt; F[Lookup Short URL in Database]\n\n    F --&gt; G{Check Existence, Expiry &amp; Validity}\n    G --&gt;|Not Found| H[Redirect to Error Page]\n    G --&gt;|Expired| H\n    G --&gt;|Invalid| H\n\n    G --&gt;|Valid| J{Check Visibility &amp; Permissions}\n    J --&gt;|Not Authenticated| M[Redirect to Login Page]\n    M --&gt; N[User Logs In]\n    N --&gt; O[Revalidate Permissions]\n\n    J --&gt;|Authenticated| P{Check User Permissions}\n    O --&gt;|Authenticated| P\n\n    P --&gt;|Access Denied| Q[Show Access Denied Page]\n    P --&gt;|Access Granted| R[Redirect to Original URL]\n\n    R--&gt; S[Display Target Content]\n    R --&gt; T{Check type of Deep Link}\n    T --&gt;|One-Time Use| U[Mark as Used in Database]</code></pre>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#thinks-to-consider-for-deep-links","title":"Thinks to consider for Deep Links","text":"<p>Security Measures</p> <ul> <li>Validate and sanitize input to prevent injection attacks.</li> <li>Avoid exposing sensitive data in URLs.</li> <li>Encrypt sensitive data in deep links.</li> <li>Use HTTPS to secure data transmission.</li> <li>Use secure shortening services to generate short URLs.</li> <li>Implement signed links (JWT-based or hash-based security).</li> <li>Implement access controls to restrict unauthorized access.</li> <li>Implement rate limiting to prevent abuse.</li> <li>Monitor and log deep link usage for auditing.</li> <li>Regularly review and update deep links to maintain security.</li> </ul> <p>Performance Optimization</p> <ul> <li>Optimize URL resolution for faster navigation.</li> <li>Cache frequently accessed deep links.</li> <li>Optimize URL resolution for faster redirection.</li> </ul>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/deep-links.html#conclusion","title":"Conclusion","text":"<p>Deep links are a powerful tool for improving accessibility, engagement, and retention in web applications. Whether for marketing, seamless navigation, or enhancing user experience, implementing deep links ensures users reach the right content effortlessly. By integrating deep linking strategically, businesses can maximize their web application\u2019s usability and effectiveness.</p> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Web Application","Improvement","UI/UX"]},{"location":"blog/open-graph-for-social-sharing.html","title":"Optimizing Social Media Sharing with Open Graph Meta Tags","text":"<p>TL;DR: Open Graph meta-tags control how your content appears when shared on social media. Adding tags like og:title, og:description, and og:image in your HTML  improves link previews, boosts engagement, and enhances branding. Use high-quality images, concise titles, and validation tools like Facebook\u2019s Debugger to ensure optimal display.","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#introduction","title":"Introduction","text":"<p>In the age of social media, sharing content effectively is crucial for engagement and visibility. Open Graph(OG), a protocol introduced by Facebook, allows developers to control how content appears when shared on platforms like Facebook, LinkedIn, and Twitter. By implementing Open Graph meta-tags, developers can ensure their content is visually appealing, accurately represented, and optimized for click-through rates.</p> <p>This article provides a comprehensive guide to Open Graph, covering its benefits, implementation, best practices, and debugging techniques.</p>","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#what-is-open-graph","title":"What is Open Graph?","text":"<p>Open Graph(OG) is a set of meta-tags added to the  section of a webpage to define how the page's content appears when shared on social media platforms. These tags specify elements such as title, description, image, and type to create rich previews that attract user engagement.","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#why-should-you-implement-open-graph","title":"Why Should You Implement Open Graph?","text":"<ul> <li>Better Visual Presentation: Ensures that links shared on social media include rich, informative previews with   images and descriptions.</li> <li>Increased Click-Through Rate (CTR): A well-optimized OG setup makes links more appealing, encouraging users to   click.</li> <li>Consistent Branding: Allows content creators/organization to define how their brand appears across social   networks.</li> <li>SEO Benefits: While not a direct SEO factor, OG tags improve social traffic, which can contribute to overall   visibility and user engagement.</li> <li>Cross-Platform Compatibility: Supported by major social media platforms like Facebook, Twitter, LinkedIn, and   Pinterest.</li> <li>Control Over Content: Developers can specify the title, description, and image that appear when the content is   shared.</li> <li>Accessibility: Rich previews make content more accessible to users with visual impairments.</li> </ul>","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#implementing-open-graph-meta-tags","title":"Implementing Open Graph Meta-Tags","text":"<p>To implement Open Graph meta-tags, add the following tags to the  section of your HTML document: <pre><code>&lt;meta property=\"og:title\" content=\"Optimizing Social Media Sharing with Open Graph Meta Tags\"/&gt;\n&lt;meta property=\"og:description\" content=\"A Developer's Guide to Open Graph: Enhancing Content for Social Media\"/&gt;\n&lt;meta property=\"og:image\"\n      content=\"https://nramc.github.io/my-notes/assets/images/social/blog/articles/web-application/open-graph-for-social-sharing.png\"/&gt;\n&lt;meta property=\"og:url\" content=\"https://nramc.github.io/my-notes/blog/open-graph-for-social-sharing.html\"/&gt;\n&lt;meta property=\"og:type\" content=\"website\"/&gt;\n</code></pre>","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#testing-open-graph-implementation","title":"Testing Open Graph Implementation","text":"<p>To verify that your Open Graph tags are working correctly, use the following tools:</p> <ul> <li>Facebook Sharing Debugger: Checks and refreshes your OG data on   Facebook.</li> <li>Twitter Card Validator: Previews how your content appears on Twitter.</li> <li>LinkedIn Post Inspector: Validates OG tags for LinkedIn sharing.</li> </ul> <p>Browser Developer Tools: Inspect meta-tags directly in the page source (View Page Source or Elements tab in DevTools).</p>","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#best-practices-for-open-graph-tags","title":"Best Practices for Open Graph Tags","text":"<ol> <li>Use High-Quality Images: Ensure the <code>og:image</code> tag links to a properly sized and optimized image (recommended    minimum 1200x630 pixels).</li> <li>Provide Accurate Titles &amp; Descriptions: Keep titles under 60 characters and descriptions under 200 characters for    optimal display.</li> <li>Test Your Implementation: Use tools like Facebook\u2019s Sharing Debugger to preview how your page will appear when    shared.</li> <li>Include OG Tags in Every Page: Ensure that every page on your site includes Open Graph meta-tags for consistent    branding.</li> <li>Update Tags Regularly: Keep your OG tags up-to-date to reflect changes in content, images, or descriptions.</li> <li>Follow Platform-Specific Guidelines: Different platforms may have specific requirements or additional tags for    optimal sharing.</li> <li>Monitor Performance: Track the performance of your shared links to identify trends and optimize your OG setup.</li> <li>Consider Localization: Provide translations or localized content for international audiences to improve    engagement.</li> <li>Comply with Platform Policies: Ensure your content meets the guidelines of each social media platform to avoid    penalties or restrictions.</li> <li>Leverage OG Tags for Marketing: Use OG tags strategically to highlight key features, promotions, or     calls-to-action in your shared content.</li> </ol>","tags":["Web Application","Improvement"]},{"location":"blog/open-graph-for-social-sharing.html#conclusion","title":"Conclusion","text":"<p>Open Graph is an essential tool for developers looking to optimize content for social media. By implementing OG tags effectively, you can enhance visibility, drive engagement, and maintain control over how your content appears when shared. Stay updated with best practices and leverage debugging tools to ensure a seamless social sharing experience.</p> <p>Further Reading:</p> <ul> <li>Open Graph Protocol</li> <li>Facebook Open Graph Documentation</li> <li>Twitter Card Validator</li> <li>LinkedIn Post Inspector</li> </ul> <p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>","tags":["Web Application","Improvement"]},{"location":"career/feedback-template.html","title":"Professional Feedback Template","text":"<p>I would use such similar feedback when I ask feedback from my superior or Manager</p> <ul> <li> Overall performance and satisfaction feedback about Day-to-Day my roles &amp; responsibilities</li> <li> Feedback about Collaboration with Product Team</li> <li> Feedback about Collaboration within Team</li> <li> Feedback about Collaboration with other teams</li> <li> Feedback about Taking Ownership and Responsibilities</li> <li> Feedback about my soft skills and dedication towards commitments</li> <li> Feedback about my knowledge skills</li> <li> Commitments towards Analysing, Designing, Planning, Developing and shipping new features</li> <li> Commitments towards Problem-Solving for businesses needs</li> <li> Commitments towards maintaining and improving code qualities and reducing technical debt</li> <li> Commitment towards to bringing and implementing innovative features and ideas to improve technical and business</li> <li> Providing Technical Guidance to colleagues</li> <li> Future Expectation for my current roles and responsibilities</li> <li> Any areas you believe I can improve or further develop to enhance my performance</li> </ul>","tags":["How-To","Template"]},{"location":"improvements/code-health-improvements.html","title":"Improve Code Health &amp; Reduce Technical Debt","text":"","tags":["Improvements","Clean Code","Code Refactoring","Secure Coding","Automation"]},{"location":"improvements/code-health-improvements.html#auto-upgrade-dependencies","title":"Auto upgrade dependencies","text":"<ul> <li>Use automated bot to update your project dependencies automatically in order to catch up with latest versions.</li> <li>Renovate provides easy integration and flexible if your organisation use   it. Documentation</li> <li>GitHub Dependent Bot if your repository exists in GitHub, you can use GitHub's   in-house dependent bot for auto updating dependencies.  </li> </ul>","tags":["Improvements","Clean Code","Code Refactoring","Secure Coding","Automation"]},{"location":"improvements/data-quality.html","title":"Improve Data Quality","text":"<p>List of improvements to improve application data quality.</p>","tags":["Improvements","Data Quality","Validations"]},{"location":"improvements/data-quality.html#mobile-phone-number","title":"Mobile Phone Number","text":"<ul> <li>Validate mobile number based on real time criteria based country code and length. Refer article for more   info Phone Number Validation.</li> </ul>","tags":["Improvements","Data Quality","Validations"]},{"location":"improvements/data-quality.html#address-data","title":"Address Data","text":"<ul> <li>GeoCoding APIs improves data quality by converting addresses into   precise geographic coordinates, ensuring location data is accurate and consistently formatted.</li> <li>It minimizes errors in user-entered addresses and enriches data with useful details like postal codes and   administrative regions.</li> <li>Many GeoCoding APIs are available in market including paid and free versions. Some of them as follows,<ul> <li>Google Geocoding API</li> <li>MapTiler GeoCoding API</li> <li>MapBox Geocoding API</li> </ul> </li> </ul>","tags":["Improvements","Data Quality","Validations"]},{"location":"improvements/documentation-improvements.html","title":"Improve Documentation","text":"","tags":["Improvements","Documentation"]},{"location":"improvements/documentation-improvements.html#mkdocs-markdown-documentation","title":"MkDocs - Markdown Documentation","text":"<ul> <li>MkDocs helps us to write any documentation with Markdown   like technical concept, blog, etc.</li> <li>Material for MkDocs provides material theme for documentation</li> <li>Varies plugins available for adding graphs, UML, etc diagrams programmatically</li> </ul>","tags":["Improvements","Documentation"]},{"location":"improvements/documentation-improvements.html#plantuml","title":"PlantUML","text":"<ul> <li>PlantUML helps us to write varies diagrams by writing code</li> <li>PlantUML IDE plugin really helpful for creating UML diagrams</li> </ul>","tags":["Improvements","Documentation"]},{"location":"improvements/web-application-improvements.html","title":"Improve Web Application","text":"","tags":["Improvements","Web Application"]},{"location":"improvements/web-application-improvements.html#hotkeys-keyboard-shortcuts","title":"HotKeys - Keyboard Shortcuts","text":"<ul> <li>HotKeys improves user's UI/UX experience and boost productivity for   any Web   applications</li> <li>It is really helpful for web application like data entry websites and application having complex navigations</li> <li>One-line takeaways<ul> <li>Don\u2019t override native browser (or OS) shortcuts</li> <li>Support standard shortcuts that don\u2019t contradict the previous rule, and use one or two letter shortcuts for other   actions</li> <li>Always have a consistent system</li> <li>Pay maximum attention to discoverability</li> </ul> </li> <li>e.g. JIRA supporting HotKeys,</li> </ul>","tags":["Improvements","Web Application"]},{"location":"java/email-templates.html","title":"Email Template","text":"","tags":["Java","Email","Template"]},{"location":"java/email-templates.html#freemarker","title":"Freemarker","text":"<ul> <li>Freemarker is one of my favorite template engine for emails</li> <li>It provides rich features to manage complex logics using parent-child template formatting</li> <li>Online FreeMarker Template Tester is really helpful and handy to test your   templates</li> <li>IntelliJ Ultimate support developing freemarker   templates out of the box</li> </ul>","tags":["Java","Email","Template"]},{"location":"java/email-templates.html#thymeleaf","title":"Thymeleaf","text":"<ul> <li>Thymeleaf is really handy for simple and lightweight email   templates</li> <li>Thymeleaf and SpringMail is one of the best combination in my opinion</li> <li>IntelliJ Ultimate supports thymeleaf development out of the box</li> </ul>","tags":["Java","Email","Template"]},{"location":"java/email-templates.html#tip","title":"Tip","text":"<ul> <li>Mailpit is email &amp; SMTP testing tool with API, it is really helpful for local   development   to run local SMTP server and visualise using builtin UI and can also be used inn unit and integration testing with   builtin REST API.</li> <li>Implementation Reference: Journey-API </li> </ul>","tags":["Java","Email","Template"]},{"location":"java/java-notes.html","title":"Java Notes","text":"","tags":["Java"]},{"location":"java/validations.html","title":"Validation","text":"","tags":["Java","Validations","Secure Coding"]},{"location":"java/validations.html#phone-number-validation","title":"Phone Number Validation","text":"<ul> <li>Google provides an excellent library libphonenumber for mobile &amp; phone   number validation</li> <li>The library helps to format numbers based on geographical format</li> <li>The Library provides normalization feature to remove unwanted characters</li> <li>The Library has various distribution for many languages</li> </ul>","tags":["Java","Validations","Secure Coding"]},{"location":"java/development/local-development.html","title":"Local Development Essentials","text":"","tags":["Java","Productivity","Workstation Setup"]},{"location":"java/development/local-development.html#testing-e-mail-sending-feature","title":"Testing E-Mail Sending Feature","text":"<ul> <li>Mailpit is a small, fast, low memory, zero-dependency, multi-platform email testing   tool &amp; API for developers</li> <li>It acts as an SMTP server, provides a modern web interface to view &amp; test captured emails, and includes an API for   automated integration testing</li> <li>Docker with Springboot really useful for local development</li> <li>Rest API really helpful for integration testing</li> </ul>","tags":["Java","Productivity","Workstation Setup"]},{"location":"java/development/local-development.html#testing-mongodb-documents","title":"Testing MongoDB documents","text":"<ul> <li>MongoDB docker image helps to run docker   container for local development</li> <li>MongoDB Express is one of the best tool to visualise MongoDB   content, and it's really helpful for local development to add/update/remove data from/to MongoDB</li> </ul>","tags":["Java","Productivity","Workstation Setup"]},{"location":"java/development/workstation-tools.html","title":"Developer Workstation Tools","text":"<p>Tools helps developer to improve productivity and simplify running application or services smoothly, conveniently.</p>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"java/development/workstation-tools.html#useful-simple-git-configuration","title":"Useful simple Git configuration","text":"<ul> <li> <p>When you work with two or more different Git accounts and want to have different configuration for each account, you   can use conditional git configuration. For example, in my case I want to have my organisation account configurations   like company email address for internal organisation repositories and my personal email address for Open Source   repositories.</p> <pre><code># create dedciated git config for personal account in user home directory and define config.\n# in my case i want to use short name and personal email address for open source projects\ncat .gitconfig-github \n[user]\n  name = Ram\n  email = ramachandrannellai@gmail.com\n\n# configure the config in main .gitconfig conditionally\ncat .gitconfig\n# my organisation based config\n[user]\n  name = Ramachandran Nellaiyappan\n  email = ramachandran.nellaiyappan@mycompany.com\n\n[includeIf \"gitdir:~/Ram/github/\"]\n  path = .gitconfig-github\n</code></pre> </li> <li> <p>my favorite one line log format, it might help you as well</p> </li> </ul> <pre><code>  git config --global alias.onelog 'log --graph --decorate --pretty=\"%C(white) Hash: %h %C(red)Date: %ad %C(yellow) %C(blue) Author: %an %C(green)Message: %s \" --date=human'\n</code></pre> <ul> <li>one of my most frequently used git command</li> </ul> <pre><code>  git config --global alias.undo 'reset --soft HEAD~1'\n</code></pre>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"java/development/workstation-tools.html#clean-as-you-code","title":"Clean as You Code","text":"<ul> <li>SonarLint Plugin for IDE: Detect bugs and code smells as early as   possible while you code</li> </ul>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"java/development/workstation-tools.html#envfile-manage-environment-variables","title":"EnvFile: Manage Environment Variables","text":"<ul> <li>EnvFile allows you to set environment variables for your run   configurations from one or multiple files</li> <li>It supports YAML, JSON and .env formats</li> </ul>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"java/development/workstation-tools.html#mkcert-local-trust-store-for-local-development","title":"mkcert: Local Trust store for Local Development","text":"<ul> <li>mkcert A simple zero-config tool to make locally trusted development   certificates with any names you'd like</li> <li>Using certificates from real certificate authorities(CAs) for development can be dangerous or impossible (for hosts   like example.test, localhost or 127.0.0.1), but self-signed certificates cause trust errors.</li> <li>Managing your own CA is the best solution, but usually involves arcane commands, specialized knowledge and manual   steps.</li> <li>mkcert automatically creates and installs a local CA in the system root   store, and generates locally-trusted certificates.</li> <li>mkcert does not automatically configure servers to use the   certificates, though, that's up to you.</li> </ul>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"java/development/workstation-tools.html#design-and-document-your-feature","title":"Design and Document your feature","text":"<ul> <li>PlantUML IDE plugin helps us to write varies diagrams by writing code for documenting your   feature</li> </ul>","tags":["Java","Productivity","Workstation Setup","Developer Tools"]},{"location":"kubernetes/logs-verification.html","title":"Kubernetes Logs Verification","text":"<p>Login:</p> <pre><code>dexctl --user &lt;user-id&gt;\n</code></pre> <p>List all available contexts:</p> <pre><code>kubectl config get-contexts\n</code></pre> <p>Set current context to targeted one:</p> <pre><code>kubectl config use-context &lt;targeted context&gt;\n</code></pre>","tags":["Kubernetes","Logs Verification"]},{"location":"kubernetes/logs-verification.html#logs-for-all-pods-deployment","title":"Logs for all pods / deployment","text":"<p>List deployments:</p> <pre><code>kubectl get deployments -n &lt;target namespace&gt;\n</code></pre> <p>List logs for all pods:</p> <pre><code>kubectl logs deployments/&lt;deployment name&gt;\n</code></pre>","tags":["Kubernetes","Logs Verification"]},{"location":"kubernetes/logs-verification.html#logs-for-a-particular-pod","title":"Logs for a particular pod","text":"<p>List all pods:</p> <pre><code>kubectl get pods -n &lt;target namespace&gt;\n</code></pre> <p>List logs for a particular pod:</p> <pre><code>kubectl logs &lt;targted pod name&gt;\n</code></pre>","tags":["Kubernetes","Logs Verification"]},{"location":"kubernetes/useful-commands.html","title":"Useful Kubernetes Commands","text":"","tags":["Kubernetes","Scripts"]},{"location":"kubernetes/useful-commands.html#executing-commands-in-kubernetes-pod","title":"Executing Commands in Kubernetes Pod","text":"<ul> <li>Sometimes we may need to connect to an existing Kubernetes pod to perform simple tasks like executing simple commands,   checking   connectivity from pod to other networks; for such activities the below command really helps Developers</li> </ul> <pre><code># Authenticate and switch to the targeted Kubernetes context\ndexctl --user &lt;username&gt;\nkubectl config use-context &lt;targeted context&gt;\n\n# List all namespaces in the current context\nkubectl get namespaces\n\n# List all pods in a specific namespace\nkubectl get pods --namespace &lt;namespace&gt;\n\n# Connect to a pod and open an interactive bash terminal for debugging\nkubectl exec --stdin --tty --namespace &lt;namespace&gt; &lt;pod-name&gt; -- /bin/bash\n\n# Execute a single command (e.g., check the current date) inside a pod\nkubectl exec -it --namespace &lt;namespace&gt; &lt;pod-name&gt; -- date\n</code></pre>","tags":["Kubernetes","Scripts"]},{"location":"kubernetes/useful-commands.html#debugging-pod","title":"Debugging Pod","text":"<ul> <li>Sometimes we may need to connect to a Kubernetes pod and perform simple tasks without modifying its existing   container like executing simple commands, checking connectivity from pod to other networks; for such activities, the   below debug command really helps Developers</li> <li>Check kubectl debug to know more</li> </ul> <pre><code>kubectl --cluster=&lt;cluster name&gt; -n &lt;namespace&gt; debug &lt;targeted pod&gt; --image=internal/koopa/toolbox-image:latest -it\n</code></pre>","tags":["Kubernetes","Scripts"]},{"location":"kubernetes/useful-commands.html#download-a-secret-file-from-kubernetes","title":"Download a secret file from Kubernetes","text":"<ul> <li>Sometimes we might save file in Kubernetes secrets e.g. client certificate, ssh keys, any encrypted files</li> <li>We might sometimes need such files on our local machine for debugging or local development</li> <li>These files might not be copied directly or downloadable directly from the Kubernetes UI.   In this case, the below command really helps to download as it is.</li> </ul> <pre><code>  kubectl --cluster=&lt;cluster name&gt; -n &lt;namespace&gt; get secrets \"&lt;name of the entry&gt;\" -o json | jq -r '.data.\"&lt;key&gt;\"' | base64 -d &gt; &lt;desired target file name e.g. localhost.p12&gt;\n</code></pre>","tags":["Kubernetes","Scripts"]},{"location":"kubernetes/useful-commands.html#port-forwarding","title":"Port Forwarding","text":"<ul> <li>Sometimes we might need to debug a pod on Kubernetes, for example, testing configurations.</li> <li>Sometimes our local application might want to connect to a particular Kubernetes pod, in these   cases Port Forwarding really helpful.</li> </ul> <pre><code>kubectl get pods -n &lt;namespace&gt; --cluster=&lt;cluster name&gt;\n\nkubectl --cluster=&lt;cluster name&gt; -n &lt;namespace&gt; port-forward &lt;intended pod&gt; &lt;local port 1&gt;:&lt;remote port 1 &gt; ... &lt;local port n&gt;:&lt;remote port n&gt; \n</code></pre>","tags":["Kubernetes","Scripts"]},{"location":"security/password-security.html","title":"Password Protection &amp; Improvements","text":"","tags":["Security","Improvements","Password","Data Quality","Secure Coding"]},{"location":"security/password-security.html#prevent-weak-passwords","title":"Prevent Weak Passwords","text":"<ul> <li>zxcvbn library helps to measure password strength in terms of score against   common   english words, common patterns &amp; sequences and even we can customize rule base with custom dictionaries</li> <li>Measure user's password strength and prevent user's to use password for which strength score less than allowed (e.g.   prevent score less 3 out of 5)</li> </ul>","tags":["Security","Improvements","Password","Data Quality","Secure Coding"]},{"location":"security/password-security.html#prevent-leaked-passwords","title":"Prevent Leaked Passwords","text":"<ul> <li>HaveIBeenPwned allows you to search across multiple data breaches to see if your email   address or phone number has been compromised.</li> <li>It supports REST API as well</li> <li>It has leaked password database and has secured way to compare passwords using hashing techniques</li> <li>Tip: Spring Security has HaveIBeenPwnedRestApiPasswordChecker API which helps application to securely connect to   the HaveIBeenPwned service  </li> </ul>","tags":["Security","Improvements","Password","Data Quality","Secure Coding"]},{"location":"security/penetration-testing.html","title":"Penetration Testing","text":"<ul> <li>Below are the list of Open Web Application Security Projects (OWASP) Testing Guide checklist to perform pen-testing</li> <li>The below checklist is of my own interest, feel free to add if you have one</li> <li>Star (\u2b50) denoted testing is strongly recommended for testing web applications</li> </ul> Category Testing Guide Remarks Information Gathering Conduct Search Engine Discovery and Reconnaissance for Information Leakage Fingerprint Web Server \u2b50 Review Webserver Metafiles for Information Leakage \u2b50 Enumerate Applications on Webserver \u2b50 Review Webpage Comments and Metadata for Information Leakage \u2b50 Identify application entry points Map execution paths through application Fingerprint Web Application Framework \u2b50 Fingerprint Web Application Map Application Architecture Configuration and Deploy Management Testing Test Network/Infrastructure Configuration Test Application Platform Configuration Test File Extensions Handling for Sensitive Information Review Old, Backup and Unreferenced Files for Sensitive Information Enumerate Infrastructure and Application Admin Interfaces \u2b50 Test HTTP Methods \u2b50 Test HTTP Strict Transport Security \u2b50 Test RIA Cross Domain Policy Test File Permission Test for Subdomain Takeover Test Cloud Storage Identity Management Testing Test Role Definitions Test User Registration Process Test Account Provisioning Process Testing for Account Enumeration and Guessable User Account \u2b50 Testing for Weak or Unenforced Username Policy \u2b50 Authentication Testing  Testing for Credentials Transported over an Encrypted Channel Testing for Default Credentials Testing for Weak Lock Out Mechanism Testing for Bypassing Authentication Schema Testing for Vulnerable Remember Password Testing for Browser Cache Weaknesses Testing for Weak Password Policy Testing for Weak Security Question Answer Testing for Weak Password Change or Reset Functionalities Testing for Weaker Authentication in Alternative Channel Authorization Testing Testing Directory Traversal File Include Testing for Bypassing Authorization Schema Testing for Privilege Escalation Testing for Insecure Direct Object References Session Management Testing Testing for Session Management Schema Testing for Cookies Attributes Testing for Session Fixation Testing for Exposed Session Variables Testing for Cross Site Request Forgery Testing for Logout Functionality Testing Session Timeout Testing for Session Puzzling Data Validation Testing Testing for Reflected Cross Site Scripting \u2b50 Testing for Stored Cross Site Scripting Testing for HTTP Verb Tampering \u2b50 Testing for HTTP Parameter Pollution \u2b50 Testing for SQL Injection Testing for Oracle Testing for MySQL Testing for SQL Server Testing PostgreSQL Testing for MS Access Testing for NoSQL Injection Testing for LDAP Injection Testing for ORM Injection Testing for XML Injection Testing for SSI Injection Testing for XPath Injection Testing for IMAP SMTP Injection Testing for Code Injection Testing for Local File Inclusion Testing for Remote File Inclusion Testing for Command Injection Testing for Format String Injection Testing for Incubated Vulnerability Testing for HTTP Splitting Smuggling Testing for HTTP Incoming Requests Testing for Client-side Testing for Host Header Injection Testing for Server-side Template Injection Error Handling Testing for Improper Error Handling \u2b50 Cryptography Testing for Weak Encryption \u2b50 Testing for Padding Oracle \u2b50 Testing for Sensitive Information Sent via Unencrypted Channels \u2b50 Testing for Weak Transport Layer Security \u2b50 Business Logic Testing Test Business Logic Data Validation  Test Ability to Forge Requests \u2b50 Test Integrity Checks Test for Process Timing \u2b50 Test Number of Times a Function Can Be Used Limits \u2b50 Testing for the Circumvention of Work Flows \u2b50 Test Defenses Against Application Misuse \u2b50 Test Upload of Unexpected File Types Test Upload of Malicious Files Client Side Testing Testing for DOM-Based Cross Site Scripting \u2b50 Testing for JavaScript Execution Testing for HTML Injection Testing for Client-side URL Redirect Testing for CSS Injection Testing for Client-side Resource Manipulation Testing Cross Origin Resource Sharing Testing for Cross Site Flashing Testing for Clickjacking Testing WebSockets Testing Web Messaging Testing Browser Storage Testing for Cross Site Script Inclusion","tags":["Security","Testing","Penetration Testing","Security Testing"]},{"location":"security/secure-coding.html","title":"Secure Coding","text":"","tags":["Security","Secure Coding"]},{"location":"security/secure-coding.html#clean-as-you-code","title":"Clean As You Code","text":"<ul> <li>SonarLint Plugin for IDE: Detect bugs and code smells as early as   possible while you code   You can even bind your organisation's quality gate rules if exists any</li> <li>SonarCloud does support Clean as You code   policy for your open source projects. It is free of cost for open source projects.</li> </ul>","tags":["Security","Secure Coding"]},{"location":"security/secure-coding.html#xss-encode-for-client","title":"XSS: Encode for client","text":"<ul> <li> <p>OWASP Java Encoder helps to encode values based on client use case to   avoid any XSS attack</p> </li> <li> <p>Similar to html, dedicated methods available for CSS(<code>forCssString</code>) and JS (<code>forJavaScript</code>) as well</p> </li> <li>Similarly different encoding methods available for script/style   attribute(<code>forJavaScriptAttribute, forCssString-</code>), block (<code>forJavaScriptBlock</code>) and URL   components (<code>forCssUrl, forJavaScriptSource</code>) parameter   <pre><code>// when you want to place json properties inside &lt;script type=\"application/json\"&gt;${toJson()}&lt;/script&gt; in html\npublic String toJson() {\n  ObjectMapper objectMapper = new ObjectMapper();\n  try {\n    return Encode.forHtmlContent(objectMapper.writeValueAsString(this));\n  } catch (JsonProcessingException ex) {\n    log.error(\"Serialization error.\", ex);\n  }\n  return null;\n}\n</code></pre></li> </ul>","tags":["Security","Secure Coding"]},{"location":"security/secure-coding.html#obfuscate-sensitive-information","title":"Obfuscate Sensitive Information","text":"<ul> <li>Sensitive information like username, password and OneTimeToken, sometimes unknowingly logged in log files, and it   might   lead to potential information leak</li> <li>To avoid such accidental information leak, it is always recommended to obfuscate such information either partially or   completely</li> <li>example overriding default toString() to obfuscate complete information as follows</li> </ul> <pre><code>  record Password(String value) {\n    @Override\n    public String toString() {\n        return \"Password { 'value': '***' }\";\n    }\n}\n</code></pre> <ul> <li>example obfuscate partial information about email address</li> </ul> <pre><code>record EmailAddress(String value) {\n    @Override\n    public String toString() {\n        return \"EmailAddress {'value': '%s'}\".formatted(EmailAddressObfuscator.obfuscate(value));\n    }\n}\n\n\n/**\n * Obfuscates an email address by starring the local part (username), except the first character.\n * &lt;p&gt;\n * If the local part has only one character, then this will be starred.\n * &lt;/p&gt;\n * &lt;p&gt;\n * For example the email address &lt;c&gt;name.surname@example.com&lt;/c&gt; will be obfuscated as &lt;c&gt;n***********@example.com&lt;/c&gt;.\n * &lt;/p&gt;\n */\npublic final class EmailAddressObfuscator {\n    private static final String EMAIL_ADDRESS_SEPARATOR = \"@\";\n    private static final int NO_VISIBLE_LOCAL_PART_CHARS = 1;\n    private static final String MASK_CHAR = \"*\";\n\n    private EmailAddressObfuscator() {\n        throw new UnsupportedOperationException(\"This is a utility class and cannot be instantiated\");\n    }\n\n\n    private static String getNonLocalPart(String emailAddress) {\n        return StringUtils.substringAfterLast(emailAddress, EMAIL_ADDRESS_SEPARATOR);\n    }\n\n    private static String getLocalPart(String emailAddress) {\n        return StringUtils.substringBeforeLast(emailAddress, EMAIL_ADDRESS_SEPARATOR);\n    }\n\n    private static String obfuscateLocalPart(String emailAddress) {\n        String localPart = getLocalPart(emailAddress);\n        return StringUtils.substring(localPart, 0, NO_VISIBLE_LOCAL_PART_CHARS)\n                + StringUtils.repeat(MASK_CHAR, StringUtils.length(localPart) - NO_VISIBLE_LOCAL_PART_CHARS);\n    }\n\n    private static String getObfuscateValue(String emailAddress) {\n        return obfuscateLocalPart(emailAddress) + EMAIL_ADDRESS_SEPARATOR + getNonLocalPart(emailAddress);\n    }\n\n\n    public static String obfuscate(final String emailAddress) {\n        return Optional.ofNullable(emailAddress)\n                .filter(StringUtils::isNotBlank)\n                .map(EmailAddressObfuscator::getObfuscateValue).orElse(\"\");\n    }\n\n}\n</code></pre>","tags":["Security","Secure Coding"]},{"location":"testings/automation-tips.html","title":"Automation Testing Tips","text":"","tags":["Testing","Automation","Testing","Tips"]},{"location":"testings/automation-tips.html#maven-failsafe-plugin","title":"maven-failsafe-plugin","text":"<ul> <li>maven-failsafe-plugin provides rich features for   integration and automation tests. If possible and suitable for your project case, use it</li> <li><code>rerunFailingTestsCount</code> is really useful feature to rerun failing tests at the end of the build   reference.</li> </ul>","tags":["Testing","Automation","Testing","Tips"]},{"location":"testings/intellij-testing-tools.html","title":"IntelliJ IDE Testing Tools &amp; Plugins","text":"","tags":["Testing","Testing","Developer Tools","Productivity","IntelliJ Plugins"]},{"location":"testings/intellij-testing-tools.html#test-data-intellij-ide-plugin","title":"Test Data - IntelliJ IDE Plugin","text":"<ul> <li>Test Data can generate all sorts of randomized data including   Text, UUID, Numbers, Date &amp; Time, and Custom types such as popular ones like JSON, CSV, and SQL</li> <li>The plugin adds a context action 'Test Data' to generate data</li> </ul>","tags":["Testing","Testing","Developer Tools","Productivity","IntelliJ Plugins"]},{"location":"testings/intellij-testing-tools.html#restfultool-intellij-ide-plugin","title":"RestFulTool - IntelliJ IDE Plugin","text":"<ul> <li>RestFulTool offers a window to make REST API calls all from   IDE</li> <li>The plugin provides a bunch of tools for Restful Service development</li> <li>It has great integration support for Spring MVC and Spring Boot</li> </ul>","tags":["Testing","Testing","Developer Tools","Productivity","IntelliJ Plugins"]},{"location":"testings/intellij-testing-tools.html#http-client-intellij-ide-plugin","title":"HTTP Client - IntelliJ IDE Plugin","text":"<ul> <li>HTTP Client helps to create, edit, and   execute HTTP requests directly in the IntelliJ IDEA code editor.</li> <li>It provides varies features like configuring env variable file with support for environments like dev, qa and live.</li> <li>Please refer HowTo:HTTP Client - IntelliJ Plugin</li> </ul>","tags":["Testing","Testing","Developer Tools","Productivity","IntelliJ Plugins"]},{"location":"blog/category/automation.html","title":"Automation","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/architecture.html","title":"Architecture","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/java.html","title":"Java","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/security.html","title":"Security","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/web-application.html","title":"Web Application","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/testing.html","title":"Testing","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/category/workstation-setup.html","title":"Workstation Setup","text":"<p>Did this post help you? Share on:  X (Twitter)  Facebook  LinkedIn  reddit  WhatsApp  Hacker News</p>"},{"location":"blog/page/2/index.html","title":"Blogs","text":""}]}